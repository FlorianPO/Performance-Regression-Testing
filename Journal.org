#+TAGS: Phoronix(P) Pypy(Y) Jenkins(J) CollectiveMind(C)
#+TAGS: XPFlow(C) Expo(A) Execo(B) 
#+TAGS: Spack(S) Kameleon(K)

* Jeudi 19/05
  - Installation de D√©bian8 avec Vincent Danjean
  - Mise en place de l'environnement de travail (quelques raccourcis
    qui me sont chers, des marque-pages, un Git:
    https://github.com/FlorianPO/Performance-Regression-Testing)
  - Il faut que je fournisse mon adresse MAC √† Christian afin d'avoir
    Internet en filaire (tr√®s peu de Wifi dans la salle)
  - Prise en main de Org-mode sous emacs
* Lundi 23/05				    :Phoronix:Jenkins:CollectiveMind:
  - [[https://github.com/FlorianPO/Performance-Regression-Testing/blob/master/Phoronix.org][Overview de Phoronix]] : d√©pendant du mat√©riel, deux tests n'auront
    du sens que s'ils sont √©xecut√©s sur la /m√™me/ machine.
  - [[https://github.com/FlorianPO/Performance-Regression-Testing/blob/master/CollectiveMind.org][Overview de CollectiveMind]] : plus proche du sujet (ax√© recherche)
  - [[https://github.com/FlorianPO/Performance-Regression-Testing/blob/master/Jenkins.org][Overview de Jenkins]]

  Ces documents ne sont qu'une √©bauche, il conviendra √† l'avenir de
  s'int√©resser √† leur points communs/diff√©rences. En premi√®re
  approximation, les benchmarks propos√©s d√©pendent de la machine qui
  les a g√©n√©r√©s (√† l'exception de CollectiveMind qui semble
  s'int√©resser au probl√®me). N√©anmoins, ces trois plateformes sont des
  /usines √† gaz/, il reste encore √©norm√©ment √† d√©couvrir.
* Mardi 24/05
  - Uniformisation des .org. L'objectif est de comparer les 3
    plateformes sur le benchmarking.
  - Ajout d'un [[https://github.com/FlorianPO/Performance-Regression-Testing/blob/master/State_of_the_art.org][rapport]] /tr√®s bref/ sur l'√©tat de l'art. Il convient d'en
    discuter.
  - R√©union avec Arnaud Legrand : creuser les outils pour voir s'ils
    correspondent au besoin (benchmarks propres, possibilit√© de
    r√©cup√©rer les donn√©es pour une exploitation sp√©cifique, un peu de
    contr√¥le d'exp√©rience, technologie p√©renne). + utiliser Marker
    pour le journal.
  - S'occuper de Pypy, ...
  - Tester Phoronix
  - Installation de Phoronix Test Suite v6.2.1
* Mercredi 25/05						     :ATTACH:
** Phoronix							   :Phoronix:
 :PROPERTIES:
  :Attachments: FirstTest.png SecondTest.png
  :ID:       d5f63874-eef8-49c2-b544-2f7391cd499d
  :END:
   + Premier test avec Phoronix -> rbenchmark -> failed to run properly
   + Deuxi√®me test avec Phoronix -> 7zip compression -> ok
   + Pr√©sence de tests multicoeurs
   + L'injection de charges semble possible (see Fulldoc : "stressing
     your system with random workloads") m√™me si ce n'est pas
     l'objectif premier (cf- Vincent)
   + Possibilit√© d'exporter les donn√©es collect√©es
   + L'interface semble simple √† utiliser (m√™me si je n'y suis pas
     arriv√© (pour le moment))
   + S'int√©resser aux tests eux-m√™me (comment les √©crire, etc...)
** Pypy								       :Pypy:
   http://speed.pypy.org/timeline/#/?exe=3,6,1,5&base=2+472&ben=ai&env=1&revs=200&equid=off
   + Fait avec Django (Framework Web python) et Codespeed (Web
     benchmark application) -> √† regarder, semble int√©ressant !
   + Code des benchmarks :
     https://bitbucket.org/pypy/benchmarks/src/846fa56a282b/unladen_swallow/performance/
    
* Jeudi 26/05							       
** Codespeed							       :Pypy:
   https://github.com/tobami/codespeed
   - Probl√®me d'installation (Python invalid syntax (?))
   - La commande magique : =python ./manage.py syncdb --migrate=
   - Serveur lanc√© : probl√®me d'authentification cependant
   - Il faut cr√©er un super-utilisateur : =python manage.py
     createsuperuser=
   - Lancer le serveur en _sudo_ : =sudo python manage.py runserver 8000=
   - Fournir Codespeed en donn√©es : "Codespeed is a web application to
     monitor and analyze the performance of your code" -> seulement de
     la visualisation de donn√©es
** Phoronix 							   :Phoronix:
   R√©sultats des tests dans
   =~/.phoronix-test-suite/test-results/<TEST>/= :
     - =composite.xml= :: : plan d'exp√©rience
     - =system-logs/= :: : 2 tonnes de donn√©es collect√©es
   M√©ta-donn√©es des tests (par d√©fault) dans
   =~/.phoronix-test-suite/test-profiles/pts/<TEST>/=

* Vendredi 27/05
** Phoronix							   :Phoronix:
   - Ecriture d'un bubble sort en python pour tester Phoronix,
     t√©l√©chargeable √†
     https://github.com/FlorianPO/Performance-Regression-Testing/raw/master/bubble_sort.py.tar.gz
   - Ecriture des m√©ta-donn√©es du test (√† tester, ne marchera s√ªrement
     pas du premier coup)
*** Bubble sort TEST
    - placer le test dans :
      =~/.phoronix-test-suite/test-profiles/local/<TEST>/= (celui-ci
      devrait √™tre visible par la commande =phoronix-test-suite
      list-available-tests=
    - il faut g√©n√©rer un checksum MD5 de l'archive √† t√©l√©charger :
      =md5sum <FILE>= (√† placer dans =download.xml=)
    - probl√®me d'√©xecutable :
      - le script g√©n√©r√© dans install.sh doit avoir le m√™me nom
        =<TEST-NAME>= que le dossier du test =local/<TEST-NAME>=
* Lundi 30/05
** Phoronix							   :Phoronix:
   - Output template : la sortie du programme semble devoir
     correspondre √† l'OutputTemplate dans =results-definition.xml=
   - Update : la correspondance doit √™tre exacte (sauf certains cas
     (ex: en C les retours chariot semble ignor√©s), √† √©tudier...)
   - https://www.phoronix.com/forums/forum/phoronix/phoronix-test-suite/46913-custom-benchmark
*** Multiple results
    - Multiplier les champs =OutputTemplate= dans =results-definition.xml= ne suffit pas...
    - Ce n'est pas possible...
    - Regarder dans le code source -> hardcore
** Autres pistes
   - Execo, XPFlow, Expo
   - Regarder Webinar n¬∞2 + √©tat de l'art de ces outils (voir slide)
     - Regard√© jusqu'√† 35 min (partie 6)
* Mardi 31/05
** Expo								       :Expo:
*** Intro
    It aims at simplifying the experimental process on such
    distributed platforms. Works with client / server.
    - Liens :
      + http://expo.gforge.inria.fr/
    - Pros :
      + Everything is logged : IO, commands, date, ...
*** Avancement
    - Installation de Ruby
    - Installation de gem2.1
    - Probl√®me de version : Expo et ses d√©pendances utilisent Ruby
      1.9.3 (current version : Ruby 2.3)
    - Installation de RVM pour installer / switcher Ruby 1.9.3
      + https://rvm.io/rvm/install 
      + http://stackoverflow.com/questions/9919739/how-to-use-the-older-version-of-ruby-1-9-2
      + Pour utiliser la commande =rvm= : =source
        /home/<USER>/.rvm/scripts/rvm= (<USER> : florian)
      + Pour switcher sur Ruby 1.9.3 : =rvm use ruby-1.9.3 --default=
    - Petit tuto Ruby : http://tryruby.org/levels/1/challenges/0
    - Impossible de lancer =./expo= -> probl√®me syntaxe -> passage en
      Ruby 2.3.1
      + IMPOSSIBLE, rien ne marche
      + Expo utilise Ruby 1.8.7 mais Restfully n√©cessite Ruby >= 1.9.3
** XPFlow							     :XPFlow:
*** Intro
    XPFlow is a new approach to description and execution of
    experiments involving large-scale computer installations. The main
    idea consists in describing the experiment as workflow and using
    achievements of Business Workflow Management to reliably and
    efficiently execute it. Moreover, to facilitate the design
    process, the framework provides abstractions that hide unnecessary
    complexity from the user.
    - Liens:
      + http://xpflow.gforge.inria.fr/
      + http://xpflow.gforge.inria.fr/img/slides/slides.pdf
	* http://xpflow.gforge.inria.fr/img/slides/slides.pdf
*** Avancement
    - Installation de XPFlow
    - Lecture des slides : pas d√©gueux du tout
    - Permet de lancer des commandes syst√®mes, etc...
    - Installation de =cairo= : =gem install cairo= (pour exporter en pdf)
      + permet de visualiser le workflow
    - A tester avec Grid5000 -> demande de compte faite.
** Execo							      :Execo:
*** Intro
    Execo is a Python library that allows you to finely manage unix
    processes on thousands of remote hosts. It is well designed for :
    - prototyping experiments on distributed systems (Grid5000
      support)
    - automatize admin tasks
    - create reproducible experiments
    - Liens :
      + http://execo.gforge.inria.fr/doc/latest-stable/
      + http://execo.gforge.inria.fr/doc/latest-stable/userguide.html
*** Avancement
    - Installation de Execo et de tous ses packages optionnels.
* Mercredi 01/06
** Execo							      :Execo:
  - Obtention d'un compte Grid5000
  - Lecture de la doc d'Execo
  - A faire : comparer Execo et XPFlow
** XPFlow							     :XPFlow:
   - Liste des patterns : http://xpflow.gforge.inria.fr/docs/patterns/ :
     super cool !
   - =git clone= du projet
   - Installation de LaTeX-mk pour g√©n√©rer la doc
   - Recherche de la structure du pattern =info= : classe InfoRun dans
     runs.rb (peu de choses...)
* Mardi 07/06
  - Visionnage des webinars 2 et 3
  - Contacter Olivier Richard et Michael Mercier au sujet de
    l'installation d'environnement. XPFlow m√©lange celui-ci et le
    contr√¥le de l'exp√©rience : pas une bonne id√©e.
* Mercredi 08/06
  - Installation de =emacs= sur Windows (=C-H v user-init-file RET= dans
    emacs pour trouver l'emplacement du fichier =.emacs=)  
  - Visionnage du webinar 1 + [[https://github.com/FlorianPO/Performance-Regression-Testing/blob/master/Webinar_1.org][prise de note]]
* Jeudi 09/06
  - Visionnage du webinar 2 + [[https://github.com/FlorianPO/Performance-Regression-Testing/blob/master/Webinar_2.org][prise de note]]
  - Docker for reproducible research :
    http://www.carlboettiger.info/assets/files/pubs/10.1145/2723872.2723882.pdf
  - SPACK + KAMELEON -> t√©l√©chargement (+ installation)
    - SPACK : Lucas 
    - D√©pendances : Ven√¨cius
    - KAMELEON : Michael
  - (XPFlow) -> Contr√¥le de l'exp√©rience
* Vendredi 10/06
** Spack							      :Spack:
   Petits tutos sur le PATH pour se mettre √† niveau :
   - https://wiki.debian.org/EnvironmentVariables
   - http://www.generation-linux.fr/index.php?post/2008/10/15/Changer-les-dossiers-par-defaut-dans-le-PATH
   Installation de Spack
*** Liens :
    - Features :: http://software.llnl.gov/spack/features.html
    - Doc :: http://software.llnl.gov/spack/
    - Package installable ::
         http://software.llnl.gov/spack/basic_usage.html
** Kameleon							   :Kameleon:
   Installation de Kameleon
*** Liens :
    - Doc :: http://kameleon.imag.fr/index.html
* Lundi 13/06
** Kameleon							   :Kameleon:
   - Le tutoriel qui va bien :
     http://kameleon.imag.fr/grid5000_tutorial.html
   - Kameleon + Puppet :
     https://www.grid5000.fr/mediawiki/index.php/Environments_creation_using_Kameleon_and_Puppet
** Spack							      :Spack:
   - http://software.llnl.gov/spack/basic_usage.html
* Mardi 14/06
  - Lecture compl√®te de la doc de Kameleon : fait.
  - R√©union avec Michael et Arnaud :
    + Pr√©liminaires :      
      * Lire le /Getting started/ de G5k
        https://www.grid5000.fr/mediawiki/index.php/Getting_Started
      * D√©ployer une image, jouer avec les commandes, ...
      * Objectif : lancer au moins un benchmark StarPU Morse
        http://starpu.gforge.inria.fr/testing/morse/trunk/morse.html
    + Automatiser : 
      * Kameleon + Spack (pour les BLAS)
      * r√©cup√©rer sur Git StarPU / Morse
      * benchmark sur les versions (en mode r√©el ou simul√©)
	- mode simul√© : √©xecution des versions parall√®les (Execo
          peut-il faire ceci ? Voir avec Michael)
      * logger
** Grid5000 getting started
*** R√©servation
    - Dabord, la frontale :
      #+begin_src sh :session foo :results output :exports both 
      ssh fpopek@access.grid5000.fr
      #+end_src

      #+RESULTS:
      #+begin_example

      Linux access-south.grid5000.fr 3.2.0-4-amd64 #1 SMP Debian 3.2.73-2+deb7u3 x86_64
      ----- Grid'5000 - access-south.grid5000.fr -----

      Welcome to Grid'5000

      ** Connect to a site:
      ssh {grenoble,lille,luxembourg,lyon,nancy,nantes,reims,rennes}

      ** Useful links:
       - account management (password change): https://api.grid5000.fr/ui/account
       - homepage: https://www.grid5000.fr/mediawiki/index.php/Category:Portal:User
       - charter : https://www.grid5000.fr/mediawiki/index.php/Grid5000:UserCharter
       - support : https://www.grid5000.fr/mediawiki/index.php/Support

      ** Data on access.grid5000.fr :
       - your home directory on access machines (access-north and access-south)
	 is not synchronized and should not be use to store data.
       - please use ssh forwarding to send data directly to sites or
      scp files login@access.grid5000.fr:reims/ using the nfs mount point in your home

      [31m[5m
      ** Warning: 1 event in progress
      #Incident in #Sophia¬†: hard drive failures on srv.sophia.grid5000.fr, site unavailable
      [0m[31m    https://intranet.grid5000.fr/bugzilla/show_bug.cgi?id=6967
      [0m
      Last login: Tue Jun 14 14:39:37 2016 from 129.88.54.126
#+end_example

    - Puis grenoble :
      #+begin_src sh :session foo :results output :exports both 
      ssh grenoble
      #+end_src

      #+RESULTS:
      #+begin_example
      ----- Grid'5000 - Grenoble - fgrenoble.grenoble.grid5000.fr -----

      This site has 3 clusters (see: https://api.grid5000.fr/stable/ui/visualizations/nodes.html)

      Available in queue default:
       - genepi (2008): 34 nodes (2 CPUs Intel Xeon E5420, 4 cores/CPU, 8GB RAM, 153GB HDD)
       - edel   (2008): 72 nodes (2 CPUs Intel Xeon E5520, 4 cores/CPU, 24GB RAM, 119GB SSD)
       - adonis (2010): 10 nodes (2 CPUs Intel Xeon E5520, 4 cores/CPU, 24GB RAM, 233GB HDD)

      ** Useful links:
       - account management (password change): https://api.grid5000.fr/ui/account
       - homepage: https://www.grid5000.fr/mediawiki/index.php/Category:Portal:User
       - charter : https://www.grid5000.fr/mediawiki/index.php/Grid5000:UserCharter
       - support : https://www.grid5000.fr/mediawiki/index.php/Support

      ** Others sites:
      ssh {lille,luxembourg,lyon,nancy,nantes,reims,rennes,sophia}

      Last login: Tue Jun 14 14:40:46 2016 from access-south.grid5000.fr
#+end_example

    - =oarsub -I= pour r√©server une machine en mode interactif
    - Pour r√©server 2 noeuds pendant 30 min :
      #+begin_src sh :session foo :results output :exports both 
      oarsub -I -l nodes=2,walltime=0:30 
      #+end_src

    - Pour r√©server dans le futur
      #+begin_src sh :session foo :results output :exports both 
      oarsub -I -r '2012-12-23 16:30:00'
      #+end_src

      + =oarstat= pour voir l'historique des r√©servations
      + =oarstat -u= pour voir ses r√©servations
      + =oarstat -r <JOB_ID>= pour supprimer une r√©servation
    - Propri√©t√©s OAR
      #+begin_src sh :session foo :results output :exports both 
      oarsub -p "gpu='YES'"
      #+end_src

    - =oarsub -t deploy= pour d√©ployer avec Kadeploy (/The root password
      for all Grid'5000-provided images is grid5000/)
*** Gestion des noeuds
    - =uniq $OAR_NODEFILE= liste des noeuds r√©serv√©s
    - =oarsh <NODE>= utiliser un noeud r√©serv√©
    - =ssh root@<NODE>= se connecter en root sur un noeud
** Spack
   Installation :
   - =git clone https://github.com/llnl/spack.git=
   - =export PATH=$SPACK_ROOT/bin:$PATH=
   - =spack install libelf=
** StarPU
*** Installation avec Spack
    http://morse.gforge.inria.fr/chameleon/tuto_chameleon/chameleon-tutorial-2015-12-16-inria.html#sec-6-2
*** En pratique (buggu√©, voir le lendemain)
    D√©ploiement

    #+begin_src sh :session foo :results output :exports both 
    ssh grenoble.g5k (ou ssh fpopek@access.grid5000.fr puis ssh grenoble)
    ssh digitalis
    oarsub -I -t deploy
    kadeploy3 -f $OAR_NODE_FILE -e jessie-x64-big -k (probl√®me avec Digitalis)
    ssh root@machine
    #+end_src
    
    Installation de Spack
    
    #+begin_src sh :session foo :results output :exports both 
    git clone https://github.com/fpruvost/spack
    export SPACK_ROOT=~/spack/
    export PATH=$SPACK_ROOT/bin:$PATH
    #+end_src
      
    Morse package
    
    #+begin_src sh :session foo :results output :exports both 
    cd spack
    git checkout morse
    #+end_src
    
    Installation de Chameleon

    #+begin_src sh :session foo :results output :exports both 
    spack install chameleon+examples
    #+end_src

    Installation de StarPU

    #+begin_src sh :session foo :results output :exports both 
    spack install -v chameleon@trunk~quark+examples+fxt ^starpu@svn-trunk+fxt
    spack install -v chameleon@trunk~quark+simu+examples+fxt ^starpu@svn-trunk+simgrid+fxt ^simgrid@starpumpi (pour la simulation)

    ( spack install -v chameleon@trunk~quark+examples+fxt )
    #+end_src
* Mercredi 15/06
  - Ma version de Spack ne permet pas d'installer StarPu (0.9.1) celle
  de Vin√¨cius (0.8.15) marche
  - Probl√®me d'import Python -> r√©cup√©ration de l'image de Vin√¨cius
  - Probl√®me de Spack -> envoie d'un mail √† Lucas
** Environnement de Vin√¨cius
   #+begin_src sh :session foo :results output :exports both 
   ssh grenoble.g5k
   ssh digitalis
   oarsub -I -t deploy
   kadeploy3 -f $OAR_NODE_FILE -a imageIDCin.env -k
   #+end_src
  
   Image copi√©e depuis =/home/vgarciapinto/= (avec modification de
   imageIDCin.env avec mon login)

   #+begin_src sh :session foo :results output :exports both 
   ssh root@machine
   sudo apt-get update
   sudo apt-get install -y python2.7-dev
   sudo apt-get install -y vim emacs
   sudo apt-get install -y curl patch
   sudo apt-get install -y git subversion mercurial
   sudo apt-get install -y build-essential gfortran
   sudo apt-get install -y autoconf automake cmake cmake-data doxygen texinfo
   sudo apt-get install -y libtool (libtool-bin)
   sudo apt-get install -y libboost-dev
   sudo apt-get install -y gawk
   sudo apt-get install -y bison flex
   sudo apt-get install -y binutils-dev libelf-dev (libiberty-dev)
   sudo apt-get install -y libz-dev
   sudo apt-get install -y libqt4-dev freeglut3-dev
   sudo apt-get install -y environment-modules
   #+end_src

   #+begin_src sh :session foo :results output :exports both 
   git clone https://github.com/fpruvost/spack
   export SPACK_ROOT=~/spack/
   export PATH=$SPACK_ROOT/bin:$PATH
   #+end_src

   #+begin_src sh :session foo :results output :exports both 
   cd spack/
   git checkout morse
   #+end_src

   La branche morse peut (sous quelles conditions ?) ne pas marcher :

   #+RESULTS:
   #+begin_example
   Traceback (most recent call last):
     File "/root/spack//bin/spack", line 50, in <module>
       import nose
     File "/root/spack/lib/spack/external/nose/__init__.py", line 1, in <module>
       from nose.core import collector, main, run, run_exit, runmodule
     File "/root/spack/lib/spack/external/nose/core.py", line 9, in <module>
      import unittest
     File "/usr/lib/python2.7/unittest/__init__.py", line 58, in <module>
      from .result import TestResult
     File "/usr/lib/python2.7/unittest/result.py", line 10, in <module>
      from functools import wraps
   ImportError: cannot import name wraps
   #+end_example

   (semble optionnel)
   #+begin_src sh :session foo :results output :exports both 
   spack install chameleon
   #+end_src

   #+begin_src sh :session foo :results output :exports both 
   spack install chameleon~quark+fxt+starpu ^starpu+fxt
   #+end_src

   ==> Error: chameleon does not depend on starpu
* Vendredi 17/06
  Enregistrement d'une nouvelle image contenant Chameleon et Starpu (+
  toutes les d√©pendances n√©cessaires)

  #+begin_src sh :session foo :results output :exports both 
  ssh grenoble.g5k
  ssh digitalis
  oarsub -I -t deploy
  kadeploy3 -f $OAR_NODE_FILE -a image.env -k
  #+end_src

  Rappel de l'objectif : lancer un benchmark 
  http://starpu.gforge.inria.fr/testing/morse/trunk/morse.html

  #+begin_src sh :session foo :results output :exports both 
  export SPACK_ROOT=~/spack/
  export PATH=$SPACK_ROOT/bin:$PATH
  spack install -v chameleon@trunk~quark+simu+examples+fxt+starpu ^starpu@svn-trunk+simgrid+fxt ^simgrid@starpumpi (pour la simulationg, ne marche pas)
  #+end_src

  #+RESULTS:
  #+begin_example
  ==> Successfully installed simgrid
  Fetch: 11.83s.  Build: 45.30s.  Total: 57.12s.
  [+] /root/spack/opt/spack/linux-x86_64/gcc-4.7/simgrid-starpumpi-tosagznhajv6jgnrtesrrzuhppizpmp3
  Traceback (most recent call last):
    File "/root/spack//bin/spack", line 176, in <module>
      main()
    File "/root/spack//bin/spack", line 154, in main
      return_val = command(parser, args)
    File "/root/spack/lib/spack/spack/cmd/install.py", line 82, in install
      explicit=True)
    File "/root/spack/lib/spack/spack/package.py", line 927, in do_install
      make_jobs=make_jobs)
    File "/root/spack/lib/spack/spack/package.py", line 1051, in do_install_dependencies
      dep.package.do_install(**kwargs)
    File "/root/spack/lib/spack/spack/package.py", line 1008, in do_install
      spack.build_environment.fork(self, build_process)
    File "/root/spack/lib/spack/spack/build_environment.py", line 402, in fork
      setup_package(pkg)
    File "/root/spack/lib/spack/spack/build_environment.py", line 360, in setup_package
      dpkg.setup_dependent_package(pkg.module, spec)
    File "/root/spack/var/spack/repos/builtin/packages/simgrid/package.py", line 37, in setup_dependent_package
      if spec.satisfies('+smpi'):
  NameError: global name 'spec' is not defined
  ==> Error: Installation process had nonzero exit code.
  #+end_example

  Solution : remplacer =spec= par =dep_spec=

  #+RESULTS:
  #+begin_example
  ==> 'make' '-j16'
  Making all in src
  make[1]: Entering directory `/tmp/root/spack-stage/spack-stage-Bqd_mp/trunk/src'
  make[2]: Entering directory `/tmp/root/spack-stage/spack-stage-Bqd_mp/trunk/src'
    CC     libstarpu_1.3_la-barrier.lo
    CC     libstarpu_1.3_la-barrier_counter.lo
    CC     libstarpu_1.3_la-bitmap.lo
    CC     libstarpu_1.3_la-hash.lo
    CC     libstarpu_1.3_la-rwlock.lo
    CC     libstarpu_1.3_la-starpu_spinlock.lo
    CC     libstarpu_1.3_la-timing.lo
    CC     libstarpu_1.3_la-utils.lo
    CC     libstarpu_1.3_la-fxt.lo
    CC     libstarpu_1.3_la-thread.lo
    CC     libstarpu_1.3_la-rbtree.lo
    CC     libstarpu_1.3_la-graph.lo
    CC     libstarpu_1.3_la-jobs.lo
    CC     libstarpu_1.3_la-task.lo
    CC     libstarpu_1.3_la-task_bundle.lo
    CC     libstarpu_1.3_la-tree.lo
  common/fxt.c: In function ‚Äò_starpu_profile_set_tracefile‚Äô:
  common/fxt.c:86:2: error: implicit declaration of function ‚Äòvnsprintf‚Äô [-Werror=implicit-function-declaration]
  cc1: some warnings being treated as errors
  make[2]: *** [libstarpu_1.3_la-fxt.lo] Error 1
  make[2]: *** Waiting for unfinished jobs....
  make[2]: Leaving directory `/tmp/root/spack-stage/spack-stage-Bqd_mp/trunk/src'
  make[1]: *** [all-recursive] Error 1
  make[1]: Leaving directory `/tmp/root/spack-stage/spack-stage-Bqd_mp/trunk/src'
  make: *** [all-recursive] Error 1
  #+end_example

  Solution : rajouter le flag *-posix* au compilateur C : 

  #+begin_src sh :session foo :results output :exports both 
  spack install -v chameleon@trunk~quark+simu+examples+fxt+starpu cflags=\"-posix\" ^starpu@svn-trunk+simgrid+fxt ^simgrid@starpumpi
  #+end_src

  #+RESULTS:
  #+begin_example
  /tmp/root/spack-stage/spack-stage-NiynFP/cmake-3.5.2/Source/kwsys/ProcessUNIX.c:189:53: error: unknown type name ‚Äòsiginfo_t‚Äô
  /tmp/root/spack-stage/spack-stage-NiynFP/cmake-3.5.2/Source/kwsys/ProcessUNIX.c: In function ‚ÄòcmsysProcess_AddCommand‚Äô:
  /tmp/root/spack-stage/spack-stage-NiynFP/cmake-3.5.2/Source/kwsys/ProcessUNIX.c:469:46: warning: incompatible implicit declaration of built-in function ‚Äòstrdup‚Äô [enabled by default]
  /tmp/root/spack-stage/spack-stage-NiynFP/cmake-3.5.2/Source/kwsys/ProcessUNIX.c: In function ‚ÄòkwsysProcessKill‚Äô:
  /tmp/root/spack-stage/spack-stage-NiynFP/cmake-3.5.2/Source/kwsys/ProcessUNIX.c:2687:16: warning: initialization makes pointer from integer without a cast [enabled by default]
  /tmp/root/spack-stage/spack-stage-NiynFP/cmake-3.5.2/Source/kwsys/ProcessUNIX.c: In function ‚ÄòkwsysProcessesAdd‚Äô:
  /tmp/root/spack-stage/spack-stage-NiynFP/cmake-3.5.2/Source/kwsys/ProcessUNIX.c:2861:17: error: ‚Äòstruct sigaction‚Äô has no member named ‚Äòsa_sigaction‚Äô
  /tmp/root/spack-stage/spack-stage-NiynFP/cmake-3.5.2/Source/kwsys/ProcessUNIX.c:2861:33: error: ‚ÄòkwsysProcessesSignalHandler‚Äô undeclared (first use in this function)
  /tmp/root/spack-stage/spack-stage-NiynFP/cmake-3.5.2/Source/kwsys/ProcessUNIX.c:2861:33: note: each undeclared identifier is reported only once for each function it appears in
  /tmp/root/spack-stage/spack-stage-NiynFP/cmake-3.5.2/Source/kwsys/ProcessUNIX.c: At top level:
  /tmp/root/spack-stage/spack-stage-NiynFP/cmake-3.5.2/Source/kwsys/ProcessUNIX.c:2950:43: error: unknown type name ‚Äòsiginfo_t‚Äô
  #+end_example

  Solution : rajouter le flag *-D_POSIX_C_SOURCE=200112L* (le flag
  -posix n'est plus n√©cessaire)
  http://stackoverflow.com/questions/22912674/unknown-type-name-siginfo-t-with-clang-using-posix-c-source-2-why
  
  Autre erreur de d√©claration implicite (je ne vais pas toutes les noter).

  Solution : rajouter le flag *-D_GNU_SOURCE*

  #+begin_src sh :session foo :results output :exports both 
  spack install -v chameleon@trunk~quark+simu+examples+fxt+starpu cflags=\"-D_POSIX_C_SOURCE=200112L -D_GNU_SOURCE\" ^starpu@svn-trunk+simgrid+fxt ^simgrid@starpumpi
  #+end_src

  #+RESULTS:
  #+begin_example
  core/perfmodel/perfmodel_history.c: In function ‚Äò_starpu_perfmodel_realloc‚Äô:
  core/perfmodel/perfmodel_history.c:662:2: error: ‚ÄòLONG_MAX‚Äô undeclared (first use in this function)
  core/perfmodel/perfmodel_history.c:662:2: note: each undeclared identifier is reported only once for each function it appears in
  make[2]: *** [libstarpu_1.3_la-perfmodel_history.lo] Error 1
  make[2]: *** Waiting for unfinished jobs....
  make[2]: Leaving directory `/tmp/root/spack-stage/spack-stage-AAkAxm/trunk/src'
  make[1]: *** [all-recursive] Error 1
  make[1]: Leaving directory `/tmp/root/spack-stage/spack-stage-AAkAxm/trunk/src'
  make: *** [all-recursive] Error 1
  #+end_example

  Solution : rajouter le flag *-include limits.h*

  #+begin_src sh :session foo :results output :exports both 
  spack install -v chameleon@trunk~quark+simu+examples+fxt+starpu cflags=\"-D_POSIX_C_SOURCE=200112L -D_GNU_SOURCE -include limits.h\" ^starpu@svn-trunk+simgrid+fxt ^simgrid@starpumpi
  #+end_src

  #+RESULTS:
  #+begin_example
  CMake Error at tools/cmake/CompleteInFiles.cmake:117 (message):
  Failed to find Boost libraries.Did you install libboost-dev and
  libboost-context-dev?(libboost-context-dev is optional)
  #+end_example

** R√©capitulatif
   #+begin_src sh :session foo :results output :exports both 
   ssh grenoble.g5k
   ssh digitalis
   oarsub -I -t deploy
   kadeploy3 -f $OAR_NODE_FILE -a image.env -k

   ssh root@node
   export SPACK_ROOT=~/spack/
   export PATH=$SPACK_ROOT/bin:$PATH
   spack install -v chameleon@trunk~quark+simu+examples+fxt+starpu cflags=\"-D_POSIX_C_SOURCE=200112L -D_GNU_SOURCE -include limits.h\" ^starpu@svn-trunk+simgrid+fxt ^simgrid@starpumpi
   #+end_src

   + r√©solution *spec* -> *dep_spec*
* Lundi 20/06
  Florent Pruvost : la branche est instable. Cette commande fonctionne + report d'un bug dans Spack
  #+begin_src sh :session foo :results output :exports both 
  spack install -v chameleon@trunk+starpu+fxt+simu+mpi ^simgrid@starpumpi
  #+end_src

  Lancement des premi√®res simulations avec StarPU -> toutes fausses :)

  Image actuelle trop "sale", cr√©ation d'une nouvelle image, exclusivement pour la simulation,
  avec le nouveau pull de Spack

  Pour le hash : =chameleon-trunk-b7vkqkzpqff7jhw4v76hmcnh7wxvqfp7=
  Lancement des simulations -> segmentation fault..
  
  Nouvelle installation :
  #+begin_src sh :session foo :results output :exports both 
  spack install -v chameleon@trunk+starpu+fxt+simu+mpi ^simgrid@starpumpi ^starpu@svn-trunk+simgrid+fxt
  #+end_src
  -> probl√®me d'installation

  Nouvelle installation (tir√©e de ce qui a √©t√© fait Vendredi 17/06) :
  #+begin_src sh :session foo :results output :exports both 
  spack install -v chameleon@trunk+simu+fxt+starpu cflags=\"-D_POSIX_C_SOURCE=200112L -D_GNU_SOURCE -include limits.h\" ^starpu@svn-trunk+simgrid+fxt ^simgrid@starpumpi
  #+end_src

  Pour le hash : =chameleon-trunk-4iyjznfgw6drrrgli47trrjadryxs72e=
  Lancement des simulations -> segmentation fault..

  Installation de la version non simul√©e :
  #+begin_src sh :session foo :results output :exports both 
  spack install -v chameleon@trunk+starpu+fxt ^starpu@svn-trunk+fxt
  #+end_src

  Hash correspondant : =chameleon-trunk-gj5brkq45hyoavckcdaxtcpz3hjdlxmd=
  
  Cette version marche.

  Bilan : la simulation ne marche pas, des d√©viations tr√®s importantes
  (voir le warning) pour le mode non simul√© -> quoiqu'il en soit
  l'installation avec Spack est ma√Ætris√©e

  #+RESULTS:
  #+begin_example
  ./timing/time_spotrf_tile --warmup --gpus=3 --threads=9 --nb=960 --ib=96 --n_range=48000:48000:9600
  [starpu][starpu_initialize] Warning: StarPU was configured with --with-fxt, which slows down a bit
  [starpu][_starpu_bind_thread_on_cpu] Warning: both workers 0 and 8 are bound to the same PU 0, this will strongly degrade performance
  #
  # CHAMELEON 0.9.1, ./timing/time_spotrf_tile
  # Nb threads: 9
  # Nb GPUs:    3
  # NB:         960
  # IB:         96
  # eps:        5.960464e-08
  #
  #     M       N  K/NRHS   seconds   Gflop/s Deviation
    48000   48000       1 [starpu][_starpu_update_perfmodel_history] Too big deviation for model splgsy on cpu0_impl0 (Comb0): 17470.704000 vs average 11059.039143, 7 such errors against 7 samples (+57.976690%), flushing the performance model. Use the STARPU_HISTORY_MAX_ERROR environement variable to control the threshold (currently 50%)
  [starpu][_starpu_update_perfmodel_history] Too big deviation for model splgsy on cpu0_impl0 (Comb0): 10813.469000 vs average 18872.197000, 1 such errors against 1 samples (-42.701589%), flushing the performance model. Use the STARPU_HISTORY_MAX_ERROR environement variable to control the threshold (currently 50%)
  [starpu][_starpu_update_perfmodel_history] Too big deviation for model splgsy on cpu0_impl0 (Comb0): 21952.844000 vs average 11692.761069, 29 such errors against 29 samples (+87.747307%), flushing the performance model. Use the STARPU_HISTORY_MAX_ERROR environement variable to control the threshold (currently 50%)
  [starpu][_starpu_update_perfmodel_history] Too big deviation for model splgsy on cpu0_impl0 (Comb0): 9965.069000 vs average 22145.963190, 79 such errors against 79 samples (-55.002774%), flushing the performance model. Use the STARPU_HISTORY_MAX_ERROR environement variable to control the threshold (currently 50%)
  [starpu][_starpu_update_perfmodel_history] Too big deviation for model strsm on cpu0_impl0 (Comb0): 51143.533000 vs average 82083.798857, 7 such errors against 7 samples (-37.693511%), flushing the performance model. Use the STARPU_HISTORY_MAX_ERROR environement variable to control the threshold (currently 50%)
    242.332    152.13 +-   0.00  

  #---------------------
  Worker stats:
  CPU 0                           
  	3335 task(s)
  CPU 1                           
  	6089 task(s)
  CPU 2                           
  	6095 task(s)
  CPU 3                           
  	6072 task(s)
  CPU 4                           
  	6067 task(s)
  CPU 5                           
  	6089 task(s)
  CPU 6                           
  	6073 task(s)
  CPU 7                           
  	6062 task(s)
  CPU 8                           
  	3318 task(s)
  #---------------------
  #+end_example

** A faire
   Installer Kameleon et int√©grer Spack √† Kameleon (lancer les
   commandes Spack depuis Kameleon)
   
* Mardi 21/06							   :Kameleon:
  Pr√©paration d'une image pour d√©ploiement sur Grid5000

  Rappel sur l'installation de Kameleon :

  #+begin_src sh :session foo :results output :exports both
  apt-get install ruby-dev ruby-childprocess polipo libguestfs-tools
  gem install --no-ri --no-rdoc kameleon-builder
  
  kameleon template repo add default https://github.com/oar-team/kameleon-recipes.git
  #+end_src

  Cr√©ation d'un custom recipe pour grid5000 :
  
  #+begin_src sh :session foo :results output :exports both 
  kameleon new debian8_g5k default/grid5000/debian8
  #+end_src
  
  Premier d√©ploiement d'une sur Grid5000 avec Kameleon : le recipe
  =default/grid5000/debian8.yaml= se charge de d√©ployer lors du build

  Probl√®me avec Git :

  #+begin_src sh :session foo :results output :exports both 
  Step 24 : setup/first_step/spack
  --> Running the step...
  [in] Cloning into 'spack'...
  [in] fatal: Not a git repository (or any of the parent directories): .git
  Starting command: "bash"
  Starting command: "ssh -A -t -F /home/florian/Bureau/Kameleon/build/debian8_g5k/ssh_config grenoble /bin/bash"
  Starting command: "ssh -A -t -F /home/florian/Bureau/Kameleon/build/debian8_g5k/ssh_config debian8_g5k /bin/bash"
  Error occured when executing the following command :

  > exec_in: git checkout morse
  #+end_src

  Source du probl√®me : la commande =cd= ne fonctionne pas, ni =export= ->
  faire autrement

  Solution (Michael) : exporter la variable du contexte =out= vers =in= ou
  bien utiliser un fichier intermediaire
  
  Pour =cd= : grouper les comandes dans le =exec_in= avec =|= (voir cheat
  sheet yaml pour se familiariser avec la syntaxe :
  http://lzone.de/cheat-sheet/YAML). Le directory courant est remis √†
  sa position initial entre chaque =exec_in=. 
* Jeudi 23/06
  Int√©gration de Spack √† Kameleon.
