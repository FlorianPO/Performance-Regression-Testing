#+TAGS: Phoronix(P) Pypy(Y) Jenkins(J) CollectiveMind(C)
#+TAGS: XPFlow(C) Expo(A) Execo(B) 
#+TAGS: Spack(S) Kameleon(K)

* Jeudi 19/05
  - Installation de D√©bian8 avec Vincent Danjean
  - Mise en place de l'environnement de travail (quelques raccourcis
    qui me sont chers, des marque-pages, un Git:
    https://github.com/FlorianPO/Performance-Regression-Testing)
  - Il faut que je fournisse mon adresse MAC √† Christian afin d'avoir
    Internet en filaire (tr√®s peu de Wifi dans la salle)
  - Prise en main de Org-mode sous emacs
* Lundi 23/05				    :Phoronix:Jenkins:CollectiveMind:
  - [[file:Overviews/Phoronix.org][Overview de Phoronix]] : d√©pendant du mat√©riel, deux tests n'auront
    du sens que s'ils sont √©xecut√©s sur la /m√™me/ machine.
  - [[https://github.com/FlorianPO/Performance-Regression-Testing/blob/master/CollectiveMind.org][Overview de CollectiveMind]] : plus proche du sujet (ax√© recherche)
  - [[https://github.com/FlorianPO/Performance-Regression-Testing/blob/master/Jenkins.org][Overview de Jenkins]]

  Ces documents ne sont qu'une √©bauche, il conviendra √† l'avenir de
  s'int√©resser √† leur points communs/diff√©rences. En premi√®re
  approximation, les benchmarks propos√©s d√©pendent de la machine qui
  les a g√©n√©r√©s (√† l'exception de CollectiveMind qui semble
  s'int√©resser au probl√®me). N√©anmoins, ces trois plateformes sont des
  /usines √† gaz/, il reste encore √©norm√©ment √† d√©couvrir.
* Mardi 24/05
  - Uniformisation des .org. L'objectif est de comparer les 3
    plateformes sur le benchmarking.
  - Ajout d'un [[https://github.com/FlorianPO/Performance-Regression-Testing/blob/master/State_of_the_art.org][rapport]] /tr√®s bref/ sur l'√©tat de l'art. Il convient d'en
    discuter.
  - R√©union avec Arnaud Legrand : creuser les outils pour voir s'ils
    correspondent au besoin (benchmarks propres, possibilit√© de
    r√©cup√©rer les donn√©es pour une exploitation sp√©cifique, un peu de
    contr√¥le d'exp√©rience, technologie p√©renne). + utiliser Marker
    pour le journal.
  - S'occuper de Pypy, ...
  - Tester Phoronix
  - Installation de Phoronix Test Suite v6.2.1
* Mercredi 25/05						     :ATTACH:
** Phoronix							   :Phoronix:
 :PROPERTIES:
  :Attachments: FirstTest.png SecondTest.png
  :ID:       d5f63874-eef8-49c2-b544-2f7391cd499d
  :END:
   + Premier test avec Phoronix -> rbenchmark -> failed to run properly
   + Deuxi√®me test avec Phoronix -> 7zip compression -> ok
   + Pr√©sence de tests multicoeurs
   + L'injection de charges semble possible (see Fulldoc : "stressing
     your system with random workloads") m√™me si ce n'est pas
     l'objectif premier (cf- Vincent)
   + Possibilit√© d'exporter les donn√©es collect√©es
   + L'interface semble simple √† utiliser (m√™me si je n'y suis pas
     arriv√© (pour le moment))
   + S'int√©resser aux tests eux-m√™me (comment les √©crire, etc...)
** Pypy								       :Pypy:
   http://speed.pypy.org/timeline/#/?exe=3,6,1,5&base=2+472&ben=ai&env=1&revs=200&equid=off
   + Fait avec Django (Framework Web python) et Codespeed (Web
     benchmark application) -> √† regarder, semble int√©ressant !
   + Code des benchmarks :
     https://bitbucket.org/pypy/benchmarks/src/846fa56a282b/unladen_swallow/performance/
    
* Jeudi 26/05							       
** Codespeed							       :Pypy:
   https://github.com/tobami/codespeed
   - Probl√®me d'installation (Python invalid syntax (?))
   - La commande magique : =python ./manage.py syncdb --migrate=
   - Serveur lanc√© : probl√®me d'authentification cependant
   - Il faut cr√©er un super-utilisateur : =python manage.py
     createsuperuser=
   - Lancer le serveur en _sudo_ : =sudo python manage.py runserver 8000=
   - Fournir Codespeed en donn√©es : "Codespeed is a web application to
     monitor and analyze the performance of your code" -> seulement de
     la visualisation de donn√©es
** Phoronix 							   :Phoronix:
   R√©sultats des tests dans
   =~/.phoronix-test-suite/test-results/<TEST>/= :
     - =composite.xml= :: : plan d'exp√©rience
     - =system-logs/= :: : 2 tonnes de donn√©es collect√©es
   M√©ta-donn√©es des tests (par d√©fault) dans
   =~/.phoronix-test-suite/test-profiles/pts/<TEST>/=

* Vendredi 27/05
** Phoronix							   :Phoronix:
   - Ecriture d'un bubble sort en python pour tester Phoronix,
     t√©l√©chargeable √†
     https://github.com/FlorianPO/Performance-Regression-Testing/raw/master/bubble_sort.py.tar.gz
   - Ecriture des m√©ta-donn√©es du test (√† tester, ne marchera s√ªrement
     pas du premier coup)
*** Bubble sort TEST
    - placer le test dans :
      =~/.phoronix-test-suite/test-profiles/local/<TEST>/= (celui-ci
      devrait √™tre visible par la commande =phoronix-test-suite
      list-available-tests=
    - il faut g√©n√©rer un checksum MD5 de l'archive √† t√©l√©charger :
      =md5sum <FILE>= (√† placer dans =download.xml=)
    - probl√®me d'√©xecutable :
      - le script g√©n√©r√© dans install.sh doit avoir le m√™me nom
        =<TEST-NAME>= que le dossier du test =local/<TEST-NAME>=
* Lundi 30/05
** Phoronix							   :Phoronix:
   - Output template : la sortie du programme semble devoir
     correspondre √† l'OutputTemplate dans =results-definition.xml=
   - Update : la correspondance doit √™tre exacte (sauf certains cas
     (ex: en C les retours chariot semble ignor√©s), √† √©tudier...)
   - https://www.phoronix.com/forums/forum/phoronix/phoronix-test-suite/46913-custom-benchmark
*** Multiple results
    - Multiplier les champs =OutputTemplate= dans =results-definition.xml= ne suffit pas...
    - Ce n'est pas possible...
    - Regarder dans le code source -> hardcore
** Autres pistes
   - Execo, XPFlow, Expo
   - Regarder Webinar n¬∞2 + √©tat de l'art de ces outils (voir slide)
     - Regard√© jusqu'√† 35 min (partie 6)
* Mardi 31/05
** Expo								       :Expo:
*** Intro
    It aims at simplifying the experimental process on such
    distributed platforms. Works with client / server.
    - Liens :
      + http://expo.gforge.inria.fr/
    - Pros :
      + Everything is logged : IO, commands, date, ...
*** Avancement
    - Installation de Ruby
    - Installation de gem2.1
    - Probl√®me de version : Expo et ses d√©pendances utilisent Ruby
      1.9.3 (current version : Ruby 2.3)
    - Installation de RVM pour installer / switcher Ruby 1.9.3
      + https://rvm.io/rvm/install 
      + http://stackoverflow.com/questions/9919739/how-to-use-the-older-version-of-ruby-1-9-2
      + Pour utiliser la commande =rvm= : =source
        /home/<USER>/.rvm/scripts/rvm= (<USER> : florian)
      + Pour switcher sur Ruby 1.9.3 : =rvm use ruby-1.9.3 --default=
    - Petit tuto Ruby : http://tryruby.org/levels/1/challenges/0
    - Impossible de lancer =./expo= -> probl√®me syntaxe -> passage en
      Ruby 2.3.1
      + IMPOSSIBLE, rien ne marche
      + Expo utilise Ruby 1.8.7 mais Restfully n√©cessite Ruby >= 1.9.3
** XPFlow							     :XPFlow:
*** Intro
    XPFlow is a new approach to description and execution of
    experiments involving large-scale computer installations. The main
    idea consists in describing the experiment as workflow and using
    achievements of Business Workflow Management to reliably and
    efficiently execute it. Moreover, to facilitate the design
    process, the framework provides abstractions that hide unnecessary
    complexity from the user.
    - Liens:
      + http://xpflow.gforge.inria.fr/
      + http://xpflow.gforge.inria.fr/img/slides/slides.pdf
	* http://xpflow.gforge.inria.fr/img/slides/slides.pdf
*** Avancement
    - Installation de XPFlow
    - Lecture des slides : pas d√©gueux du tout
    - Permet de lancer des commandes syst√®mes, etc...
    - Installation de =cairo= : =gem install cairo= (pour exporter en pdf)
      + permet de visualiser le workflow
    - A tester avec Grid5000 -> demande de compte faite.
** Execo							      :Execo:
*** Intro
    Execo is a Python library that allows you to finely manage unix
    processes on thousands of remote hosts. It is well designed for :
    - prototyping experiments on distributed systems (Grid5000
      support)
    - automatize admin tasks
    - create reproducible experiments
    - Liens :
      + http://execo.gforge.inria.fr/doc/latest-stable/
      + http://execo.gforge.inria.fr/doc/latest-stable/userguide.html
*** Avancement
    - Installation de Execo et de tous ses packages optionnels.
* Mercredi 01/06
** Execo							      :Execo:
  - Obtention d'un compte Grid5000
  - Lecture de la doc d'Execo
  - A faire : comparer Execo et XPFlow
** XPFlow							     :XPFlow:
   - Liste des patterns : http://xpflow.gforge.inria.fr/docs/patterns/ :
     super cool !
   - =git clone= du projet
   - Installation de LaTeX-mk pour g√©n√©rer la doc
   - Recherche de la structure du pattern =info= : classe InfoRun dans
     runs.rb (peu de choses...)
* Mardi 07/06
  - Visionnage des webinars 2 et 3
  - Contacter Olivier Richard et Michael Mercier au sujet de
    l'installation d'environnement. XPFlow m√©lange celui-ci et le
    contr√¥le de l'exp√©rience : pas une bonne id√©e.
* Mercredi 08/06
  - Installation de =emacs= sur Windows (=C-H v user-init-file RET= dans
    emacs pour trouver l'emplacement du fichier =.emacs=)  
  - Visionnage du webinar 1 + [[https://github.com/FlorianPO/Performance-Regression-Testing/blob/master/Webinar_1.org][prise de note]]
* Jeudi 09/06
  - Visionnage du webinar 2 + [[https://github.com/FlorianPO/Performance-Regression-Testing/blob/master/Webinar_2.org][prise de note]]
  - Docker for reproducible research :
    http://www.carlboettiger.info/assets/files/pubs/10.1145/2723872.2723882.pdf
  - SPACK + KAMELEON -> t√©l√©chargement (+ installation)
    - SPACK : Luka 
    - D√©pendances : Ven√¨cius
    - KAMELEON : Michael
  - (XPFlow) -> Contr√¥le de l'exp√©rience
* Vendredi 10/06
** Spack							      :Spack:
   Petits tutos sur le PATH pour se mettre √† niveau :
   - https://wiki.debian.org/EnvironmentVariables
   - http://www.generation-linux.fr/index.php?post/2008/10/15/Changer-les-dossiers-par-defaut-dans-le-PATH
   Installation de Spack
*** Liens :
    - Features :: http://software.llnl.gov/spack/features.html
    - Doc :: http://software.llnl.gov/spack/
    - Package installable ::
         http://software.llnl.gov/spack/basic_usage.html
** Kameleon							   :Kameleon:
   Installation de Kameleon
*** Liens :
    - Doc :: http://kameleon.imag.fr/index.html
* Lundi 13/06
** Kameleon							   :Kameleon:
   - Le tutoriel qui va bien :
     http://kameleon.imag.fr/grid5000_tutorial.html
   - Kameleon + Puppet :
     https://www.grid5000.fr/mediawiki/index.php/Environments_creation_using_Kameleon_and_Puppet
** Spack							      :Spack:
   - http://software.llnl.gov/spack/basic_usage.html
* Mardi 14/06
  - Lecture compl√®te de la doc de Kameleon : fait.
  - R√©union avec Michael et Arnaud :
    + Pr√©liminaires :      
      * Lire le /Getting started/ de G5k
        https://www.grid5000.fr/mediawiki/index.php/Getting_Started
      * D√©ployer une image, jouer avec les commandes, ...
      * Objectif : lancer au moins un benchmark StarPU Morse
        http://starpu.gforge.inria.fr/testing/morse/trunk/morse.html
    + Automatiser : 
      * Kameleon + Spack (pour les BLAS)
      * r√©cup√©rer sur Git StarPU / Morse
      * benchmark sur les versions (en mode r√©el ou simul√©)
	- mode simul√© : √©xecution des versions parall√®les (Execo
          peut-il faire ceci ? Voir avec Michael)
      * logger
** Grid5000 getting started
*** R√©servation
    - Dabord, la frontale :
      #+begin_src sh :session foo :results output :exports both 
      ssh fpopek@access.grid5000.fr
      #+end_src

      
      #+begin_example

      Linux access-south.grid5000.fr 3.2.0-4-amd64 #1 SMP Debian 3.2.73-2+deb7u3 x86_64
      ----- Grid'5000 - access-south.grid5000.fr -----

      Welcome to Grid'5000

      ** Connect to a site:
      ssh {grenoble,lille,luxembourg,lyon,nancy,nantes,reims,rennes}

      ** Useful links:
       - account management (password change): https://api.grid5000.fr/ui/account
       - homepage: https://www.grid5000.fr/mediawiki/index.php/Category:Portal:User
       - charter : https://www.grid5000.fr/mediawiki/index.php/Grid5000:UserCharter
       - support : https://www.grid5000.fr/mediawiki/index.php/Support

      ** Data on access.grid5000.fr :
       - your home directory on access machines (access-north and access-south)
	 is not synchronized and should not be use to store data.
       - please use ssh forwarding to send data directly to sites or
      scp files login@access.grid5000.fr:reims/ using the nfs mount point in your home

      [31m[5m
      ** Warning: 1 event in progress
      #Incident in #Sophia¬†: hard drive failures on srv.sophia.grid5000.fr, site unavailable
      [0m[31m    https://intranet.grid5000.fr/bugzilla/show_bug.cgi?id=6967
      [0m
      Last login: Tue Jun 14 14:39:37 2016 from 129.88.54.126
#+end_example

    - Puis grenoble :
      #+begin_src sh :session foo :results output :exports both 
      ssh grenoble
      #+end_src

      
      #+begin_example
      ----- Grid'5000 - Grenoble - fgrenoble.grenoble.grid5000.fr -----

      This site has 3 clusters (see: https://api.grid5000.fr/stable/ui/visualizations/nodes.html)

      Available in queue default:
       - genepi (2008): 34 nodes (2 CPUs Intel Xeon E5420, 4 cores/CPU, 8GB RAM, 153GB HDD)
       - edel   (2008): 72 nodes (2 CPUs Intel Xeon E5520, 4 cores/CPU, 24GB RAM, 119GB SSD)
       - adonis (2010): 10 nodes (2 CPUs Intel Xeon E5520, 4 cores/CPU, 24GB RAM, 233GB HDD)

      ** Useful links:
       - account management (password change): https://api.grid5000.fr/ui/account
       - homepage: https://www.grid5000.fr/mediawiki/index.php/Category:Portal:User
       - charter : https://www.grid5000.fr/mediawiki/index.php/Grid5000:UserCharter
       - support : https://www.grid5000.fr/mediawiki/index.php/Support

      ** Others sites:
      ssh {lille,luxembourg,lyon,nancy,nantes,reims,rennes,sophia}

      Last login: Tue Jun 14 14:40:46 2016 from access-south.grid5000.fr
#+end_example

    - =oarsub -I= pour r√©server une machine en mode interactif
    - Pour r√©server 2 noeuds pendant 30 min :
      #+begin_src sh :session foo :results output :exports both 
      oarsub -I -l nodes=2,walltime=0:30 
      #+end_src

    - Pour r√©server dans le futur
      #+begin_src sh :session foo :results output :exports both 
      oarsub -I -r '2012-12-23 16:30:00'
      #+end_src

      + =oarstat= pour voir l'historique des r√©servations
      + =oarstat -u= pour voir ses r√©servations
      + =oarstat -r <JOB_ID>= pour supprimer une r√©servation
    - Propri√©t√©s OAR
      #+begin_src sh :session foo :results output :exports both 
      oarsub -p "gpu='YES'"
      #+end_src

    - =oarsub -t deploy= pour d√©ployer avec Kadeploy (/The root password
      for all Grid'5000-provided images is grid5000/)
*** Gestion des noeuds
    - =uniq $OAR_NODEFILE= liste des noeuds r√©serv√©s
    - =oarsh <NODE>= utiliser un noeud r√©serv√©
    - =ssh root@<NODE>= se connecter en root sur un noeud
** Spack
   Installation :
   - =git clone https://github.com/llnl/spack.git=
   - =export PATH=$SPACK_ROOT/bin:$PATH=
   - =spack install libelf=
** StarPU
*** Installation avec Spack
    http://morse.gforge.inria.fr/chameleon/tuto_chameleon/chameleon-tutorial-2015-12-16-inria.html#sec-6-2
*** En pratique (buggu√©, voir le lendemain)
    D√©ploiement

    #+begin_src sh :session foo :results output :exports both 
    ssh grenoble.g5k (ou ssh fpopek@access.grid5000.fr puis ssh grenoble)
    ssh digitalis
    oarsub -I -t deploy
    kadeploy3 -f $OAR_NODE_FILE -e jessie-x64-big -k (probl√®me avec Digitalis)
    ssh root@machine
    #+end_src
    
    Installation de Spack
    
    #+begin_src sh :session foo :results output :exports both 
    git clone https://github.com/fpruvost/spack
    export SPACK_ROOT=~/spack/
    export PATH=$SPACK_ROOT/bin:$PATH
    #+end_src
      
    Morse package
    
    #+begin_src sh :session foo :results output :exports both 
    cd spack
    git checkout morse
    #+end_src
    
    Installation de Chameleon

    #+begin_src sh :session foo :results output :exports both 
    spack install chameleon+examples
    #+end_src

    Installation de StarPU

    #+begin_src sh :session foo :results output :exports both 
    spack install -v chameleon@trunk~quark+examples+fxt ^starpu@svn-trunk+fxt
    spack install -v chameleon@trunk~quark+simu+examples+fxt ^starpu@svn-trunk+simgrid+fxt ^simgrid@starpumpi (pour la simulation)

    ( spack install -v chameleon@trunk~quark+examples+fxt )
    #+end_src
* Mercredi 15/06
  - Ma version de Spack ne permet pas d'installer StarPu (0.9.1) celle
  de Vin√¨cius (0.8.15) marche
  - Probl√®me d'import Python -> r√©cup√©ration de l'image de Vin√¨cius
  - Probl√®me de Spack -> envoie d'un mail √† Lucas
** Environnement de Vin√¨cius
   #+begin_src sh :session foo :results output :exports both 
   ssh grenoble.g5k
   ssh digitalis
   oarsub -I -t deploy
   kadeploy3 -f $OAR_NODE_FILE -a imageIDCin.env -k
   #+end_src
  
   Image copi√©e depuis =/home/vgarciapinto/= (avec modification de
   imageIDCin.env avec mon login)

   #+begin_src sh :session foo :results output :exports both 
   ssh root@machine
   sudo apt-get update
   sudo apt-get install -y python2.7-dev
   sudo apt-get install -y vim emacs
   sudo apt-get install -y curl patch
   sudo apt-get install -y git subversion mercurial
   sudo apt-get install -y build-essential gfortran
   sudo apt-get install -y autoconf automake cmake cmake-data doxygen texinfo
   sudo apt-get install -y libtool (libtool-bin)
   sudo apt-get install -y libboost-dev
   sudo apt-get install -y gawk
   sudo apt-get install -y bison flex
   sudo apt-get install -y binutils-dev libelf-dev (libiberty-dev)
   sudo apt-get install -y libz-dev
   sudo apt-get install -y libqt4-dev freeglut3-dev
   sudo apt-get install -y environment-modules
   #+end_src

   #+begin_src sh :session foo :results output :exports both 
   git clone https://github.com/fpruvost/spack
   export SPACK_ROOT=~/spack/
   export PATH=$SPACK_ROOT/bin:$PATH
   #+end_src

   #+begin_src sh :session foo :results output :exports both 
   cd spack/
   git checkout morse
   #+end_src

   La branche morse peut (sous quelles conditions ?) ne pas marcher :

   
   #+begin_example
   Traceback (most recent call last):
     File "/root/spack//bin/spack", line 50, in <module>
       import nose
     File "/root/spack/lib/spack/external/nose/__init__.py", line 1, in <module>
       from nose.core import collector, main, run, run_exit, runmodule
     File "/root/spack/lib/spack/external/nose/core.py", line 9, in <module>
      import unittest
     File "/usr/lib/python2.7/unittest/__init__.py", line 58, in <module>
      from .result import TestResult
     File "/usr/lib/python2.7/unittest/result.py", line 10, in <module>
      from functools import wraps
   ImportError: cannot import name wraps
   #+end_example

   (semble optionnel)
   #+begin_src sh :session foo :results output :exports both 
   spack install chameleon
   #+end_src

   #+begin_src sh :session foo :results output :exports both 
   spack install chameleon~quark+fxt+starpu ^starpu+fxt
   #+end_src

   ==> Error: chameleon does not depend on starpu
* Vendredi 17/06
  Enregistrement d'une nouvelle image contenant Chameleon et Starpu (+
  toutes les d√©pendances n√©cessaires)

  #+begin_src sh :session foo :results output :exports both 
  ssh grenoble.g5k
  ssh digitalis
  oarsub -I -t deploy
  kadeploy3 -f $OAR_NODE_FILE -a image.env -k
  #+end_src

  Rappel de l'objectif : lancer un benchmark 
  http://starpu.gforge.inria.fr/testing/morse/trunk/morse.html

  #+begin_src sh :session foo :results output :exports both 
  export SPACK_ROOT=~/spack/
  export PATH=$SPACK_ROOT/bin:$PATH
  spack install -v chameleon@trunk~quark+simu+examples+fxt+starpu ^starpu@svn-trunk+simgrid+fxt ^simgrid@starpumpi (pour la simulationg, ne marche pas)
  #+end_src

  
  #+begin_example
  ==> Successfully installed simgrid
  Fetch: 11.83s.  Build: 45.30s.  Total: 57.12s.
  [+] /root/spack/opt/spack/linux-x86_64/gcc-4.7/simgrid-starpumpi-tosagznhajv6jgnrtesrrzuhppizpmp3
  Traceback (most recent call last):
    File "/root/spack//bin/spack", line 176, in <module>
      main()
    File "/root/spack//bin/spack", line 154, in main
      return_val = command(parser, args)
    File "/root/spack/lib/spack/spack/cmd/install.py", line 82, in install
      explicit=True)
    File "/root/spack/lib/spack/spack/package.py", line 927, in do_install
      make_jobs=make_jobs)
    File "/root/spack/lib/spack/spack/package.py", line 1051, in do_install_dependencies
      dep.package.do_install(**kwargs)
    File "/root/spack/lib/spack/spack/package.py", line 1008, in do_install
      spack.build_environment.fork(self, build_process)
    File "/root/spack/lib/spack/spack/build_environment.py", line 402, in fork
      setup_package(pkg)
    File "/root/spack/lib/spack/spack/build_environment.py", line 360, in setup_package
      dpkg.setup_dependent_package(pkg.module, spec)
    File "/root/spack/var/spack/repos/builtin/packages/simgrid/package.py", line 37, in setup_dependent_package
      if spec.satisfies('+smpi'):
  NameError: global name 'spec' is not defined
  ==> Error: Installation process had nonzero exit code.
  #+end_example

  Solution : remplacer =spec= par =dep_spec=

  
  #+begin_example
  ==> 'make' '-j16'
  Making all in src
  make[1]: Entering directory `/tmp/root/spack-stage/spack-stage-Bqd_mp/trunk/src'
  make[2]: Entering directory `/tmp/root/spack-stage/spack-stage-Bqd_mp/trunk/src'
    CC     libstarpu_1.3_la-barrier.lo
    CC     libstarpu_1.3_la-barrier_counter.lo
    CC     libstarpu_1.3_la-bitmap.lo
    CC     libstarpu_1.3_la-hash.lo
    CC     libstarpu_1.3_la-rwlock.lo
    CC     libstarpu_1.3_la-starpu_spinlock.lo
    CC     libstarpu_1.3_la-timing.lo
    CC     libstarpu_1.3_la-utils.lo
    CC     libstarpu_1.3_la-fxt.lo
    CC     libstarpu_1.3_la-thread.lo
    CC     libstarpu_1.3_la-rbtree.lo
    CC     libstarpu_1.3_la-graph.lo
    CC     libstarpu_1.3_la-jobs.lo
    CC     libstarpu_1.3_la-task.lo
    CC     libstarpu_1.3_la-task_bundle.lo
    CC     libstarpu_1.3_la-tree.lo
  common/fxt.c: In function ‚Äò_starpu_profile_set_tracefile‚Äô:
  common/fxt.c:86:2: error: implicit declaration of function ‚Äòvnsprintf‚Äô [-Werror=implicit-function-declaration]
  cc1: some warnings being treated as errors
  make[2]: *** [libstarpu_1.3_la-fxt.lo] Error 1
  make[2]: *** Waiting for unfinished jobs....
  make[2]: Leaving directory `/tmp/root/spack-stage/spack-stage-Bqd_mp/trunk/src'
  make[1]: *** [all-recursive] Error 1
  make[1]: Leaving directory `/tmp/root/spack-stage/spack-stage-Bqd_mp/trunk/src'
  make: *** [all-recursive] Error 1
  #+end_example

  Solution : rajouter le flag *-posix* au compilateur C : 

  #+begin_src sh :session foo :results output :exports both 
  spack install -v chameleon@trunk~quark+simu+examples+fxt+starpu cflags=\"-posix\" ^starpu@svn-trunk+simgrid+fxt ^simgrid@starpumpi
  #+end_src

  
  #+begin_example
  /tmp/root/spack-stage/spack-stage-NiynFP/cmake-3.5.2/Source/kwsys/ProcessUNIX.c:189:53: error: unknown type name ‚Äòsiginfo_t‚Äô
  /tmp/root/spack-stage/spack-stage-NiynFP/cmake-3.5.2/Source/kwsys/ProcessUNIX.c: In function ‚ÄòcmsysProcess_AddCommand‚Äô:
  /tmp/root/spack-stage/spack-stage-NiynFP/cmake-3.5.2/Source/kwsys/ProcessUNIX.c:469:46: warning: incompatible implicit declaration of built-in function ‚Äòstrdup‚Äô [enabled by default]
  /tmp/root/spack-stage/spack-stage-NiynFP/cmake-3.5.2/Source/kwsys/ProcessUNIX.c: In function ‚ÄòkwsysProcessKill‚Äô:
  /tmp/root/spack-stage/spack-stage-NiynFP/cmake-3.5.2/Source/kwsys/ProcessUNIX.c:2687:16: warning: initialization makes pointer from integer without a cast [enabled by default]
  /tmp/root/spack-stage/spack-stage-NiynFP/cmake-3.5.2/Source/kwsys/ProcessUNIX.c: In function ‚ÄòkwsysProcessesAdd‚Äô:
  /tmp/root/spack-stage/spack-stage-NiynFP/cmake-3.5.2/Source/kwsys/ProcessUNIX.c:2861:17: error: ‚Äòstruct sigaction‚Äô has no member named ‚Äòsa_sigaction‚Äô
  /tmp/root/spack-stage/spack-stage-NiynFP/cmake-3.5.2/Source/kwsys/ProcessUNIX.c:2861:33: error: ‚ÄòkwsysProcessesSignalHandler‚Äô undeclared (first use in this function)
  /tmp/root/spack-stage/spack-stage-NiynFP/cmake-3.5.2/Source/kwsys/ProcessUNIX.c:2861:33: note: each undeclared identifier is reported only once for each function it appears in
  /tmp/root/spack-stage/spack-stage-NiynFP/cmake-3.5.2/Source/kwsys/ProcessUNIX.c: At top level:
  /tmp/root/spack-stage/spack-stage-NiynFP/cmake-3.5.2/Source/kwsys/ProcessUNIX.c:2950:43: error: unknown type name ‚Äòsiginfo_t‚Äô
  #+end_example

  Solution : rajouter le flag *-D_POSIX_C_SOURCE=200112L* (le flag
  -posix n'est plus n√©cessaire)
  http://stackoverflow.com/questions/22912674/unknown-type-name-siginfo-t-with-clang-using-posix-c-source-2-why
  
  Autre erreur de d√©claration implicite (je ne vais pas toutes les noter).

  Solution : rajouter le flag *-D_GNU_SOURCE*

  #+begin_src sh :session foo :results output :exports both 
  spack install -v chameleon@trunk~quark+simu+examples+fxt+starpu cflags=\"-D_POSIX_C_SOURCE=200112L -D_GNU_SOURCE\" ^starpu@svn-trunk+simgrid+fxt ^simgrid@starpumpi
  #+end_src

  
  #+begin_example
  core/perfmodel/perfmodel_history.c: In function ‚Äò_starpu_perfmodel_realloc‚Äô:
  core/perfmodel/perfmodel_history.c:662:2: error: ‚ÄòLONG_MAX‚Äô undeclared (first use in this function)
  core/perfmodel/perfmodel_history.c:662:2: note: each undeclared identifier is reported only once for each function it appears in
  make[2]: *** [libstarpu_1.3_la-perfmodel_history.lo] Error 1
  make[2]: *** Waiting for unfinished jobs....
  make[2]: Leaving directory `/tmp/root/spack-stage/spack-stage-AAkAxm/trunk/src'
  make[1]: *** [all-recursive] Error 1
  make[1]: Leaving directory `/tmp/root/spack-stage/spack-stage-AAkAxm/trunk/src'
  make: *** [all-recursive] Error 1
  #+end_example

  Solution : rajouter le flag *-include limits.h*

  #+begin_src sh :session foo :results output :exports both 
  spack install -v chameleon@trunk~quark+simu+examples+fxt+starpu cflags=\"-D_POSIX_C_SOURCE=200112L -D_GNU_SOURCE -include limits.h\" ^starpu@svn-trunk+simgrid+fxt ^simgrid@starpumpi
  #+end_src

  
  #+begin_example
  CMake Error at tools/cmake/CompleteInFiles.cmake:117 (message):
  Failed to find Boost libraries.Did you install libboost-dev and
  libboost-context-dev?(libboost-context-dev is optional)
  #+end_example

** R√©capitulatif
   #+begin_src sh :session foo :results output :exports both 
   ssh grenoble.g5k
   ssh digitalis
   oarsub -I -t deploy
   kadeploy3 -f $OAR_NODE_FILE -a image.env -k

   ssh root@node
   export SPACK_ROOT=~/spack/
   export PATH=$SPACK_ROOT/bin:$PATH
   spack install -v chameleon@trunk~quark+simu+examples+fxt+starpu cflags=\"-D_POSIX_C_SOURCE=200112L -D_GNU_SOURCE -include limits.h\" ^starpu@svn-trunk+simgrid+fxt ^simgrid@starpumpi
   #+end_src

   + r√©solution *spec* -> *dep_spec*
* Lundi 20/06
  Florent Pruvost : la branche est instable. Cette commande fonctionne + report d'un bug dans Spack
  #+begin_src sh :session foo :results output :exports both 
  spack install -v chameleon@trunk+starpu+fxt+simu+mpi ^simgrid@starpumpi
  #+end_src

  Lancement des premi√®res simulations avec StarPU -> toutes fausses :)

  Image actuelle trop "sale", cr√©ation d'une nouvelle image, exclusivement pour la simulation,
  avec le nouveau pull de Spack

  Pour le hash : =chameleon-trunk-b7vkqkzpqff7jhw4v76hmcnh7wxvqfp7=
  Lancement des simulations -> segmentation fault..
  
  Nouvelle installation :
  #+begin_src sh :session foo :results output :exports both 
  spack install -v chameleon@trunk+starpu+fxt+simu+mpi ^simgrid@starpumpi ^starpu@svn-trunk+simgrid+fxt
  #+end_src
  -> probl√®me d'installation

  Nouvelle installation (tir√©e de ce qui a √©t√© fait Vendredi 17/06) :
  #+begin_src sh :session foo :results output :exports both 
  spack install -v chameleon@trunk+simu+fxt+starpu cflags=\"-D_POSIX_C_SOURCE=200112L -D_GNU_SOURCE -include limits.h\" ^starpu@svn-trunk+simgrid+fxt ^simgrid@starpumpi
  #+end_src

  Pour le hash : =chameleon-trunk-4iyjznfgw6drrrgli47trrjadryxs72e=
  Lancement des simulations -> segmentation fault..

  Installation de la version non simul√©e :
  #+begin_src sh :session foo :results output :exports both 
  spack install -v chameleon@trunk+starpu+fxt ^starpu@svn-trunk+fxt
  #+end_src

  Hash correspondant : =chameleon-trunk-gj5brkq45hyoavckcdaxtcpz3hjdlxmd=
  
  Cette version marche.

  Bilan : la simulation ne marche pas, des d√©viations tr√®s importantes
  (voir le warning) pour le mode non simul√© -> quoiqu'il en soit
  l'installation avec Spack est ma√Ætris√©e

  
  #+begin_example
  ./timing/time_spotrf_tile --warmup --gpus=3 --threads=9 --nb=960 --ib=96 --n_range=48000:48000:9600
  [starpu][starpu_initialize] Warning: StarPU was configured with --with-fxt, which slows down a bit
  [starpu][_starpu_bind_thread_on_cpu] Warning: both workers 0 and 8 are bound to the same PU 0, this will strongly degrade performance
  #
  # CHAMELEON 0.9.1, ./timing/time_spotrf_tile
  # Nb threads: 9
  # Nb GPUs:    3
  # NB:         960
  # IB:         96
  # eps:        5.960464e-08
  #
  #     M       N  K/NRHS   seconds   Gflop/s Deviation
    48000   48000       1 [starpu][_starpu_update_perfmodel_history] Too big deviation for model splgsy on cpu0_impl0 (Comb0): 17470.704000 vs average 11059.039143, 7 such errors against 7 samples (+57.976690%), flushing the performance model. Use the STARPU_HISTORY_MAX_ERROR environement variable to control the threshold (currently 50%)
  [starpu][_starpu_update_perfmodel_history] Too big deviation for model splgsy on cpu0_impl0 (Comb0): 10813.469000 vs average 18872.197000, 1 such errors against 1 samples (-42.701589%), flushing the performance model. Use the STARPU_HISTORY_MAX_ERROR environement variable to control the threshold (currently 50%)
  [starpu][_starpu_update_perfmodel_history] Too big deviation for model splgsy on cpu0_impl0 (Comb0): 21952.844000 vs average 11692.761069, 29 such errors against 29 samples (+87.747307%), flushing the performance model. Use the STARPU_HISTORY_MAX_ERROR environement variable to control the threshold (currently 50%)
  [starpu][_starpu_update_perfmodel_history] Too big deviation for model splgsy on cpu0_impl0 (Comb0): 9965.069000 vs average 22145.963190, 79 such errors against 79 samples (-55.002774%), flushing the performance model. Use the STARPU_HISTORY_MAX_ERROR environement variable to control the threshold (currently 50%)
  [starpu][_starpu_update_perfmodel_history] Too big deviation for model strsm on cpu0_impl0 (Comb0): 51143.533000 vs average 82083.798857, 7 such errors against 7 samples (-37.693511%), flushing the performance model. Use the STARPU_HISTORY_MAX_ERROR environement variable to control the threshold (currently 50%)
    242.332    152.13 +-   0.00  

  #---------------------
  Worker stats:
  CPU 0                           
  	3335 task(s)
  CPU 1                           
  	6089 task(s)
  CPU 2                           
  	6095 task(s)
  CPU 3                           
  	6072 task(s)
  CPU 4                           
  	6067 task(s)
  CPU 5                           
  	6089 task(s)
  CPU 6                           
  	6073 task(s)
  CPU 7                           
  	6062 task(s)
  CPU 8                           
  	3318 task(s)
  #---------------------
  #+end_example

** A faire
   Installer Kameleon et int√©grer Spack √† Kameleon (lancer les
   commandes Spack depuis Kameleon)
   
* Mardi 21/06							   :Kameleon:
  Pr√©paration d'une image pour d√©ploiement sur Grid5000

  Rappel sur l'installation de Kameleon :

  #+begin_src sh :session foo :results output :exports both
  apt-get install ruby-dev ruby-childprocess polipo libguestfs-tools
  gem install --no-ri --no-rdoc kameleon-builder
  
  kameleon template repo add default https://github.com/oar-team/kameleon-recipes.git
  #+end_src

  Cr√©ation d'un custom recipe pour grid5000 :
  
  #+begin_src sh :session foo :results output :exports both 
  kameleon new debian8_g5k default/grid5000/debian8
  #+end_src
  
  Premier d√©ploiement d'une sur Grid5000 avec Kameleon : le recipe
  =default/grid5000/debian8.yaml= se charge de d√©ployer lors du build

  Probl√®me avec Git :

  #+begin_src sh :session foo :results output :exports both 
  Step 24 : setup/first_step/spack
  --> Running the step...
  [in] Cloning into 'spack'...
  [in] fatal: Not a git repository (or any of the parent directories): .git
  Starting command: "bash"
  Starting command: "ssh -A -t -F /home/florian/Bureau/Kameleon/build/debian8_g5k/ssh_config grenoble /bin/bash"
  Starting command: "ssh -A -t -F /home/florian/Bureau/Kameleon/build/debian8_g5k/ssh_config debian8_g5k /bin/bash"
  Error occured when executing the following command :

  > exec_in: git checkout morse
  #+end_src

  Source du probl√®me : la commande =cd= ne fonctionne pas, ni =export= ->
  faire autrement

  Solution (Michael) : exporter la variable du contexte =out= vers =in= ou
  bien utiliser un fichier intermediaire
  
  Pour =cd= : grouper les comandes dans le =exec_in= avec =|= (voir cheat
  sheet yaml pour se familiariser avec la syntaxe :
  http://lzone.de/cheat-sheet/YAML). Le directory courant est remis √†
  sa position initial entre chaque =exec_in=. 
* Mercredi 22/06
  A rattraper...
* Jeudi 23/06
  Int√©gration de Spack √† Kameleon -> probl√®me d'installation. Une
  partie des logs est cach√©e, ce qui n'est pas pratique.

  Utilisation d'une tour pour d√©ployer -> probl√®me de chemin, un
  projet Kameleon est quelque part li√© √† une machine (de premiers
  abords).

  BUG Kameleon : pas d'espace dans le chemin de recipe Kameleon

  Ajout d'une issue dans le GitHub de Kameleon :
  https://github.com/oar-team/kameleon/issues/84

  Probl√®me de build avec spack :
  
  #+begin_example
  [in] Traceback (most recent call last):
  [in]   File "/root/kameleon_workdir/debian_g5k/spack/lib/spack/spack/build_environment.py", line 406, in fork
  [in]     function()
  [in]   File "/root/kameleon_workdir/debian_g5k/spack/lib/spack/spack/package.py", line 1016, in build_process
  [in]     self.install(self.spec, self.prefix)
  [in]   File "/root/kameleon_workdir/debian_g5k/spack/lib/spack/spack/multimethod.py", line 124, in __call__
  [in]     return self.default(package_self, *args, **kwargs)
  [in]   File "/root/kameleon_workdir/debian_g5k/spack/var/spack/repos/builtin/packages/starpu/package.py", line 84, in install
  [in]     subprocess.check_call("./autogen.sh")
  [in]   File "/usr/lib/python2.7/subprocess.py", line 540, in check_call
  [in]     raise CalledProcessError(retcode, cmd)
  [in] subprocess.CalledProcessError: Command './autogen.sh' returned non-zero exit status 1
  [in] ==> Error: Installation process had nonzero exit code.
  Starting command: "bash"
  Starting command: "ssh -A -t -F /home/bepo/Bureau/Kameleon/build/debian_g5k/ssh_config grenoble /bin/bash"
  Starting command: "ssh -A -t -F /home/bepo/Bureau/Kameleon/build/debian_g5k/ssh_config debian_g5k /bin/bash"
  Error occured when executing the following command :
  
  > exec_in: "git clone https://github.com/fpruvost/spack\nexport SPACK_ROOT=/root/kameleon_workdir/debian_g5k/spack/\nexport
  >   PATH=$SPACK_ROOT/bin:$PATH          \ncd spack/\ngit checkout morse\nspack install
  >   -v chameleon@trunk+starpu+fxt ^starpu@svn-trunk+fxt\n"

  #+end_example

  Rajout de d√©pendances suppl√©mentaires (celles indiqu√©es ici :
  http://morse.gforge.inria.fr/chameleon/tuto_chameleon/chameleon-tutorial-2015-12-16-inria.html#sec-1-2-1)

  Nouveau probl√®me : 
  
  #+begin_example
  [in] checking glpk.h usability... no
  [in] checking glpk.h presence... no==> Error: Command exited with status 1:
  [in] ==> Error: Installation process had nonzero exit code.
  Starting command: "bash"
  Starting command: "ssh -A -t -F /home/bepo/Bureau/Kameleon/build/debian_g5k/ssh_config grenoble /bin/bash"
  Starting command: "ssh -A -t -F /home/bepo/Bureau/Kameleon/build/debian_g5k/ssh_config debian_g5k /bin/bash"
  Error occured when executing the following command :
  
  > exec_in: "git clone https://github.com/fpruvost/spack\nexport SPACK_ROOT=/root/kameleon_workdir/debian_g5k/spack/\nexport
  >   PATH=$SPACK_ROOT/bin:$PATH          \ncd spack/\ngit checkout morse\nspack install
  >   -v chameleon@trunk+starpu+fxt ^starpu@svn-trunk+fxt\n"
  #+end_example

  Le probl√®me est peut-√™tre d√ª au fait que la machine ne contient pas
  de GPU (ou autre chose), tout du moins, cela marchait sur Digitalis.

  Essayer de se connecter √† Digitalis via le recipe Kameleon.

  Michael : faire un tunnel ssh

  -> modification de =g5k_reserv.yaml=
  
  Probl√®me :
  
  #+begin_example
  [out] Deploying environment jessie-x64-base on grimage-9.grenoble.grid5000.fr
  [out] Resource not found /environments
  Starting command: "bash"
  Starting command: "ssh -A -t -F /home/bepo/Bureau/Kameleon/build/debian_g5k/ssh_config digitalis /bin/bash"
  Error occured when executing the following command :
  
  > exec_out: kadeploy3 -e jessie-x64-base -m $machine -k
  #+end_example

  -> Digitalis ne poss√®de pas le r√©pertoire /environments

  On va r√©server une machine avec des GPU √† la main :
  #+begin_src sh :session foo :results output :exports both 
  oarsub -p "gpu='YES'" -t deploy
  #+end_src

  Ajout dans la recette g5k (m√©thode brutale)

  #+begin_src sh :session foo :results output :exports both 
  [out] The out_context has been initialized
  [out] Deploying image jessie-x64-base with kadeploy
  [out] Submitting a job for deployment
  [out] Properties: (gpu='YES') AND deploy = 'YES'
  [out] [ADMISSION RULE] Modify resource description with type constraints
  [out] Generate a job key...
  [out] There are not enough resources for your request
  [out] Oarsub failed: please verify your request syntax or ask for support to your admin.
  #+end_src

  Aka : Comment se faire jeter par Grid5000 ?

  Solution : d√©ployer une image .tgz sur Digitalis (l'image de Vin√¨nius)

  En attendant : modifier la recette de fa√ßon propre (avec des
  variables globales) -> DONE

  Pour voir les caract√®res speciaux dans vim : =:set list=    
* Lundi 27/06							      :Execo:
  Tuto fourni pour Michael :
  https://www.grid5000.fr/mediawiki/index.php/Execo_Practical_Session

  Utiliser Spack dans Execo ? Spack installe et _compile_. R√©ponse : OUI.

  Installation locale d'Execo pour tester + r√©cup√©ration d'un test de
  Michael : ce test comprend la r√©servation et le d√©ploiement d'un
  benchmark sur Grid5000. Ceci est fait par Kameleon, il convient de
  pouvoir donner √† Execo ces options de r√©servations (nombres de
  noeuds, walltime, ...)

  Grid5000 sur Grenoble down -> impossible de d√©ployer sur Digitalis

  Lecture approfondie de la doc Execo
** A faire
   - Inclure les donn√©es de Kameleon dans Execo (voir Michael si
     besoin)
   - Piloter avec Execo
   - D√©ployer
* Mardi 28/06
  Int√©gration de Execo √† Kameleon : Kameleon se charge de d√©ployer sur
  Grid5000 et fournit au script Execo un certain nombre
  d'informations : le site, l'ID du job (grep dans le recipe
  Kameleon), le nombre de noeud ainsi que le walltime.

  Question (voir Michael) : les variables d'environnement
  restent-elles pr√©sentes lors de toute la dur√©e du recipe Kameleon ?
  (esp√©rer que oui) -> OUI

  Probl√®me d'installation d'environnement :
  
  #+begin_example
  [in] Installing new version of config file /etc/init.d/nscd ...
  [in] 
  [in] Configuration file `/etc/nscd.conf'
  [in]  ==> Modified (by you or by a script) since installation.
  [in]  ==> Package distributor has shipped an updated version.
  [in]    What would you like to do about it ?  Your options are:
  [in]     Y or I  : install the package maintainer's version
  [in]     N or O  : keep your currently-installed version
  [in]       D     : show the differences between the versions
  [in]       Z     : start a shell to examine the situation
  [in]  The default action is to keep your current version.
  [in] *** nscd.conf (Y/I/N/O/D/Z) [default=N] ? 
  #+end_example

  L'op√©ration est bloquante (entrer un caract√®re est sans effet) :
  impossibilit√© de tester (voir Michael)

  A faire : int√©grer Spack dans Execo (et non dans Kameleon)
* Mercredi 29/06
  Michael : correctif du bug du Mardi 28/06, utiliser :
  
  #+begin_src sh :session foo :results output :exports both 
  -o Dpkg::Options::="--force-confnew"
  #+end_src

  Ceci arrive fr√©quemment, voire syst√©matiquement et semble intervenir
  lorsque une m√™me machine est d√©ploy√©e plusieurs fois (?) ->
  utilisation des variables d'environnement dans Kameleon pour all√©ger
  les recipes.

  
  #+begin_example
  [in] E: dpkg was interrupted, you must manually run 'dpkg --configure -a' to correct the problem. 
  [in] Fetched 21.3 MB in 3s (6,288 kB/s)
  Starting command: "bash"
  Starting command: "ssh -A -t -F /home/florian/Bureau/Polaris/Kameleon/build/debian_g5k/ssh_config grenoble /bin/bash"
  Starting command: "ssh -A -t -F /home/florian/Bureau/Polaris/Kameleon/build/debian_g5k/ssh_config debian_g5k /bin/bash"
  Error occured when executing the following command :
  
  > exec_in: apt-get -o Acquire::Check-Valid-Until=false -y --force-yes update
  Press [r] to retry
  Press [c] to continue with execution
  Press [a] to abort execution
  Press [l] to switch to local_context shell
  Press [o] to switch to out_context shell
  Press [i] to switch to in_context shell
  answer ? [c/a/r/l/o/i]:  i
  User choice: [i] launch in_context
  Starting interactive shell
  Starting interactive command: "source /var/lib/gems/2.1.0/gems/kameleon-builder-2.7.2/contrib/kameleon_bashrc.sh 2> /dev/null; ssh -A -t -F /home/florian/Bureau/Polaris/Kameleon/build/debian_g5k/ssh_config debian_g5k /bin/bash --rcfile /root/kameleon_workdir/debian_g5k/kameleon_scripts/in/bash_rc"
  (in_context) root@adonis-3: /root/kameleon_workdir/debian_g5k # dpkg --configure -a
  Setting up bash (4.3-11+b1) ...
  
  Configuration file '/etc/skel/.bashrc'
  ==> Modified (by you or by a script) since installation.
  ==> Package distributor has shipped an updated version.
  What would you like to do about it ?  Your options are:
  Y or I  : install the package maintainer's version
  N or O  : keep your currently-installed version
  D     : show the differences between the versions
  Z     : start a shell to examine the situation
  The default action is to keep your current version.
  *** .bashrc (Y/I/N/O/D/Z) [default=N] ? Y
  Installing new version of config file /etc/skel/.bashrc ...
  update-alternatives: using /usr/share/man/man7/bash-builtins.7.gz to provide /usr/share/man/man7/builtins.7.gz (builtins.7.gz) in auto mode
  (in_context) root@adonis-3: /root/kameleon_workdir/debian_g5k # exit
  Saved ENV in /root/kameleon_workdir/debian_g5k/kameleon_scripts/in/bash_env file
  Shared connection to debian_g5k closed.
  Getting back to Kameleon...
  Press [r] to retry
  Press [c] to continue with execution
  Press [a] to abort execution
  Press [l] to switch to local_context shell
  Press [o] to switch to out_context shell
  Press [i] to switch to in_context shell
  answer ? [c/a/r/l/o/i]:  r
  ...
  [in] Get:11 http://ftp.debian.org jessie-backports/non-free Translation-en/DiffIndex [7,330 B]
  [in] Fetched 424 kB in 2s (175 kB/s)
  [in] Reading package lists...
  [in] W: Ignoring Provides line with DepCompareOp for package python-cffi-backend-api-max
  [in] W: Ignoring Provides line with DepCompareOp for package python-cffi-backend-api-min
  [in] W: Ignoring Provides line with DepCompareOp for package python3-cffi-backend-api-max
  [in] W: Ignoring Provides line with DepCompareOp for package python3-cffi-backend-api-min
  [in] W: You may want to run apt-get update to correct these problems
  #+end_example

  Modification √† faire de la recette Kameleon pour prendre en compte /
  d√©ployer sur plusieurs noeuds (=$OAR_NODE_FILES= n'est pas atteignable
  directement)

  Erreur lors de l'installation de Kameleon dans les machines (?) :
  #+begin_src sh :session foo :results output :exports both 
  useradd -m kameleon -s /bin/bash
  #+end_src
  
  #+begin_example
  [in] useradd: cannot create directory /home/kameleon
  #+end_example

  Source des probl√®mes : conflit entre le d√©ploiement d'un environnement
  de base et d'un .tgz
* Jeudi 30/06
  Cr√©ation de deux recipes distinctes : une bas√©e sur debian8, l'autre
  bas√©e sur un .tgz

  Probl√®me avec HWLOC :
  
  #+begin_example
  [in] checking for FFTW... checking for FFTWF... checking for FFTWL... checking for HWLOC... configure: error: libhwloc was not found on your system. If the target machine is hyperthreaded the performance may be impacted a lot.  It is strongly recommended to install libhwloc. However, if you really want to use StarPU without enabling libhwloc, please restart configure by speci==> Error: Command exited with status 1:
  [in] ==> Error: Installation process had nonzero exit code.
  #+end_example

  HWLOC est pourtant bien install√© -> envoie d'un mail √† Luka

  Le recipe custom marche pourtant -> probl√®me avec le debian8 de base
  
* Lundi 04/07
  R√©cup√©rer le _dernier_ jobID

  
  #+begin_example
  Job id     Name           User           Submission Date     S Queue
  ---------- -------------- -------------- ------------------- - ----------
  812911     a289d67b66d2   fpopek         2016-07-04 11:28:31 R default   
  812917                    fpopek         2016-07-04 11:33:09 R default   
  #+end_example

  Commande : =oarstat -u | tail -n 1 | grep -o -E '[0-9]+' | head -n 1=

  Frontale grenobe.g5k down -> impossible de r√©cup√©rer mon image .tgz :'(
  
  Mot de passe non reconnu sur grenoble -> attente

  D√©ploiement sur lyon avec le recipe =debian8=
 
  Probl√®me r√©current : kameleon cr√©e l'utilisateur /kameleon/ mais il
  peut d√©j√† exister (il suffit alors de sauter l'√©tape)

  Mise en place du script execo -> √† placer dans
  =build/$${kameleon_workdir}/= -> √† changer 

  Ne jamais appeller un script python du m√™me nom que les modules
  qu'il utilise !

  Probl√®me avec le walltime donn√© √† execo :

  
  #+begin_example
  install --user execo\npython execo_script.py lyon $job_id 1
  >   1:00:00\n"
  #+end_example

  -> le probl√®me vient de =$job_id= qui est nulle ! -> utilisation d'un
     fichier inter-contexte
* Mardi 05/07
  Premier lancement de Spack dans Execo :

  
  #+begin_example
  [in] 2016-07-05 10:22:20,655 INFO: command line arguments: ['execo_script.py', 'grenoble', '1711869', '1', '1:00:00']
  [in] 2016-07-05 10:22:20,655 INFO: command line: execo_script.py grenoble 1711869 1 1:00:00
  [in] 2016-07-05 10:22:20,655 INFO: run in directory /root/kameleon_workdir/custom_debian_g5k/results_2016-07-05--10-22-20
  [in] 2016-07-05 10:37:20,684 INFO: Starting StarPU installation...
  [in] 2016-07-05 10:37:20,684 INFO: StarPU installation DONE...
  [in] 2016-07-05 10:37:20,694 WARNING: terminated: <Process('spack install -v chameleon@trunk+starpu+fxt ^starpu@svn-trunk+fxt', name=spack install -v chameleon@trunk+sta..., started=True, start_date=2016-07-05 10:37:20+00:00, ended=True, end_date=2016-07-05 10:37:20+00:00, killed=False, error=True, error_reason=[Errno 2] No such file or directory, timeouted=False, expect_fail=False, write_error=False, exit_code=None, ok=False, pid=None)>
  [in] stdout:
  [in] 
  [in] stderr:
  [in] 
  [in] 2016-07-05 10:37:20,700 INFO: Delete job: [(1711869, 'grenoble')]
  #+end_example

  -> erreur d'installation (voir le warning)

  Plut√¥t que d'attendre 20 minutes √† chaque fois, cr√©ation d'un script
  execo local (sans tenir compte de la gestion de Grid5000)

  -> un des package n'existait plus (l'utilisation de =apt-get -m= dans le
     recipe kameleon ne fonctionne pas ! Solution : individualiser
     l'installation des packages)

  Besoin de r√©cup√©rer la sortie standard de Spack dans Execo.
  Michael : utiliser =stdout= et =stdout_handler=

  
  #+begin_example
  [in] 2016-07-05 15:12:50,547 INFO: command line arguments: ['execo_script.py', 'grenoble', '1711875', '1', '1:00:00']
  [in] 2016-07-05 15:12:50,547 INFO: command line: execo_script.py grenoble 1711875 1 1:00:00
  [in] 2016-07-05 15:12:50,547 INFO: run in directory /root/kameleon_workdir/custom_debian_g5k/results_2016-07-05--15-12-50
  [in] 2016-07-05 15:27:50,576 INFO: Starting StarPU installation...
  [in] 2016-07-05 15:27:50,586 WARNING: terminated: <Process('spack install -v chameleon@trunk+starpu+fxt ^starpu@svn-trunk+fxt', name=spack install -v chameleon@trunk+sta..., started=True, start_date=2016-07-05 15:27:50+00:00, ended=True, end_date=2016-07-05 15:27:50+00:00, killed=False, error=True, error_reason=[Errno 2] No such file or directory, timeouted=False, expect_fail=False, write_error=False, exit_code=None, ok=False, pid=None)>
  [in] stdout:
  [in] 
  [in] stderr:
  [in] 
  [in] 2016-07-05 15:27:50,592 INFO: StarPU installation DONE...
  [in] 2016-07-05 15:27:50,592 INFO: Error : [Errno 2] No such file or directory
  [in] 2016-07-05 15:27:50,592 INFO: Spack stdout : 
  [in] 2016-07-05 15:27:50,592 INFO: Delete job: [(1711875, 'grenoble')]
  #+end_example

* Mercredi 06/07
  L'erreur semble provenir de Python et non de Spack :
  http://stackoverflow.com/questions/15725273/python-oserror-errno-2-no-such-file-or-directoryq

  Utiliser : =python ./execo_script= ou =os.path.abspath()=
  -> ne marche toujours pas
  -> cr√©ation d'un recipe local

  -> probl√®me venant de l'utilisation de Spack dans Execo
  -> probl√®me de variable d'environnement -> facile √† r√©gler (ouf !)

  HS : avertissement Grid5000 (175% of daily allowance) -> il serait
  temps que cela marche :)

  Installation de Spack dans Execo -> √ßa marche !

  Mise en place d'un breakpoint pour v√©rifier les installations :
  
  #+begin_example
  IN_CONTEXT :
    Kameleon_working_dir : /home/root/kamaleon_workdir/
    Recipe deployed : /home/root/kameleon_workdir/custom_debian_g5k/ (custom_debian_g5k est le nom du recipe) -> default in_context
    Spack : /home/root/kameleon_workdir/custom_debian_g5k/spack/
    Execo : /home/root/kameleon_workdir/custom_debian_g5k/
  
  OUT_CONTEXT:
    Kameleon_working_dir : /home/fpopek/kamaleon_workdir/
    Recipe deployed : /home/fpopek/kameleon_workdir/custom_debian_g5k/ (custom_debian_g5k est le nom du recipe) -> default out_context
      -> info OAR
      -> dans kameleon_scripts/out/ : toutes les commandes utilis√©es

  LOCAL_CONTEXT:
    Kameleon_working_dir : /home/bepo/Bureau/custom/
    Recipe deployed : /home/bepo/Bureau/custom/build/custom_debian_g5k (custom_debian_g5k est le nom du recipe) -> default local_context
  #+end_example
  
  La recipe G5K de base ne nettoie pas les r√©servations ! (d'o√π
  l'avertissement) -> l'ajouter, puis pull request dans le git de
  Kameleon ou envoyer le code √† Michael.

  Les variables d'environnement du contexte OUT sont elles pr√©serv√©es ?
* Jeudi 07/07
  Ajout d'un hook dans le recipe kameleon pour nettoyer la r√©servation
  G5k -> √ßa marche bien !

  Conservation des variables d'environnement dans le context IN :
  parfois buggu√© 

  Conservation des variables d'environnement dans le
  context OUT : ok

  Probl√®me de hook : =on_export_clean= intervient peu apr√®s le boostrap
  -> envoie d'un mail √† Michael -> fausse alerte

  Report du bug de contexte IN √† Michael -> ajout d'une issue dans
  Github : https://github.com/oar-team/kameleon/issues/86

** A faire
   R√©cup√©rer les donn√©es dans le contexte local

   
   #+begin_example
   Dans IN :
   R√©cup√©rer kameleon_scripts/ -> fait
   R√©cup√©rer results_XXX/ (ex : results_2016-07-07--11-34-18/) -> cr√©er un dossier execo
  
   Dans OUT :
   R√©cup√©rer kameleon_scripts/ -> fait
   R√©cup√©rer les infos de r√©servations : -> fait
   OAR.d7c379dee39f.1711919.stdout
   OAR.d7c379dee39f.1711919.stderr
   ssh_config
   #+end_example
   
   Utiliser les pipes (comment passer en dossier par le pipe ?) ->
   passer par tar.gz
* Lundi 11/07
  R√©cup√©ration des infos g√©n√©r√©es par Kameleon

  R√©cup√©ration des infos machines (linker √† StarPU)

  Phase finale : lancer StarPU / r√©cup√©rer ses infos
  http://starpu.gforge.inria.fr/testing/morse/trunk/morse.html

  - Trouver comment Spack g√®re les emplacements d'installation
    https://groups.google.com/forum/#!msg/spack/-4DvgF3QKTE/wQQvDb26DAAJ

    Le script √† ex√©cuter se trouve dans : {StarPU installation}/lib/chameleon/timing/
  - Trouver comment installer StarPU / Simgrid >:(
    http://morse.gforge.inria.fr/spack/spack.html#sec-2-1-1-7-2

    -> impossible !

    Genre d'erreurs obtenues :
    
    #+begin_example
    core/simgrid.c:224:2: error: too many arguments to function 'xbt_cfg_set_int'
    xbt_cfg_set_int(_sg_cfg_set, "contexts/stack_size", stack_size);
    #+end_example

    Cette fonction ne prend que deux arguments !
    http://simgrid.gforge.inria.fr/simgrid/3.13/doc/group__XBT__cfg__use.html#ga6940aacb7b28c261e5468a5500758679
    http://simgrid.gforge.inria.fr/simgrid/3.14/doc/group__XBT__cfg__use.html

    Luka et Florent n'y arrivent pas non plus. Arnaud : laisser tomber

  Ecriture du programme Execo ex√©cutant StarPU (√† tester)
* Mardi 12/07
  Probl√®me avec G5k -> ssh anormalement long -> tester execo pas
  possible :(

  Apr√®s quelques minutes -> lancement

  Quelques soucis suppl√©mentaires : 

  
  #+begin_example
  [in] Err http://ftp.fr.debian.org wheezy Release.gpg
  [in]   Could not connect to proxy:3128 (172.16.31.113). - connect (113: No route to host)
  [in] Err http://security.debian.org wheezy/updates Release.gpg
  [in]   Could not connect to proxy:3128 (172.16.31.113). - connect (113: No route to host)
  #+end_example

  Michael : pas besoin des proxys sur G5k dor√©navant -> je n'en
  utilisais pas. Probl√®me G5k ? voir Bastien

  Ecriture d'un sweeper python
* Mercredi 13/07
  A rattraper...
* Lundi 18/07
  S√©paration de Kameleon et de Execo : Kameleon cr√©e une image .tgz,
  Execo d√©ploie l'image

  Execo doit √™tre lanc√© depuis la frontale, sinon il faut modifier son
  .ssh et son .execo.conf.py -> utiliser une deuxi√®me recette Kameleon
  ?

  Cr√©ation d'une deuxi√®me recette Kameleon pour Execo

  Le fichier .env cr√©e par la premi√®re recette n'est pas exact !

  Fatal error :
  
  #+begin_example
  Error : undefined method `read_nonblock' for nil:NilClass
  Unfortunately, a fatal error has occurred : undefined method `read_nonblock' for nil:NilClass.
  #+end_example

  Ce que dit le mode debug :
  
  #+begin_example
  Error : undefined method `read_nonblock' for nil:NilClass
  /var/lib/gems/1.9.1/gems/kameleon-builder-2.7.3/lib/kameleon/shell.rb:273:in `read_io': undefined method `read_nonblock' for nil:NilClass (NoMethodError)
	from /var/lib/gems/1.9.1/gems/kameleon-builder-2.7.3/lib/kameleon/shell.rb:102:in `init_shell_cmd'
	from /var/lib/gems/1.9.1/gems/kameleon-builder-2.7.3/lib/kameleon/shell.rb:86:in `send_file'
	from /var/lib/gems/1.9.1/gems/kameleon-builder-2.7.3/lib/kameleon/context.rb:152:in `send_file'
	from /var/lib/gems/1.9.1/gems/kameleon-builder-2.7.3/lib/kameleon/context.rb:109:in `pipe'
	from /var/lib/gems/1.9.1/gems/kameleon-builder-2.7.3/lib/kameleon/engine.rb:294:in `exec_cmd'
	from /var/lib/gems/1.9.1/gems/kameleon-builder-2.7.3/lib/kameleon/engine.rb:247:in `safe_exec_cmd'
	from /var/lib/gems/1.9.1/gems/kameleon-builder-2.7.3/lib/kameleon/engine.rb:231:in `block (3 levels) in do_steps'
	from /var/lib/gems/1.9.1/gems/kameleon-builder-2.7.3/lib/kameleon/engine.rb:230:in `each'
	from /var/lib/gems/1.9.1/gems/kameleon-builder-2.7.3/lib/kameleon/engine.rb:230:in `block (2 levels) in do_steps'
	from /var/lib/gems/1.9.1/gems/kameleon-builder-2.7.3/lib/kameleon/step.rb:195:in `block in sequence'
	from /var/lib/gems/1.9.1/gems/kameleon-builder-2.7.3/lib/kameleon/step.rb:195:in `each'
	from /var/lib/gems/1.9.1/gems/kameleon-builder-2.7.3/lib/kameleon/step.rb:195:in `sequence'
	from /var/lib/gems/1.9.1/gems/kameleon-builder-2.7.3/lib/kameleon/engine.rb:202:in `block in do_steps'
	from /var/lib/gems/1.9.1/gems/kameleon-builder-2.7.3/lib/kameleon/step.rb:227:in `block in sequence'
	from /var/lib/gems/1.9.1/gems/kameleon-builder-2.7.3/lib/kameleon/step.rb:227:in `each'
	from /var/lib/gems/1.9.1/gems/kameleon-builder-2.7.3/lib/kameleon/step.rb:227:in `sequence'
	from /var/lib/gems/1.9.1/gems/kameleon-builder-2.7.3/lib/kameleon/engine.rb:191:in `do_steps'
	from /var/lib/gems/1.9.1/gems/kameleon-builder-2.7.3/lib/kameleon/engine.rb:526:in `block in build'
	from /var/lib/gems/1.9.1/gems/kameleon-builder-2.7.3/lib/kameleon/engine.rb:525:in `each'
	from /var/lib/gems/1.9.1/gems/kameleon-builder-2.7.3/lib/kameleon/engine.rb:525:in `build'
	from /var/lib/gems/1.9.1/gems/kameleon-builder-2.7.3/lib/kameleon/cli.rb:314:in `build'
	from /var/lib/gems/1.9.1/gems/thor-0.19.1/lib/thor/command.rb:27:in `run'
	from /var/lib/gems/1.9.1/gems/thor-0.19.1/lib/thor/invocation.rb:126:in `invoke_command'
	from /var/lib/gems/1.9.1/gems/thor-0.19.1/lib/thor.rb:359:in `dispatch'
	from /var/lib/gems/1.9.1/gems/thor-0.19.1/lib/thor/base.rb:440:in `start'
	from /var/lib/gems/1.9.1/gems/kameleon-builder-2.7.3/lib/kameleon/cli.rb:357:in `start'
	from /var/lib/gems/1.9.1/gems/kameleon-builder-2.7.3/bin/kameleon:18:in `<top (required)>'
	from /usr/local/bin/kameleon:23:in `load'
	from /usr/local/bin/kameleon:23:in `<main>'
  #+end_example

  Probl√®me de gem : https://github.com/bundler/bundler/issues/2915

  Il va falloir g√©n√©rer une nouvelle image ne comportant pas ce bug...

  Solution √† tester : passer √† Debian7
* Mardi 19/07
  Passage √† Debian7 : m√™me erreur...

  -> probl√®me de pipe : ne pas appeller un pipe en 1√®re commande :
  https://github.com/oar-team/kameleon/issues/89

  Comportement singulier (pas une erreur) :
  
  #+begin_example
  OpenSSH_6.6.1, OpenSSL 1.0.1f 6 Jan 2014
  debug1: Reading configuration data /home/bepo/Bureau/debian7/execution/build/execo_recipe/ssh_config
  debug1: /home/bepo/Bureau/debian7/execution/build/execo_recipe/ssh_config line 1: Applying options for *
  debug1: /home/bepo/Bureau/debian7/execution/build/execo_recipe/ssh_config line 15: Applying options for grenoble
  debug1: auto-mux: Trying existing master
  debug2: fd 3 setting O_NONBLOCK
  debug2: mux_client_hello_exchange: master version 4
  debug3: mux_client_forwards: request forwardings: 0 local, 0 remote
  debug3: mux_client_request_session: entering
  debug3: mux_client_request_alive: entering
  debug3: mux_client_request_alive: done pid = 5299
  debug3: mux_client_request_session: session request sent
  debug1: mux_client_request_session: master session id: 4
  #+end_example

  Spack : =spack location= ne marche pas. Utiliser =spack location -i=
  (Vin√¨cius)

  Execo : le r√©pertoire courant revient √† sa valeur par d√©faut entre
  deux process -> faire de grande commandes

  Premiers r√©sultats de StarPU :
  
  #+begin_example
  #
  # CHAMELEON 0.9.1, ./timing/time_spotrf_tile
  # Nb threads: 9
  # Nb GPUs:    3
  # NB:         960
  # IB:         96
  # eps:        5.960464e-08
  #
  #     M       N  K/NRHS   seconds   Gflop/s Deviation
  48000   48000       1   256.229    143.88 +-   0.00
  #+end_example

  Ajout des lignes de codes dans Kameleon permettant de r√©cup√©rer ces
  r√©sultats

  Un peu l√©ger non ? Non, c'est √ßa. 143 Gflop/s c'est tr√®s nul (~2000
  sur http://starpu.gforge.inria.fr/testing/morse/trunk/morse.html)

  Deuxi√®me lancemement, probl√®me d'installation (WTF !) :
  
  #+begin_example
  [in] c.satisfies('+magma'):
  [in]      89                   # Enable MAGMA here.
  [in]      90                   cmake_args.extend(["-DCHAMELEON_USE_MAGMA=ON"])
  [in]      91               if spec.satisfies('+fxt'):
  [in]      92                   # Enable FxT here.
  [in]      93                   if spec.satisfies('chameleon@0.9.0:0.9.1'):
  [in]      94                       cmake_args.extend(["-DCHAMELEON_USE_FXT=ON"])
  [in]      95                   else:
  [in]      96                       cmake_args.extend(["-DCHAMELEON_ENABLE_TRACING=ON"])
  [in]      97               if spec.satisfies('+simu'):
  [in]      98                   # Enable SimGrid here.
  [in]      99                   cmake_args.extend(["-DCHAMELEON_SIMULATION=ON"])
  [in]      100              if spec.satisfies('+quark') and spec.satisfies('+starpu'):
  [in]      101                  raise RuntimeError('variant +quark and +starpu are mutually exclusive, please choose one.')
  [in]      102              if spec.satisfies('~quark') and spec.satisfies('~starpu'):
  [in]      103                  raise RuntimeError('Chameleon requires a runtime system to be enabled, either +quark or +starpu, please choose one.')
  [in]      104              if spec.satisfies('+quark'):
  [in]      105                  # Enable Quark here.
  [in]      106                  cmake_args.extend(["-DCHAMELEON_SCHED_QUARK=ON"])
  [in]      107              else:
  [in]      108                  cmake_args.extend(["-DCHAMELEON_SCHED_QUARK=OFF"])
  [in]      109              if spec.satisfies('+starpu'):
  [in]      110                  # Enable StarPU here.
  [in]      111                  starpu = self.spec['starpu']
  [in]      112                  cmake_args.extend(["-DCHAMELEON_SCHED_STARPU=ON"])
  [in]      113                  cmake_args.extend(['-DSTARPU_DIR=%s' % starpu.prefix])
  [in]      114              else:
  [in]      115                  cmake_args.extend(["-DCHAMELEON_SCHED_STARPU=OFF"])
  [in]      116  
  [in]      117              if spec.satisfies('~simu'):
  [in]      118                  blas = self.spec['blas']
  [in]      119                  cblas = self.spec['cblas']
  [in]      120                  lapack = self.spec['lapack']
  [in]      121                  lapacke
  [in] stderr:
  [in] ==> Error: Command exited with status 2:
  [in] ==> Error: Installation process had nonzero exit code.
  #+end_example

  Troisi√®me lancement : OK -> bizarre

** A faire
   R√©cup√©rer les sorties standards de TOUS les process (installation,
   etc...) -> modifier le scipt Execo -> Fait

   Le script de Luka ne semble pas r√©cup√©rer d'informations sur les
   GPU

   Trouver pourquoi les r√©sultats sont si bas, peut-√™tre un manque de
   configuration ?
   http://starpu.gforge.inria.fr/testing/morse/trunk/plafrim-trunk-plafrim-morse_trunk_chameleon_HEAD_seq.sl.o233738
   
   #+begin_example
   config.status: executing executable-scripts commands
   configure:
   
	CPUs   enabled: yes
	CUDA   enabled: yes
	OpenCL enabled: yes
	SCC    enabled: no
	MIC    enabled: no
   
	Compile-time limits
	(change these with --enable-maxcpus, --enable-maxcudadev,
	--enable-maxopencldev, --enable-maxmicdev, --enable-maxnodes,
        --enable-maxbuffers)
        (Note these numbers do not represent the number of detected
	devices, but the maximum number of devices StarPU can manage)
   
	Maximum number of CPUs:           64
	Maximum number of CUDA devices:   4
	Maximum number of OpenCL devices: 8
	Maximum number of SCC devices:    0
	Maximum number of MIC threads:    0
	Maximum number of memory nodes:   16
	Maximum number of task buffers:   8
   
	GPU-GPU transfers: yes
	Allocation cache:  yes
   
	Magma enabled:     no
	BLAS library:      mkl
	hwloc:             yes
	FxT trace enabled: no
	StarPU-Top:        no
   
        Documentation:     no
        Examples:          no
   
	StarPU Extensions:
	       MPI enabled:                                 yes
	       MPI test suite:                              yes
	       FFT Support:                                 yes
	       GCC plug-in:                                 no
	       GCC plug-in test suite (requires GNU Guile): no
	       OpenMP runtime support enabled:              no
	       SOCL enabled:                                no
               SOCL test suite:                             no
               Scheduler Hypervisor:                        yes
               simgrid enabled:                             no
               ayudame enabled:                             no
   #+end_example
* Mercredi 20/07
  Pour r√©cup√©rer √† partir d'une r√©vision SVN :
  http://software.llnl.gov/spack/spack.html?highlight=git#spack.fetch_strategy.SvnFetchStrategy

  Doc : http://software.llnl.gov/spack/packaging_guide.html

  Il faut re-√©crire le package StarPU pour accepter les diff√©rentes
  r√©visions SVN

  Un fichier CSV contient les r√©visions √† tester (on pourra y mettre
  √©galement un jeu d'options de compilation √† tester). A partir de ce
  fichier CSV, on g√©n√®re le package Spack correspondant (avec un
  script python), enfin on
  l'utilise dans Execo.

  Cr√©ation des g√©n√©rateurs de packages Chameleon et StarPU, et du
  fichier CSV

  Import de ces fichiers dans la recette Execo

  -> √ßa marche ! (facile)

** Exploitation des donn√©es
   Exploiter les donn√©es avec :
   http://rmarkdown.rstudio.com/flexdashboard/ 
   (il faut juste r√©cup√©rer les Gflop/s)

   -> Installation de RStudio
  
* Jeudi 21/07
  Peaufinnage : le fichier CSV contient un header, un module python
  (CSVHeader) permet de g√©rer cela facilement entre tous les scripts
  utilisant le header

  -> utilisation d'un .tar pour passer tous les scripts
  -> recipe plus propre

  PS: la commande tar est une horreur

  Cr√©ation d'un script r√©cup√©rant les donn√©es calcul√©es en CSV
* Lundi 25/07
  Fin de l'√©criture du script

  Ajout des fermetures de fichier avec =close()= dans les scripts python
  (plus propre)

  Installation manuelle de R 3.2.5 (les packages par d√©faut ne
  d√©ppassent pas 3.0.2) -> long

  #+begin_example
  T√©l√©charger l'archive .tar..gz
  Ex√©cuter : ./configuration --enable-R-shrlib=yes
  Ex√©cuter : make
  Remplacer le binaire √† l'endroit donn√© par =which R=
  #+end_example

  Premi√®re utilisation de flexdashboard : long √† charger
  http://rmarkdown.rstudio.com/authoring_shiny.html#deployment
  http://rmarkdown.rstudio.com/flexdashboard/shiny.html

  Le mieux est encore de regarder le code source des exemples :
  http://rmarkdown.rstudio.com/flexdashboard/examples.html

  Pour des courbes :
  https://beta.rstudioconnect.com/jjallaire/htmlwidgets-ggplotly-geoms/#geom_density
* Mardi 26/07
  Cr√©ation du Markdown

  D√©pendances (celles utilis√©es dans les exemples flashdashboard):
  - ggplot2
  - plotly (n√©cessite =apt-get install libssl-dev libcurl4-openssl-dev=)
  - plyr
  - flexdashboard

  X11 introuvable -> pour Debian : =apt-get install xorg-dev=

  Librairie readline introuvable : =apt-get install libreadline-dev=

  -> recompilation de R -> √ßa marche

  Premi√®re visualisation des r√©sultats : √ßa marche bien !

  Pour rendre √ßa joli : http://docs.ggplot2.org/0.9.2.1/theme.html

  Utiliser Shiny pour rendre √ßa encore plus interactif

  A lire :
  - http://starpu-simgrid.gforge.inria.fr/misc/SIGOPS_paper.pdf
  - Git Scott Shacon -> youtube
  - Webinar 4
  - http://orgmode.org/worg/org-contrib/org-git-link.html
  
