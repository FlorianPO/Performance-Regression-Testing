#+TAGS: Phoronix(P) Pypy(Y) Jenkins(J) CollectiveMind(C)
#+TAGS: XPFlow(C) Expo(A) Execo(B) 
#+TAGS: Spack(S) Kameleon(K)

* Jeudi 19/05
  - Installation de Débian8 avec Vincent Danjean
  - Mise en place de l'environnement de travail (quelques raccourcis
    qui me sont chers, des marque-pages, un Git:
    https://github.com/FlorianPO/Performance-Regression-Testing)
  - Il faut que je fournisse mon adresse MAC à Christian afin d'avoir
    Internet en filaire (très peu de Wifi dans la salle)
  - Prise en main de Org-mode sous emacs
* Lundi 23/05				    :Phoronix:Jenkins:CollectiveMind:
  - [[file:Overviews/Phoronix.org][Overview de Phoronix]] : dépendant du matériel, deux tests n'auront
    du sens que s'ils sont éxecutés sur la /même/ machine.
  - [[https://github.com/FlorianPO/Performance-Regression-Testing/blob/master/CollectiveMind.org][Overview de CollectiveMind]] : plus proche du sujet (axé recherche)
  - [[https://github.com/FlorianPO/Performance-Regression-Testing/blob/master/Jenkins.org][Overview de Jenkins]]

  Ces documents ne sont qu'une ébauche, il conviendra à l'avenir de
  s'intéresser à leur points communs/différences. En première
  approximation, les benchmarks proposés dépendent de la machine qui
  les a générés (à l'exception de CollectiveMind qui semble
  s'intéresser au problème). Néanmoins, ces trois plateformes sont des
  /usines à gaz/, il reste encore énormément à découvrir.
* Mardi 24/05
  - Uniformisation des .org. L'objectif est de comparer les 3
    plateformes sur le benchmarking.
  - Ajout d'un [[https://github.com/FlorianPO/Performance-Regression-Testing/blob/master/State_of_the_art.org][rapport]] /très bref/ sur l'état de l'art. Il convient d'en
    discuter.
  - Réunion avec Arnaud Legrand : creuser les outils pour voir s'ils
    correspondent au besoin (benchmarks propres, possibilité de
    récupérer les données pour une exploitation spécifique, un peu de
    contrôle d'expérience, technologie pérenne). + utiliser Marker
    pour le journal.
  - S'occuper de Pypy, ...
  - Tester Phoronix
  - Installation de Phoronix Test Suite v6.2.1
* Mercredi 25/05						     :ATTACH:
** Phoronix							   :Phoronix:
 :PROPERTIES:
  :Attachments: FirstTest.png SecondTest.png
  :ID:       d5f63874-eef8-49c2-b544-2f7391cd499d
  :END:
   + Premier test avec Phoronix -> rbenchmark -> failed to run properly
   + Deuxième test avec Phoronix -> 7zip compression -> ok
   + Présence de tests multicoeurs
   + L'injection de charges semble possible (see Fulldoc : "stressing
     your system with random workloads") même si ce n'est pas
     l'objectif premier (cf- Vincent)
   + Possibilité d'exporter les données collectées
   + L'interface semble simple à utiliser (même si je n'y suis pas
     arrivé (pour le moment))
   + S'intéresser aux tests eux-même (comment les écrire, etc...)
** Pypy								       :Pypy:
   http://speed.pypy.org/timeline/#/?exe=3,6,1,5&base=2+472&ben=ai&env=1&revs=200&equid=off
   + Fait avec Django (Framework Web python) et Codespeed (Web
     benchmark application) -> à regarder, semble intéressant !
   + Code des benchmarks :
     https://bitbucket.org/pypy/benchmarks/src/846fa56a282b/unladen_swallow/performance/
    
* Jeudi 26/05							       
** Codespeed							       :Pypy:
   https://github.com/tobami/codespeed
   - Problème d'installation (Python invalid syntax (?))
   - La commande magique : =python ./manage.py syncdb --migrate=
   - Serveur lancé : problème d'authentification cependant
   - Il faut créer un super-utilisateur : =python manage.py
     createsuperuser=
   - Lancer le serveur en _sudo_ : =sudo python manage.py runserver 8000=
   - Fournir Codespeed en données : "Codespeed is a web application to
     monitor and analyze the performance of your code" -> seulement de
     la visualisation de données
** Phoronix 							   :Phoronix:
   Résultats des tests dans
   =~/.phoronix-test-suite/test-results/<TEST>/= :
     - =composite.xml= :: : plan d'expérience
     - =system-logs/= :: : 2 tonnes de données collectées
   Méta-données des tests (par défault) dans
   =~/.phoronix-test-suite/test-profiles/pts/<TEST>/=

* Vendredi 27/05
** Phoronix							   :Phoronix:
   - Ecriture d'un bubble sort en python pour tester Phoronix,
     téléchargeable à
     https://github.com/FlorianPO/Performance-Regression-Testing/raw/master/bubble_sort.py.tar.gz
   - Ecriture des méta-données du test (à tester, ne marchera sûrement
     pas du premier coup)
*** Bubble sort TEST
    - placer le test dans :
      =~/.phoronix-test-suite/test-profiles/local/<TEST>/= (celui-ci
      devrait être visible par la commande =phoronix-test-suite
      list-available-tests=
    - il faut générer un checksum MD5 de l'archive à télécharger :
      =md5sum <FILE>= (à placer dans =download.xml=)
    - problème d'éxecutable :
      - le script généré dans install.sh doit avoir le même nom
        =<TEST-NAME>= que le dossier du test =local/<TEST-NAME>=
* Lundi 30/05
** Phoronix							   :Phoronix:
   - Output template : la sortie du programme semble devoir
     correspondre à l'OutputTemplate dans =results-definition.xml=
   - Update : la correspondance doit être exacte (sauf certains cas
     (ex: en C les retours chariot semble ignorés), à étudier...)
   - https://www.phoronix.com/forums/forum/phoronix/phoronix-test-suite/46913-custom-benchmark
*** Multiple results
    - Multiplier les champs =OutputTemplate= dans =results-definition.xml= ne suffit pas...
    - Ce n'est pas possible...
    - Regarder dans le code source -> hardcore
** Autres pistes
   - Execo, XPFlow, Expo
   - Regarder Webinar n°2 + état de l'art de ces outils (voir slide)
     - Regardé jusqu'à 35 min (partie 6)
* Mardi 31/05
** Expo								       :Expo:
*** Intro
    It aims at simplifying the experimental process on such
    distributed platforms. Works with client / server.
    - Liens :
      + http://expo.gforge.inria.fr/
    - Pros :
      + Everything is logged : IO, commands, date, ...
*** Avancement
    - Installation de Ruby
    - Installation de gem2.1
    - Problème de version : Expo et ses dépendances utilisent Ruby
      1.9.3 (current version : Ruby 2.3)
    - Installation de RVM pour installer / switcher Ruby 1.9.3
      + https://rvm.io/rvm/install 
      + http://stackoverflow.com/questions/9919739/how-to-use-the-older-version-of-ruby-1-9-2
      + Pour utiliser la commande =rvm= : =source
        /home/<USER>/.rvm/scripts/rvm= (<USER> : florian)
      + Pour switcher sur Ruby 1.9.3 : =rvm use ruby-1.9.3 --default=
    - Petit tuto Ruby : http://tryruby.org/levels/1/challenges/0
    - Impossible de lancer =./expo= -> problème syntaxe -> passage en
      Ruby 2.3.1
      + IMPOSSIBLE, rien ne marche
      + Expo utilise Ruby 1.8.7 mais Restfully nécessite Ruby >= 1.9.3
** XPFlow							     :XPFlow:
*** Intro
    XPFlow is a new approach to description and execution of
    experiments involving large-scale computer installations. The main
    idea consists in describing the experiment as workflow and using
    achievements of Business Workflow Management to reliably and
    efficiently execute it. Moreover, to facilitate the design
    process, the framework provides abstractions that hide unnecessary
    complexity from the user.
    - Liens:
      + http://xpflow.gforge.inria.fr/
      + http://xpflow.gforge.inria.fr/img/slides/slides.pdf
	* http://xpflow.gforge.inria.fr/img/slides/slides.pdf
*** Avancement
    - Installation de XPFlow
    - Lecture des slides : pas dégueux du tout
    - Permet de lancer des commandes systèmes, etc...
    - Installation de =cairo= : =gem install cairo= (pour exporter en pdf)
      + permet de visualiser le workflow
    - A tester avec Grid5000 -> demande de compte faite.
** Execo							      :Execo:
*** Intro
    Execo is a Python library that allows you to finely manage unix
    processes on thousands of remote hosts. It is well designed for :
    - prototyping experiments on distributed systems (Grid5000
      support)
    - automatize admin tasks
    - create reproducible experiments
    - Liens :
      + http://execo.gforge.inria.fr/doc/latest-stable/
      + http://execo.gforge.inria.fr/doc/latest-stable/userguide.html
*** Avancement
    - Installation de Execo et de tous ses packages optionnels.
* Mercredi 01/06
** Execo							      :Execo:
  - Obtention d'un compte Grid5000
  - Lecture de la doc d'Execo
  - A faire : comparer Execo et XPFlow
** XPFlow							     :XPFlow:
   - Liste des patterns : http://xpflow.gforge.inria.fr/docs/patterns/ :
     super cool !
   - =git clone= du projet
   - Installation de LaTeX-mk pour générer la doc
   - Recherche de la structure du pattern =info= : classe InfoRun dans
     runs.rb (peu de choses...)
* Mardi 07/06
  - Visionnage des webinars 2 et 3
  - Contacter Olivier Richard et Michael Mercier au sujet de
    l'installation d'environnement. XPFlow mélange celui-ci et le
    contrôle de l'expérience : pas une bonne idée.
* Mercredi 08/06
  - Installation de =emacs= sur Windows (=C-H v user-init-file RET= dans
    emacs pour trouver l'emplacement du fichier =.emacs=)  
  - Visionnage du webinar 1 + [[https://github.com/FlorianPO/Performance-Regression-Testing/blob/master/Webinar_1.org][prise de note]]
* Jeudi 09/06
  - Visionnage du webinar 2 + [[https://github.com/FlorianPO/Performance-Regression-Testing/blob/master/Webinar_2.org][prise de note]]
  - Docker for reproducible research :
    http://www.carlboettiger.info/assets/files/pubs/10.1145/2723872.2723882.pdf
  - SPACK + KAMELEON -> téléchargement (+ installation)
    - SPACK : Luka 
    - Dépendances : Venìcius
    - KAMELEON : Michael
  - (XPFlow) -> Contrôle de l'expérience
* Vendredi 10/06
** Spack							      :Spack:
   Petits tutos sur le PATH pour se mettre à niveau :
   - https://wiki.debian.org/EnvironmentVariables
   - http://www.generation-linux.fr/index.php?post/2008/10/15/Changer-les-dossiers-par-defaut-dans-le-PATH
   Installation de Spack
*** Liens :
    - Features :: http://software.llnl.gov/spack/features.html
    - Doc :: http://software.llnl.gov/spack/
    - Package installable ::
         http://software.llnl.gov/spack/basic_usage.html
** Kameleon							   :Kameleon:
   Installation de Kameleon
*** Liens :
    - Doc :: http://kameleon.imag.fr/index.html
* Lundi 13/06
** Kameleon							   :Kameleon:
   - Le tutoriel qui va bien :
     http://kameleon.imag.fr/grid5000_tutorial.html
   - Kameleon + Puppet :
     https://www.grid5000.fr/mediawiki/index.php/Environments_creation_using_Kameleon_and_Puppet
** Spack							      :Spack:
   - http://software.llnl.gov/spack/basic_usage.html
* Mardi 14/06
  - Lecture complète de la doc de Kameleon : fait.
  - Réunion avec Michael et Arnaud :
    + Préliminaires :      
      * Lire le /Getting started/ de G5k
        https://www.grid5000.fr/mediawiki/index.php/Getting_Started
      * Déployer une image, jouer avec les commandes, ...
      * Objectif : lancer au moins un benchmark StarPU Morse
        http://starpu.gforge.inria.fr/testing/morse/trunk/morse.html
    + Automatiser : 
      * Kameleon + Spack (pour les BLAS)
      * récupérer sur Git StarPU / Morse
      * benchmark sur les versions (en mode réel ou simulé)
	- mode simulé : éxecution des versions parallèles (Execo
          peut-il faire ceci ? Voir avec Michael)
      * logger
** Grid5000 getting started
*** Réservation
    - Dabord, la frontale :
      #+begin_src sh :session foo :results output :exports both 
      ssh fpopek@access.grid5000.fr
      #+end_src

      
      #+begin_example

      Linux access-south.grid5000.fr 3.2.0-4-amd64 #1 SMP Debian 3.2.73-2+deb7u3 x86_64
      ----- Grid'5000 - access-south.grid5000.fr -----

      Welcome to Grid'5000

      ** Connect to a site:
      ssh {grenoble,lille,luxembourg,lyon,nancy,nantes,reims,rennes}

      ** Useful links:
       - account management (password change): https://api.grid5000.fr/ui/account
       - homepage: https://www.grid5000.fr/mediawiki/index.php/Category:Portal:User
       - charter : https://www.grid5000.fr/mediawiki/index.php/Grid5000:UserCharter
       - support : https://www.grid5000.fr/mediawiki/index.php/Support

      ** Data on access.grid5000.fr :
       - your home directory on access machines (access-north and access-south)
	 is not synchronized and should not be use to store data.
       - please use ssh forwarding to send data directly to sites or
      scp files login@access.grid5000.fr:reims/ using the nfs mount point in your home

      [31m[5m
      ** Warning: 1 event in progress
      #Incident in #Sophia : hard drive failures on srv.sophia.grid5000.fr, site unavailable
      [0m[31m    https://intranet.grid5000.fr/bugzilla/show_bug.cgi?id=6967
      [0m
      Last login: Tue Jun 14 14:39:37 2016 from 129.88.54.126
#+end_example

    - Puis grenoble :
      #+begin_src sh :session foo :results output :exports both 
      ssh grenoble
      #+end_src

      
      #+begin_example
      ----- Grid'5000 - Grenoble - fgrenoble.grenoble.grid5000.fr -----

      This site has 3 clusters (see: https://api.grid5000.fr/stable/ui/visualizations/nodes.html)

      Available in queue default:
       - genepi (2008): 34 nodes (2 CPUs Intel Xeon E5420, 4 cores/CPU, 8GB RAM, 153GB HDD)
       - edel   (2008): 72 nodes (2 CPUs Intel Xeon E5520, 4 cores/CPU, 24GB RAM, 119GB SSD)
       - adonis (2010): 10 nodes (2 CPUs Intel Xeon E5520, 4 cores/CPU, 24GB RAM, 233GB HDD)

      ** Useful links:
       - account management (password change): https://api.grid5000.fr/ui/account
       - homepage: https://www.grid5000.fr/mediawiki/index.php/Category:Portal:User
       - charter : https://www.grid5000.fr/mediawiki/index.php/Grid5000:UserCharter
       - support : https://www.grid5000.fr/mediawiki/index.php/Support

      ** Others sites:
      ssh {lille,luxembourg,lyon,nancy,nantes,reims,rennes,sophia}

      Last login: Tue Jun 14 14:40:46 2016 from access-south.grid5000.fr
#+end_example

    - =oarsub -I= pour réserver une machine en mode interactif
    - Pour réserver 2 noeuds pendant 30 min :
      #+begin_src sh :session foo :results output :exports both 
      oarsub -I -l nodes=2,walltime=0:30 
      #+end_src

    - Pour réserver dans le futur
      #+begin_src sh :session foo :results output :exports both 
      oarsub -I -r '2012-12-23 16:30:00'
      #+end_src

      + =oarstat= pour voir l'historique des réservations
      + =oarstat -u= pour voir ses réservations
      + =oarstat -r <JOB_ID>= pour supprimer une réservation
    - Propriétés OAR
      #+begin_src sh :session foo :results output :exports both 
      oarsub -p "gpu='YES'"
      #+end_src

    - =oarsub -t deploy= pour déployer avec Kadeploy (/The root password
      for all Grid'5000-provided images is grid5000/)
*** Gestion des noeuds
    - =uniq $OAR_NODEFILE= liste des noeuds réservés
    - =oarsh <NODE>= utiliser un noeud réservé
    - =ssh root@<NODE>= se connecter en root sur un noeud
** Spack
   Installation :
   - =git clone https://github.com/llnl/spack.git=
   - =export PATH=$SPACK_ROOT/bin:$PATH=
   - =spack install libelf=
** StarPU
*** Installation avec Spack
    http://morse.gforge.inria.fr/chameleon/tuto_chameleon/chameleon-tutorial-2015-12-16-inria.html#sec-6-2
*** En pratique (buggué, voir le lendemain)
    Déploiement

    #+begin_src sh :session foo :results output :exports both 
    ssh grenoble.g5k (ou ssh fpopek@access.grid5000.fr puis ssh grenoble)
    ssh digitalis
    oarsub -I -t deploy
    kadeploy3 -f $OAR_NODE_FILE -e jessie-x64-big -k (problème avec Digitalis)
    ssh root@machine
    #+end_src
    
    Installation de Spack
    
    #+begin_src sh :session foo :results output :exports both 
    git clone https://github.com/fpruvost/spack
    export SPACK_ROOT=~/spack/
    export PATH=$SPACK_ROOT/bin:$PATH
    #+end_src
      
    Morse package
    
    #+begin_src sh :session foo :results output :exports both 
    cd spack
    git checkout morse
    #+end_src
    
    Installation de Chameleon

    #+begin_src sh :session foo :results output :exports both 
    spack install chameleon+examples
    #+end_src

    Installation de StarPU

    #+begin_src sh :session foo :results output :exports both 
    spack install -v chameleon@trunk~quark+examples+fxt ^starpu@svn-trunk+fxt
    spack install -v chameleon@trunk~quark+simu+examples+fxt ^starpu@svn-trunk+simgrid+fxt ^simgrid@starpumpi (pour la simulation)

    ( spack install -v chameleon@trunk~quark+examples+fxt )
    #+end_src
* Mercredi 15/06
  - Ma version de Spack ne permet pas d'installer StarPu (0.9.1) celle
  de Vinìcius (0.8.15) marche
  - Problème d'import Python -> récupération de l'image de Vinìcius
  - Problème de Spack -> envoie d'un mail à Lucas
** Environnement de Vinìcius
   #+begin_src sh :session foo :results output :exports both 
   ssh grenoble.g5k
   ssh digitalis
   oarsub -I -t deploy
   kadeploy3 -f $OAR_NODE_FILE -a imageIDCin.env -k
   #+end_src
  
   Image copiée depuis =/home/vgarciapinto/= (avec modification de
   imageIDCin.env avec mon login)

   #+begin_src sh :session foo :results output :exports both 
   ssh root@machine
   sudo apt-get update
   sudo apt-get install -y python2.7-dev
   sudo apt-get install -y vim emacs
   sudo apt-get install -y curl patch
   sudo apt-get install -y git subversion mercurial
   sudo apt-get install -y build-essential gfortran
   sudo apt-get install -y autoconf automake cmake cmake-data doxygen texinfo
   sudo apt-get install -y libtool (libtool-bin)
   sudo apt-get install -y libboost-dev
   sudo apt-get install -y gawk
   sudo apt-get install -y bison flex
   sudo apt-get install -y binutils-dev libelf-dev (libiberty-dev)
   sudo apt-get install -y libz-dev
   sudo apt-get install -y libqt4-dev freeglut3-dev
   sudo apt-get install -y environment-modules
   #+end_src

   #+begin_src sh :session foo :results output :exports both 
   git clone https://github.com/fpruvost/spack
   export SPACK_ROOT=~/spack/
   export PATH=$SPACK_ROOT/bin:$PATH
   #+end_src

   #+begin_src sh :session foo :results output :exports both 
   cd spack/
   git checkout morse
   #+end_src

   La branche morse peut (sous quelles conditions ?) ne pas marcher :

   
   #+begin_example
   Traceback (most recent call last):
     File "/root/spack//bin/spack", line 50, in <module>
       import nose
     File "/root/spack/lib/spack/external/nose/__init__.py", line 1, in <module>
       from nose.core import collector, main, run, run_exit, runmodule
     File "/root/spack/lib/spack/external/nose/core.py", line 9, in <module>
      import unittest
     File "/usr/lib/python2.7/unittest/__init__.py", line 58, in <module>
      from .result import TestResult
     File "/usr/lib/python2.7/unittest/result.py", line 10, in <module>
      from functools import wraps
   ImportError: cannot import name wraps
   #+end_example

   (semble optionnel)
   #+begin_src sh :session foo :results output :exports both 
   spack install chameleon
   #+end_src

   #+begin_src sh :session foo :results output :exports both 
   spack install chameleon~quark+fxt+starpu ^starpu+fxt
   #+end_src

   ==> Error: chameleon does not depend on starpu
* Vendredi 17/06
  Enregistrement d'une nouvelle image contenant Chameleon et Starpu (+
  toutes les dépendances nécessaires)

  #+begin_src sh :session foo :results output :exports both 
  ssh grenoble.g5k
  ssh digitalis
  oarsub -I -t deploy
  kadeploy3 -f $OAR_NODE_FILE -a image.env -k
  #+end_src

  Rappel de l'objectif : lancer un benchmark 
  http://starpu.gforge.inria.fr/testing/morse/trunk/morse.html

  #+begin_src sh :session foo :results output :exports both 
  export SPACK_ROOT=~/spack/
  export PATH=$SPACK_ROOT/bin:$PATH
  spack install -v chameleon@trunk~quark+simu+examples+fxt+starpu ^starpu@svn-trunk+simgrid+fxt ^simgrid@starpumpi (pour la simulationg, ne marche pas)
  #+end_src

  
  #+begin_example
  ==> Successfully installed simgrid
  Fetch: 11.83s.  Build: 45.30s.  Total: 57.12s.
  [+] /root/spack/opt/spack/linux-x86_64/gcc-4.7/simgrid-starpumpi-tosagznhajv6jgnrtesrrzuhppizpmp3
  Traceback (most recent call last):
    File "/root/spack//bin/spack", line 176, in <module>
      main()
    File "/root/spack//bin/spack", line 154, in main
      return_val = command(parser, args)
    File "/root/spack/lib/spack/spack/cmd/install.py", line 82, in install
      explicit=True)
    File "/root/spack/lib/spack/spack/package.py", line 927, in do_install
      make_jobs=make_jobs)
    File "/root/spack/lib/spack/spack/package.py", line 1051, in do_install_dependencies
      dep.package.do_install(**kwargs)
    File "/root/spack/lib/spack/spack/package.py", line 1008, in do_install
      spack.build_environment.fork(self, build_process)
    File "/root/spack/lib/spack/spack/build_environment.py", line 402, in fork
      setup_package(pkg)
    File "/root/spack/lib/spack/spack/build_environment.py", line 360, in setup_package
      dpkg.setup_dependent_package(pkg.module, spec)
    File "/root/spack/var/spack/repos/builtin/packages/simgrid/package.py", line 37, in setup_dependent_package
      if spec.satisfies('+smpi'):
  NameError: global name 'spec' is not defined
  ==> Error: Installation process had nonzero exit code.
  #+end_example

  Solution : remplacer =spec= par =dep_spec=

  
  #+begin_example
  ==> 'make' '-j16'
  Making all in src
  make[1]: Entering directory `/tmp/root/spack-stage/spack-stage-Bqd_mp/trunk/src'
  make[2]: Entering directory `/tmp/root/spack-stage/spack-stage-Bqd_mp/trunk/src'
    CC     libstarpu_1.3_la-barrier.lo
    CC     libstarpu_1.3_la-barrier_counter.lo
    CC     libstarpu_1.3_la-bitmap.lo
    CC     libstarpu_1.3_la-hash.lo
    CC     libstarpu_1.3_la-rwlock.lo
    CC     libstarpu_1.3_la-starpu_spinlock.lo
    CC     libstarpu_1.3_la-timing.lo
    CC     libstarpu_1.3_la-utils.lo
    CC     libstarpu_1.3_la-fxt.lo
    CC     libstarpu_1.3_la-thread.lo
    CC     libstarpu_1.3_la-rbtree.lo
    CC     libstarpu_1.3_la-graph.lo
    CC     libstarpu_1.3_la-jobs.lo
    CC     libstarpu_1.3_la-task.lo
    CC     libstarpu_1.3_la-task_bundle.lo
    CC     libstarpu_1.3_la-tree.lo
  common/fxt.c: In function ‘_starpu_profile_set_tracefile’:
  common/fxt.c:86:2: error: implicit declaration of function ‘vnsprintf’ [-Werror=implicit-function-declaration]
  cc1: some warnings being treated as errors
  make[2]: *** [libstarpu_1.3_la-fxt.lo] Error 1
  make[2]: *** Waiting for unfinished jobs....
  make[2]: Leaving directory `/tmp/root/spack-stage/spack-stage-Bqd_mp/trunk/src'
  make[1]: *** [all-recursive] Error 1
  make[1]: Leaving directory `/tmp/root/spack-stage/spack-stage-Bqd_mp/trunk/src'
  make: *** [all-recursive] Error 1
  #+end_example

  Solution : rajouter le flag *-posix* au compilateur C : 

  #+begin_src sh :session foo :results output :exports both 
  spack install -v chameleon@trunk~quark+simu+examples+fxt+starpu cflags=\"-posix\" ^starpu@svn-trunk+simgrid+fxt ^simgrid@starpumpi
  #+end_src

  
  #+begin_example
  /tmp/root/spack-stage/spack-stage-NiynFP/cmake-3.5.2/Source/kwsys/ProcessUNIX.c:189:53: error: unknown type name ‘siginfo_t’
  /tmp/root/spack-stage/spack-stage-NiynFP/cmake-3.5.2/Source/kwsys/ProcessUNIX.c: In function ‘cmsysProcess_AddCommand’:
  /tmp/root/spack-stage/spack-stage-NiynFP/cmake-3.5.2/Source/kwsys/ProcessUNIX.c:469:46: warning: incompatible implicit declaration of built-in function ‘strdup’ [enabled by default]
  /tmp/root/spack-stage/spack-stage-NiynFP/cmake-3.5.2/Source/kwsys/ProcessUNIX.c: In function ‘kwsysProcessKill’:
  /tmp/root/spack-stage/spack-stage-NiynFP/cmake-3.5.2/Source/kwsys/ProcessUNIX.c:2687:16: warning: initialization makes pointer from integer without a cast [enabled by default]
  /tmp/root/spack-stage/spack-stage-NiynFP/cmake-3.5.2/Source/kwsys/ProcessUNIX.c: In function ‘kwsysProcessesAdd’:
  /tmp/root/spack-stage/spack-stage-NiynFP/cmake-3.5.2/Source/kwsys/ProcessUNIX.c:2861:17: error: ‘struct sigaction’ has no member named ‘sa_sigaction’
  /tmp/root/spack-stage/spack-stage-NiynFP/cmake-3.5.2/Source/kwsys/ProcessUNIX.c:2861:33: error: ‘kwsysProcessesSignalHandler’ undeclared (first use in this function)
  /tmp/root/spack-stage/spack-stage-NiynFP/cmake-3.5.2/Source/kwsys/ProcessUNIX.c:2861:33: note: each undeclared identifier is reported only once for each function it appears in
  /tmp/root/spack-stage/spack-stage-NiynFP/cmake-3.5.2/Source/kwsys/ProcessUNIX.c: At top level:
  /tmp/root/spack-stage/spack-stage-NiynFP/cmake-3.5.2/Source/kwsys/ProcessUNIX.c:2950:43: error: unknown type name ‘siginfo_t’
  #+end_example

  Solution : rajouter le flag *-D_POSIX_C_SOURCE=200112L* (le flag
  -posix n'est plus nécessaire)
  http://stackoverflow.com/questions/22912674/unknown-type-name-siginfo-t-with-clang-using-posix-c-source-2-why
  
  Autre erreur de déclaration implicite (je ne vais pas toutes les noter).

  Solution : rajouter le flag *-D_GNU_SOURCE*

  #+begin_src sh :session foo :results output :exports both 
  spack install -v chameleon@trunk~quark+simu+examples+fxt+starpu cflags=\"-D_POSIX_C_SOURCE=200112L -D_GNU_SOURCE\" ^starpu@svn-trunk+simgrid+fxt ^simgrid@starpumpi
  #+end_src

  
  #+begin_example
  core/perfmodel/perfmodel_history.c: In function ‘_starpu_perfmodel_realloc’:
  core/perfmodel/perfmodel_history.c:662:2: error: ‘LONG_MAX’ undeclared (first use in this function)
  core/perfmodel/perfmodel_history.c:662:2: note: each undeclared identifier is reported only once for each function it appears in
  make[2]: *** [libstarpu_1.3_la-perfmodel_history.lo] Error 1
  make[2]: *** Waiting for unfinished jobs....
  make[2]: Leaving directory `/tmp/root/spack-stage/spack-stage-AAkAxm/trunk/src'
  make[1]: *** [all-recursive] Error 1
  make[1]: Leaving directory `/tmp/root/spack-stage/spack-stage-AAkAxm/trunk/src'
  make: *** [all-recursive] Error 1
  #+end_example

  Solution : rajouter le flag *-include limits.h*

  #+begin_src sh :session foo :results output :exports both 
  spack install -v chameleon@trunk~quark+simu+examples+fxt+starpu cflags=\"-D_POSIX_C_SOURCE=200112L -D_GNU_SOURCE -include limits.h\" ^starpu@svn-trunk+simgrid+fxt ^simgrid@starpumpi
  #+end_src

  
  #+begin_example
  CMake Error at tools/cmake/CompleteInFiles.cmake:117 (message):
  Failed to find Boost libraries.Did you install libboost-dev and
  libboost-context-dev?(libboost-context-dev is optional)
  #+end_example

** Récapitulatif
   #+begin_src sh :session foo :results output :exports both 
   ssh grenoble.g5k
   ssh digitalis
   oarsub -I -t deploy
   kadeploy3 -f $OAR_NODE_FILE -a image.env -k

   ssh root@node
   export SPACK_ROOT=~/spack/
   export PATH=$SPACK_ROOT/bin:$PATH
   spack install -v chameleon@trunk~quark+simu+examples+fxt+starpu cflags=\"-D_POSIX_C_SOURCE=200112L -D_GNU_SOURCE -include limits.h\" ^starpu@svn-trunk+simgrid+fxt ^simgrid@starpumpi
   #+end_src

   + résolution *spec* -> *dep_spec*
* Lundi 20/06
  Florent Pruvost : la branche est instable. Cette commande fonctionne + report d'un bug dans Spack
  #+begin_src sh :session foo :results output :exports both 
  spack install -v chameleon@trunk+starpu+fxt+simu+mpi ^simgrid@starpumpi
  #+end_src

  Lancement des premières simulations avec StarPU -> toutes fausses :)

  Image actuelle trop "sale", création d'une nouvelle image, exclusivement pour la simulation,
  avec le nouveau pull de Spack

  Pour le hash : =chameleon-trunk-b7vkqkzpqff7jhw4v76hmcnh7wxvqfp7=
  Lancement des simulations -> segmentation fault..
  
  Nouvelle installation :
  #+begin_src sh :session foo :results output :exports both 
  spack install -v chameleon@trunk+starpu+fxt+simu+mpi ^simgrid@starpumpi ^starpu@svn-trunk+simgrid+fxt
  #+end_src
  -> problème d'installation

  Nouvelle installation (tirée de ce qui a été fait Vendredi 17/06) :
  #+begin_src sh :session foo :results output :exports both 
  spack install -v chameleon@trunk+simu+fxt+starpu cflags=\"-D_POSIX_C_SOURCE=200112L -D_GNU_SOURCE -include limits.h\" ^starpu@svn-trunk+simgrid+fxt ^simgrid@starpumpi
  #+end_src

  Pour le hash : =chameleon-trunk-4iyjznfgw6drrrgli47trrjadryxs72e=
  Lancement des simulations -> segmentation fault..

  Installation de la version non simulée :
  #+begin_src sh :session foo :results output :exports both 
  spack install -v chameleon@trunk+starpu+fxt ^starpu@svn-trunk+fxt
  #+end_src

  Hash correspondant : =chameleon-trunk-gj5brkq45hyoavckcdaxtcpz3hjdlxmd=
  
  Cette version marche.

  Bilan : la simulation ne marche pas, des déviations très importantes
  (voir le warning) pour le mode non simulé -> quoiqu'il en soit
  l'installation avec Spack est maîtrisée

  
  #+begin_example
  ./timing/time_spotrf_tile --warmup --gpus=3 --threads=9 --nb=960 --ib=96 --n_range=48000:48000:9600
  [starpu][starpu_initialize] Warning: StarPU was configured with --with-fxt, which slows down a bit
  [starpu][_starpu_bind_thread_on_cpu] Warning: both workers 0 and 8 are bound to the same PU 0, this will strongly degrade performance
  #
  # CHAMELEON 0.9.1, ./timing/time_spotrf_tile
  # Nb threads: 9
  # Nb GPUs:    3
  # NB:         960
  # IB:         96
  # eps:        5.960464e-08
  #
  #     M       N  K/NRHS   seconds   Gflop/s Deviation
    48000   48000       1 [starpu][_starpu_update_perfmodel_history] Too big deviation for model splgsy on cpu0_impl0 (Comb0): 17470.704000 vs average 11059.039143, 7 such errors against 7 samples (+57.976690%), flushing the performance model. Use the STARPU_HISTORY_MAX_ERROR environement variable to control the threshold (currently 50%)
  [starpu][_starpu_update_perfmodel_history] Too big deviation for model splgsy on cpu0_impl0 (Comb0): 10813.469000 vs average 18872.197000, 1 such errors against 1 samples (-42.701589%), flushing the performance model. Use the STARPU_HISTORY_MAX_ERROR environement variable to control the threshold (currently 50%)
  [starpu][_starpu_update_perfmodel_history] Too big deviation for model splgsy on cpu0_impl0 (Comb0): 21952.844000 vs average 11692.761069, 29 such errors against 29 samples (+87.747307%), flushing the performance model. Use the STARPU_HISTORY_MAX_ERROR environement variable to control the threshold (currently 50%)
  [starpu][_starpu_update_perfmodel_history] Too big deviation for model splgsy on cpu0_impl0 (Comb0): 9965.069000 vs average 22145.963190, 79 such errors against 79 samples (-55.002774%), flushing the performance model. Use the STARPU_HISTORY_MAX_ERROR environement variable to control the threshold (currently 50%)
  [starpu][_starpu_update_perfmodel_history] Too big deviation for model strsm on cpu0_impl0 (Comb0): 51143.533000 vs average 82083.798857, 7 such errors against 7 samples (-37.693511%), flushing the performance model. Use the STARPU_HISTORY_MAX_ERROR environement variable to control the threshold (currently 50%)
    242.332    152.13 +-   0.00  

  #---------------------
  Worker stats:
  CPU 0                           
  	3335 task(s)
  CPU 1                           
  	6089 task(s)
  CPU 2                           
  	6095 task(s)
  CPU 3                           
  	6072 task(s)
  CPU 4                           
  	6067 task(s)
  CPU 5                           
  	6089 task(s)
  CPU 6                           
  	6073 task(s)
  CPU 7                           
  	6062 task(s)
  CPU 8                           
  	3318 task(s)
  #---------------------
  #+end_example

** A faire
   Installer Kameleon et intégrer Spack à Kameleon (lancer les
   commandes Spack depuis Kameleon)
   
* Mardi 21/06							   :Kameleon:
  Préparation d'une image pour déploiement sur Grid5000

  Rappel sur l'installation de Kameleon :

  #+begin_src sh :session foo :results output :exports both
  apt-get install ruby-dev ruby-childprocess polipo libguestfs-tools
  gem install --no-ri --no-rdoc kameleon-builder
  
  kameleon template repo add default https://github.com/oar-team/kameleon-recipes.git
  #+end_src

  Création d'un custom recipe pour grid5000 :
  
  #+begin_src sh :session foo :results output :exports both 
  kameleon new debian8_g5k default/grid5000/debian8
  #+end_src
  
  Premier déploiement d'une sur Grid5000 avec Kameleon : le recipe
  =default/grid5000/debian8.yaml= se charge de déployer lors du build

  Problème avec Git :

  #+begin_src sh :session foo :results output :exports both 
  Step 24 : setup/first_step/spack
  --> Running the step...
  [in] Cloning into 'spack'...
  [in] fatal: Not a git repository (or any of the parent directories): .git
  Starting command: "bash"
  Starting command: "ssh -A -t -F /home/florian/Bureau/Kameleon/build/debian8_g5k/ssh_config grenoble /bin/bash"
  Starting command: "ssh -A -t -F /home/florian/Bureau/Kameleon/build/debian8_g5k/ssh_config debian8_g5k /bin/bash"
  Error occured when executing the following command :

  > exec_in: git checkout morse
  #+end_src

  Source du problème : la commande =cd= ne fonctionne pas, ni =export= ->
  faire autrement

  Solution (Michael) : exporter la variable du contexte =out= vers =in= ou
  bien utiliser un fichier intermediaire
  
  Pour =cd= : grouper les comandes dans le =exec_in= avec =|= (voir cheat
  sheet yaml pour se familiariser avec la syntaxe :
  http://lzone.de/cheat-sheet/YAML). Le directory courant est remis à
  sa position initial entre chaque =exec_in=. 
* Mercredi 22/06
  A rattraper...
* Jeudi 23/06
  Intégration de Spack à Kameleon -> problème d'installation. Une
  partie des logs est cachée, ce qui n'est pas pratique.

  Utilisation d'une tour pour déployer -> problème de chemin, un
  projet Kameleon est quelque part lié à une machine (de premiers
  abords).

  BUG Kameleon : pas d'espace dans le chemin de recipe Kameleon

  Ajout d'une issue dans le GitHub de Kameleon :
  https://github.com/oar-team/kameleon/issues/84

  Problème de build avec spack :
  
  #+begin_example
  [in] Traceback (most recent call last):
  [in]   File "/root/kameleon_workdir/debian_g5k/spack/lib/spack/spack/build_environment.py", line 406, in fork
  [in]     function()
  [in]   File "/root/kameleon_workdir/debian_g5k/spack/lib/spack/spack/package.py", line 1016, in build_process
  [in]     self.install(self.spec, self.prefix)
  [in]   File "/root/kameleon_workdir/debian_g5k/spack/lib/spack/spack/multimethod.py", line 124, in __call__
  [in]     return self.default(package_self, *args, **kwargs)
  [in]   File "/root/kameleon_workdir/debian_g5k/spack/var/spack/repos/builtin/packages/starpu/package.py", line 84, in install
  [in]     subprocess.check_call("./autogen.sh")
  [in]   File "/usr/lib/python2.7/subprocess.py", line 540, in check_call
  [in]     raise CalledProcessError(retcode, cmd)
  [in] subprocess.CalledProcessError: Command './autogen.sh' returned non-zero exit status 1
  [in] ==> Error: Installation process had nonzero exit code.
  Starting command: "bash"
  Starting command: "ssh -A -t -F /home/bepo/Bureau/Kameleon/build/debian_g5k/ssh_config grenoble /bin/bash"
  Starting command: "ssh -A -t -F /home/bepo/Bureau/Kameleon/build/debian_g5k/ssh_config debian_g5k /bin/bash"
  Error occured when executing the following command :
  
  > exec_in: "git clone https://github.com/fpruvost/spack\nexport SPACK_ROOT=/root/kameleon_workdir/debian_g5k/spack/\nexport
  >   PATH=$SPACK_ROOT/bin:$PATH          \ncd spack/\ngit checkout morse\nspack install
  >   -v chameleon@trunk+starpu+fxt ^starpu@svn-trunk+fxt\n"

  #+end_example

  Rajout de dépendances supplémentaires (celles indiquées ici :
  http://morse.gforge.inria.fr/chameleon/tuto_chameleon/chameleon-tutorial-2015-12-16-inria.html#sec-1-2-1)

  Nouveau problème : 
  
  #+begin_example
  [in] checking glpk.h usability... no
  [in] checking glpk.h presence... no==> Error: Command exited with status 1:
  [in] ==> Error: Installation process had nonzero exit code.
  Starting command: "bash"
  Starting command: "ssh -A -t -F /home/bepo/Bureau/Kameleon/build/debian_g5k/ssh_config grenoble /bin/bash"
  Starting command: "ssh -A -t -F /home/bepo/Bureau/Kameleon/build/debian_g5k/ssh_config debian_g5k /bin/bash"
  Error occured when executing the following command :
  
  > exec_in: "git clone https://github.com/fpruvost/spack\nexport SPACK_ROOT=/root/kameleon_workdir/debian_g5k/spack/\nexport
  >   PATH=$SPACK_ROOT/bin:$PATH          \ncd spack/\ngit checkout morse\nspack install
  >   -v chameleon@trunk+starpu+fxt ^starpu@svn-trunk+fxt\n"
  #+end_example

  Le problème est peut-être dû au fait que la machine ne contient pas
  de GPU (ou autre chose), tout du moins, cela marchait sur Digitalis.

  Essayer de se connecter à Digitalis via le recipe Kameleon.

  Michael : faire un tunnel ssh

  -> modification de =g5k_reserv.yaml=
  
  Problème :
  
  #+begin_example
  [out] Deploying environment jessie-x64-base on grimage-9.grenoble.grid5000.fr
  [out] Resource not found /environments
  Starting command: "bash"
  Starting command: "ssh -A -t -F /home/bepo/Bureau/Kameleon/build/debian_g5k/ssh_config digitalis /bin/bash"
  Error occured when executing the following command :
  
  > exec_out: kadeploy3 -e jessie-x64-base -m $machine -k
  #+end_example

  -> Digitalis ne possède pas le répertoire /environments

  On va réserver une machine avec des GPU à la main :
  #+begin_src sh :session foo :results output :exports both 
  oarsub -p "gpu='YES'" -t deploy
  #+end_src

  Ajout dans la recette g5k (méthode brutale)

  #+begin_src sh :session foo :results output :exports both 
  [out] The out_context has been initialized
  [out] Deploying image jessie-x64-base with kadeploy
  [out] Submitting a job for deployment
  [out] Properties: (gpu='YES') AND deploy = 'YES'
  [out] [ADMISSION RULE] Modify resource description with type constraints
  [out] Generate a job key...
  [out] There are not enough resources for your request
  [out] Oarsub failed: please verify your request syntax or ask for support to your admin.
  #+end_src

  Aka : Comment se faire jeter par Grid5000 ?

  Solution : déployer une image .tgz sur Digitalis (l'image de Vinìnius)

  En attendant : modifier la recette de façon propre (avec des
  variables globales) -> DONE

  Pour voir les caractères speciaux dans vim : =:set list=    
* Lundi 27/06							      :Execo:
  Tuto fourni pour Michael :
  https://www.grid5000.fr/mediawiki/index.php/Execo_Practical_Session

  Utiliser Spack dans Execo ? Spack installe et _compile_. Réponse : OUI.

  Installation locale d'Execo pour tester + récupération d'un test de
  Michael : ce test comprend la réservation et le déploiement d'un
  benchmark sur Grid5000. Ceci est fait par Kameleon, il convient de
  pouvoir donner à Execo ces options de réservations (nombres de
  noeuds, walltime, ...)

  Grid5000 sur Grenoble down -> impossible de déployer sur Digitalis

  Lecture approfondie de la doc Execo
** A faire
   - Inclure les données de Kameleon dans Execo (voir Michael si
     besoin)
   - Piloter avec Execo
   - Déployer
* Mardi 28/06
  Intégration de Execo à Kameleon : Kameleon se charge de déployer sur
  Grid5000 et fournit au script Execo un certain nombre
  d'informations : le site, l'ID du job (grep dans le recipe
  Kameleon), le nombre de noeud ainsi que le walltime.

  Question (voir Michael) : les variables d'environnement
  restent-elles présentes lors de toute la durée du recipe Kameleon ?
  (espérer que oui) -> OUI

  Problème d'installation d'environnement :
  
  #+begin_example
  [in] Installing new version of config file /etc/init.d/nscd ...
  [in] 
  [in] Configuration file `/etc/nscd.conf'
  [in]  ==> Modified (by you or by a script) since installation.
  [in]  ==> Package distributor has shipped an updated version.
  [in]    What would you like to do about it ?  Your options are:
  [in]     Y or I  : install the package maintainer's version
  [in]     N or O  : keep your currently-installed version
  [in]       D     : show the differences between the versions
  [in]       Z     : start a shell to examine the situation
  [in]  The default action is to keep your current version.
  [in] *** nscd.conf (Y/I/N/O/D/Z) [default=N] ? 
  #+end_example

  L'opération est bloquante (entrer un caractère est sans effet) :
  impossibilité de tester (voir Michael)

  A faire : intégrer Spack dans Execo (et non dans Kameleon)
* Mercredi 29/06
  Michael : correctif du bug du Mardi 28/06, utiliser :
  
  #+begin_src sh :session foo :results output :exports both 
  -o Dpkg::Options::="--force-confnew"
  #+end_src

  Ceci arrive fréquemment, voire systématiquement et semble intervenir
  lorsque une même machine est déployée plusieurs fois (?) ->
  utilisation des variables d'environnement dans Kameleon pour alléger
  les recipes.

  
  #+begin_example
  [in] E: dpkg was interrupted, you must manually run 'dpkg --configure -a' to correct the problem. 
  [in] Fetched 21.3 MB in 3s (6,288 kB/s)
  Starting command: "bash"
  Starting command: "ssh -A -t -F /home/florian/Bureau/Polaris/Kameleon/build/debian_g5k/ssh_config grenoble /bin/bash"
  Starting command: "ssh -A -t -F /home/florian/Bureau/Polaris/Kameleon/build/debian_g5k/ssh_config debian_g5k /bin/bash"
  Error occured when executing the following command :
  
  > exec_in: apt-get -o Acquire::Check-Valid-Until=false -y --force-yes update
  Press [r] to retry
  Press [c] to continue with execution
  Press [a] to abort execution
  Press [l] to switch to local_context shell
  Press [o] to switch to out_context shell
  Press [i] to switch to in_context shell
  answer ? [c/a/r/l/o/i]:  i
  User choice: [i] launch in_context
  Starting interactive shell
  Starting interactive command: "source /var/lib/gems/2.1.0/gems/kameleon-builder-2.7.2/contrib/kameleon_bashrc.sh 2> /dev/null; ssh -A -t -F /home/florian/Bureau/Polaris/Kameleon/build/debian_g5k/ssh_config debian_g5k /bin/bash --rcfile /root/kameleon_workdir/debian_g5k/kameleon_scripts/in/bash_rc"
  (in_context) root@adonis-3: /root/kameleon_workdir/debian_g5k # dpkg --configure -a
  Setting up bash (4.3-11+b1) ...
  
  Configuration file '/etc/skel/.bashrc'
  ==> Modified (by you or by a script) since installation.
  ==> Package distributor has shipped an updated version.
  What would you like to do about it ?  Your options are:
  Y or I  : install the package maintainer's version
  N or O  : keep your currently-installed version
  D     : show the differences between the versions
  Z     : start a shell to examine the situation
  The default action is to keep your current version.
  *** .bashrc (Y/I/N/O/D/Z) [default=N] ? Y
  Installing new version of config file /etc/skel/.bashrc ...
  update-alternatives: using /usr/share/man/man7/bash-builtins.7.gz to provide /usr/share/man/man7/builtins.7.gz (builtins.7.gz) in auto mode
  (in_context) root@adonis-3: /root/kameleon_workdir/debian_g5k # exit
  Saved ENV in /root/kameleon_workdir/debian_g5k/kameleon_scripts/in/bash_env file
  Shared connection to debian_g5k closed.
  Getting back to Kameleon...
  Press [r] to retry
  Press [c] to continue with execution
  Press [a] to abort execution
  Press [l] to switch to local_context shell
  Press [o] to switch to out_context shell
  Press [i] to switch to in_context shell
  answer ? [c/a/r/l/o/i]:  r
  ...
  [in] Get:11 http://ftp.debian.org jessie-backports/non-free Translation-en/DiffIndex [7,330 B]
  [in] Fetched 424 kB in 2s (175 kB/s)
  [in] Reading package lists...
  [in] W: Ignoring Provides line with DepCompareOp for package python-cffi-backend-api-max
  [in] W: Ignoring Provides line with DepCompareOp for package python-cffi-backend-api-min
  [in] W: Ignoring Provides line with DepCompareOp for package python3-cffi-backend-api-max
  [in] W: Ignoring Provides line with DepCompareOp for package python3-cffi-backend-api-min
  [in] W: You may want to run apt-get update to correct these problems
  #+end_example

  Modification à faire de la recette Kameleon pour prendre en compte /
  déployer sur plusieurs noeuds (=$OAR_NODE_FILES= n'est pas atteignable
  directement)

  Erreur lors de l'installation de Kameleon dans les machines (?) :
  #+begin_src sh :session foo :results output :exports both 
  useradd -m kameleon -s /bin/bash
  #+end_src
  
  #+begin_example
  [in] useradd: cannot create directory /home/kameleon
  #+end_example

  Source des problèmes : conflit entre le déploiement d'un environnement
  de base et d'un .tgz
* Jeudi 30/06
  Création de deux recipes distinctes : une basée sur debian8, l'autre
  basée sur un .tgz

  Problème avec HWLOC :
  
  #+begin_example
  [in] checking for FFTW... checking for FFTWF... checking for FFTWL... checking for HWLOC... configure: error: libhwloc was not found on your system. If the target machine is hyperthreaded the performance may be impacted a lot.  It is strongly recommended to install libhwloc. However, if you really want to use StarPU without enabling libhwloc, please restart configure by speci==> Error: Command exited with status 1:
  [in] ==> Error: Installation process had nonzero exit code.
  #+end_example

  HWLOC est pourtant bien installé -> envoie d'un mail à Luka

  Le recipe custom marche pourtant -> problème avec le debian8 de base
  
* Lundi 04/07
  Récupérer le _dernier_ jobID

  
  #+begin_example
  Job id     Name           User           Submission Date     S Queue
  ---------- -------------- -------------- ------------------- - ----------
  812911     a289d67b66d2   fpopek         2016-07-04 11:28:31 R default   
  812917                    fpopek         2016-07-04 11:33:09 R default   
  #+end_example

  Commande : =oarstat -u | tail -n 1 | grep -o -E '[0-9]+' | head -n 1=

  Frontale grenobe.g5k down -> impossible de récupérer mon image .tgz :'(
  
  Mot de passe non reconnu sur grenoble -> attente

  Déploiement sur lyon avec le recipe =debian8=
 
  Problème récurrent : kameleon crée l'utilisateur /kameleon/ mais il
  peut déjà exister (il suffit alors de sauter l'étape)

  Mise en place du script execo -> à placer dans
  =build/$${kameleon_workdir}/= -> à changer 

  Ne jamais appeller un script python du même nom que les modules
  qu'il utilise !

  Problème avec le walltime donné à execo :

  
  #+begin_example
  install --user execo\npython execo_script.py lyon $job_id 1
  >   1:00:00\n"
  #+end_example

  -> le problème vient de =$job_id= qui est nulle ! -> utilisation d'un
     fichier inter-contexte
* Mardi 05/07
  Premier lancement de Spack dans Execo :

  
  #+begin_example
  [in] 2016-07-05 10:22:20,655 INFO: command line arguments: ['execo_script.py', 'grenoble', '1711869', '1', '1:00:00']
  [in] 2016-07-05 10:22:20,655 INFO: command line: execo_script.py grenoble 1711869 1 1:00:00
  [in] 2016-07-05 10:22:20,655 INFO: run in directory /root/kameleon_workdir/custom_debian_g5k/results_2016-07-05--10-22-20
  [in] 2016-07-05 10:37:20,684 INFO: Starting StarPU installation...
  [in] 2016-07-05 10:37:20,684 INFO: StarPU installation DONE...
  [in] 2016-07-05 10:37:20,694 WARNING: terminated: <Process('spack install -v chameleon@trunk+starpu+fxt ^starpu@svn-trunk+fxt', name=spack install -v chameleon@trunk+sta..., started=True, start_date=2016-07-05 10:37:20+00:00, ended=True, end_date=2016-07-05 10:37:20+00:00, killed=False, error=True, error_reason=[Errno 2] No such file or directory, timeouted=False, expect_fail=False, write_error=False, exit_code=None, ok=False, pid=None)>
  [in] stdout:
  [in] 
  [in] stderr:
  [in] 
  [in] 2016-07-05 10:37:20,700 INFO: Delete job: [(1711869, 'grenoble')]
  #+end_example

  -> erreur d'installation (voir le warning)

  Plutôt que d'attendre 20 minutes à chaque fois, création d'un script
  execo local (sans tenir compte de la gestion de Grid5000)

  -> un des package n'existait plus (l'utilisation de =apt-get -m= dans le
     recipe kameleon ne fonctionne pas ! Solution : individualiser
     l'installation des packages)

  Besoin de récupérer la sortie standard de Spack dans Execo.
  Michael : utiliser =stdout= et =stdout_handler=

  
  #+begin_example
  [in] 2016-07-05 15:12:50,547 INFO: command line arguments: ['execo_script.py', 'grenoble', '1711875', '1', '1:00:00']
  [in] 2016-07-05 15:12:50,547 INFO: command line: execo_script.py grenoble 1711875 1 1:00:00
  [in] 2016-07-05 15:12:50,547 INFO: run in directory /root/kameleon_workdir/custom_debian_g5k/results_2016-07-05--15-12-50
  [in] 2016-07-05 15:27:50,576 INFO: Starting StarPU installation...
  [in] 2016-07-05 15:27:50,586 WARNING: terminated: <Process('spack install -v chameleon@trunk+starpu+fxt ^starpu@svn-trunk+fxt', name=spack install -v chameleon@trunk+sta..., started=True, start_date=2016-07-05 15:27:50+00:00, ended=True, end_date=2016-07-05 15:27:50+00:00, killed=False, error=True, error_reason=[Errno 2] No such file or directory, timeouted=False, expect_fail=False, write_error=False, exit_code=None, ok=False, pid=None)>
  [in] stdout:
  [in] 
  [in] stderr:
  [in] 
  [in] 2016-07-05 15:27:50,592 INFO: StarPU installation DONE...
  [in] 2016-07-05 15:27:50,592 INFO: Error : [Errno 2] No such file or directory
  [in] 2016-07-05 15:27:50,592 INFO: Spack stdout : 
  [in] 2016-07-05 15:27:50,592 INFO: Delete job: [(1711875, 'grenoble')]
  #+end_example

* Mercredi 06/07
  L'erreur semble provenir de Python et non de Spack :
  http://stackoverflow.com/questions/15725273/python-oserror-errno-2-no-such-file-or-directoryq

  Utiliser : =python ./execo_script= ou =os.path.abspath()=
  -> ne marche toujours pas
  -> création d'un recipe local

  -> problème venant de l'utilisation de Spack dans Execo
  -> problème de variable d'environnement -> facile à régler (ouf !)

  HS : avertissement Grid5000 (175% of daily allowance) -> il serait
  temps que cela marche :)

  Installation de Spack dans Execo -> ça marche !

  Mise en place d'un breakpoint pour vérifier les installations :
  
  #+begin_example
  IN_CONTEXT :
    Kameleon_working_dir : /home/root/kamaleon_workdir/
    Recipe deployed : /home/root/kameleon_workdir/custom_debian_g5k/ (custom_debian_g5k est le nom du recipe) -> default in_context
    Spack : /home/root/kameleon_workdir/custom_debian_g5k/spack/
    Execo : /home/root/kameleon_workdir/custom_debian_g5k/
  
  OUT_CONTEXT:
    Kameleon_working_dir : /home/fpopek/kamaleon_workdir/
    Recipe deployed : /home/fpopek/kameleon_workdir/custom_debian_g5k/ (custom_debian_g5k est le nom du recipe) -> default out_context
      -> info OAR
      -> dans kameleon_scripts/out/ : toutes les commandes utilisées

  LOCAL_CONTEXT:
    Kameleon_working_dir : /home/bepo/Bureau/custom/
    Recipe deployed : /home/bepo/Bureau/custom/build/custom_debian_g5k (custom_debian_g5k est le nom du recipe) -> default local_context
  #+end_example
  
  La recipe G5K de base ne nettoie pas les réservations ! (d'où
  l'avertissement) -> l'ajouter, puis pull request dans le git de
  Kameleon ou envoyer le code à Michael.

  Les variables d'environnement du contexte OUT sont elles préservées ?
* Jeudi 07/07
  Ajout d'un hook dans le recipe kameleon pour nettoyer la réservation
  G5k -> ça marche bien !

  Conservation des variables d'environnement dans le context IN :
  parfois buggué 

  Conservation des variables d'environnement dans le
  context OUT : ok

  Problème de hook : =on_export_clean= intervient peu après le boostrap
  -> envoie d'un mail à Michael -> fausse alerte

  Report du bug de contexte IN à Michael -> ajout d'une issue dans
  Github : https://github.com/oar-team/kameleon/issues/86

** A faire
   Récupérer les données dans le contexte local

   
   #+begin_example
   Dans IN :
   Récupérer kameleon_scripts/ -> fait
   Récupérer results_XXX/ (ex : results_2016-07-07--11-34-18/) -> créer un dossier execo
  
   Dans OUT :
   Récupérer kameleon_scripts/ -> fait
   Récupérer les infos de réservations : -> fait
   OAR.d7c379dee39f.1711919.stdout
   OAR.d7c379dee39f.1711919.stderr
   ssh_config
   #+end_example
   
   Utiliser les pipes (comment passer en dossier par le pipe ?) ->
   passer par tar.gz
* Lundi 11/07
  Récupération des infos générées par Kameleon

  Récupération des infos machines (linker à StarPU)

  Phase finale : lancer StarPU / récupérer ses infos
  http://starpu.gforge.inria.fr/testing/morse/trunk/morse.html

  - Trouver comment Spack gère les emplacements d'installation
    https://groups.google.com/forum/#!msg/spack/-4DvgF3QKTE/wQQvDb26DAAJ

    Le script à exécuter se trouve dans : {StarPU installation}/lib/chameleon/timing/
  - Trouver comment installer StarPU / Simgrid >:(
    http://morse.gforge.inria.fr/spack/spack.html#sec-2-1-1-7-2

    -> impossible !

    Genre d'erreurs obtenues :
    
    #+begin_example
    core/simgrid.c:224:2: error: too many arguments to function 'xbt_cfg_set_int'
    xbt_cfg_set_int(_sg_cfg_set, "contexts/stack_size", stack_size);
    #+end_example

    Cette fonction ne prend que deux arguments !
    http://simgrid.gforge.inria.fr/simgrid/3.13/doc/group__XBT__cfg__use.html#ga6940aacb7b28c261e5468a5500758679
    http://simgrid.gforge.inria.fr/simgrid/3.14/doc/group__XBT__cfg__use.html

    Luka et Florent n'y arrivent pas non plus. Arnaud : laisser tomber

  Ecriture du programme Execo exécutant StarPU (à tester)
* Mardi 12/07
  Problème avec G5k -> ssh anormalement long -> tester execo pas
  possible :(

  Après quelques minutes -> lancement

  Quelques soucis supplémentaires : 

  
  #+begin_example
  [in] Err http://ftp.fr.debian.org wheezy Release.gpg
  [in]   Could not connect to proxy:3128 (172.16.31.113). - connect (113: No route to host)
  [in] Err http://security.debian.org wheezy/updates Release.gpg
  [in]   Could not connect to proxy:3128 (172.16.31.113). - connect (113: No route to host)
  #+end_example

  Michael : pas besoin des proxys sur G5k dorénavant -> je n'en
  utilisais pas. Problème G5k ? voir Bastien

  Ecriture d'un sweeper python
* Mercredi 13/07
  A rattraper...
* Lundi 18/07
  Séparation de Kameleon et de Execo : Kameleon crée une image .tgz,
  Execo déploie l'image

  Execo doit être lancé depuis la frontale, sinon il faut modifier son
  .ssh et son .execo.conf.py -> utiliser une deuxième recette Kameleon
  ?

  Création d'une deuxième recette Kameleon pour Execo

  Le fichier .env crée par la première recette n'est pas exact !

  Fatal error :
  
  #+begin_example
  Error : undefined method `read_nonblock' for nil:NilClass
  Unfortunately, a fatal error has occurred : undefined method `read_nonblock' for nil:NilClass.
  #+end_example

  Ce que dit le mode debug :
  
  #+begin_example
  Error : undefined method `read_nonblock' for nil:NilClass
  /var/lib/gems/1.9.1/gems/kameleon-builder-2.7.3/lib/kameleon/shell.rb:273:in `read_io': undefined method `read_nonblock' for nil:NilClass (NoMethodError)
	from /var/lib/gems/1.9.1/gems/kameleon-builder-2.7.3/lib/kameleon/shell.rb:102:in `init_shell_cmd'
	from /var/lib/gems/1.9.1/gems/kameleon-builder-2.7.3/lib/kameleon/shell.rb:86:in `send_file'
	from /var/lib/gems/1.9.1/gems/kameleon-builder-2.7.3/lib/kameleon/context.rb:152:in `send_file'
	from /var/lib/gems/1.9.1/gems/kameleon-builder-2.7.3/lib/kameleon/context.rb:109:in `pipe'
	from /var/lib/gems/1.9.1/gems/kameleon-builder-2.7.3/lib/kameleon/engine.rb:294:in `exec_cmd'
	from /var/lib/gems/1.9.1/gems/kameleon-builder-2.7.3/lib/kameleon/engine.rb:247:in `safe_exec_cmd'
	from /var/lib/gems/1.9.1/gems/kameleon-builder-2.7.3/lib/kameleon/engine.rb:231:in `block (3 levels) in do_steps'
	from /var/lib/gems/1.9.1/gems/kameleon-builder-2.7.3/lib/kameleon/engine.rb:230:in `each'
	from /var/lib/gems/1.9.1/gems/kameleon-builder-2.7.3/lib/kameleon/engine.rb:230:in `block (2 levels) in do_steps'
	from /var/lib/gems/1.9.1/gems/kameleon-builder-2.7.3/lib/kameleon/step.rb:195:in `block in sequence'
	from /var/lib/gems/1.9.1/gems/kameleon-builder-2.7.3/lib/kameleon/step.rb:195:in `each'
	from /var/lib/gems/1.9.1/gems/kameleon-builder-2.7.3/lib/kameleon/step.rb:195:in `sequence'
	from /var/lib/gems/1.9.1/gems/kameleon-builder-2.7.3/lib/kameleon/engine.rb:202:in `block in do_steps'
	from /var/lib/gems/1.9.1/gems/kameleon-builder-2.7.3/lib/kameleon/step.rb:227:in `block in sequence'
	from /var/lib/gems/1.9.1/gems/kameleon-builder-2.7.3/lib/kameleon/step.rb:227:in `each'
	from /var/lib/gems/1.9.1/gems/kameleon-builder-2.7.3/lib/kameleon/step.rb:227:in `sequence'
	from /var/lib/gems/1.9.1/gems/kameleon-builder-2.7.3/lib/kameleon/engine.rb:191:in `do_steps'
	from /var/lib/gems/1.9.1/gems/kameleon-builder-2.7.3/lib/kameleon/engine.rb:526:in `block in build'
	from /var/lib/gems/1.9.1/gems/kameleon-builder-2.7.3/lib/kameleon/engine.rb:525:in `each'
	from /var/lib/gems/1.9.1/gems/kameleon-builder-2.7.3/lib/kameleon/engine.rb:525:in `build'
	from /var/lib/gems/1.9.1/gems/kameleon-builder-2.7.3/lib/kameleon/cli.rb:314:in `build'
	from /var/lib/gems/1.9.1/gems/thor-0.19.1/lib/thor/command.rb:27:in `run'
	from /var/lib/gems/1.9.1/gems/thor-0.19.1/lib/thor/invocation.rb:126:in `invoke_command'
	from /var/lib/gems/1.9.1/gems/thor-0.19.1/lib/thor.rb:359:in `dispatch'
	from /var/lib/gems/1.9.1/gems/thor-0.19.1/lib/thor/base.rb:440:in `start'
	from /var/lib/gems/1.9.1/gems/kameleon-builder-2.7.3/lib/kameleon/cli.rb:357:in `start'
	from /var/lib/gems/1.9.1/gems/kameleon-builder-2.7.3/bin/kameleon:18:in `<top (required)>'
	from /usr/local/bin/kameleon:23:in `load'
	from /usr/local/bin/kameleon:23:in `<main>'
  #+end_example

  Problème de gem : https://github.com/bundler/bundler/issues/2915

  Il va falloir générer une nouvelle image ne comportant pas ce bug...

  Solution à tester : passer à Debian7
* Mardi 19/07
  Passage à Debian7 : même erreur...

  -> problème de pipe : ne pas appeller un pipe en 1ère commande :
  https://github.com/oar-team/kameleon/issues/89

  Comportement singulier (pas une erreur) :
  
  #+begin_example
  OpenSSH_6.6.1, OpenSSL 1.0.1f 6 Jan 2014
  debug1: Reading configuration data /home/bepo/Bureau/debian7/execution/build/execo_recipe/ssh_config
  debug1: /home/bepo/Bureau/debian7/execution/build/execo_recipe/ssh_config line 1: Applying options for *
  debug1: /home/bepo/Bureau/debian7/execution/build/execo_recipe/ssh_config line 15: Applying options for grenoble
  debug1: auto-mux: Trying existing master
  debug2: fd 3 setting O_NONBLOCK
  debug2: mux_client_hello_exchange: master version 4
  debug3: mux_client_forwards: request forwardings: 0 local, 0 remote
  debug3: mux_client_request_session: entering
  debug3: mux_client_request_alive: entering
  debug3: mux_client_request_alive: done pid = 5299
  debug3: mux_client_request_session: session request sent
  debug1: mux_client_request_session: master session id: 4
  #+end_example

  Spack : =spack location= ne marche pas. Utiliser =spack location -i=
  (Vinìcius)

  Execo : le répertoire courant revient à sa valeur par défaut entre
  deux process -> faire de grande commandes

  Premiers résultats de StarPU :
  
  #+begin_example
  #
  # CHAMELEON 0.9.1, ./timing/time_spotrf_tile
  # Nb threads: 9
  # Nb GPUs:    3
  # NB:         960
  # IB:         96
  # eps:        5.960464e-08
  #
  #     M       N  K/NRHS   seconds   Gflop/s Deviation
  48000   48000       1   256.229    143.88 +-   0.00
  #+end_example

  Ajout des lignes de codes dans Kameleon permettant de récupérer ces
  résultats

  Un peu léger non ? Non, c'est ça. 143 Gflop/s c'est très nul (~2000
  sur http://starpu.gforge.inria.fr/testing/morse/trunk/morse.html)

  Deuxième lancemement, problème d'installation (WTF !) :
  
  #+begin_example
  [in] c.satisfies('+magma'):
  [in]      89                   # Enable MAGMA here.
  [in]      90                   cmake_args.extend(["-DCHAMELEON_USE_MAGMA=ON"])
  [in]      91               if spec.satisfies('+fxt'):
  [in]      92                   # Enable FxT here.
  [in]      93                   if spec.satisfies('chameleon@0.9.0:0.9.1'):
  [in]      94                       cmake_args.extend(["-DCHAMELEON_USE_FXT=ON"])
  [in]      95                   else:
  [in]      96                       cmake_args.extend(["-DCHAMELEON_ENABLE_TRACING=ON"])
  [in]      97               if spec.satisfies('+simu'):
  [in]      98                   # Enable SimGrid here.
  [in]      99                   cmake_args.extend(["-DCHAMELEON_SIMULATION=ON"])
  [in]      100              if spec.satisfies('+quark') and spec.satisfies('+starpu'):
  [in]      101                  raise RuntimeError('variant +quark and +starpu are mutually exclusive, please choose one.')
  [in]      102              if spec.satisfies('~quark') and spec.satisfies('~starpu'):
  [in]      103                  raise RuntimeError('Chameleon requires a runtime system to be enabled, either +quark or +starpu, please choose one.')
  [in]      104              if spec.satisfies('+quark'):
  [in]      105                  # Enable Quark here.
  [in]      106                  cmake_args.extend(["-DCHAMELEON_SCHED_QUARK=ON"])
  [in]      107              else:
  [in]      108                  cmake_args.extend(["-DCHAMELEON_SCHED_QUARK=OFF"])
  [in]      109              if spec.satisfies('+starpu'):
  [in]      110                  # Enable StarPU here.
  [in]      111                  starpu = self.spec['starpu']
  [in]      112                  cmake_args.extend(["-DCHAMELEON_SCHED_STARPU=ON"])
  [in]      113                  cmake_args.extend(['-DSTARPU_DIR=%s' % starpu.prefix])
  [in]      114              else:
  [in]      115                  cmake_args.extend(["-DCHAMELEON_SCHED_STARPU=OFF"])
  [in]      116  
  [in]      117              if spec.satisfies('~simu'):
  [in]      118                  blas = self.spec['blas']
  [in]      119                  cblas = self.spec['cblas']
  [in]      120                  lapack = self.spec['lapack']
  [in]      121                  lapacke
  [in] stderr:
  [in] ==> Error: Command exited with status 2:
  [in] ==> Error: Installation process had nonzero exit code.
  #+end_example

  Troisième lancement : OK -> bizarre

** A faire
   Récupérer les sorties standards de TOUS les process (installation,
   etc...) -> modifier le scipt Execo -> Fait

   Le script de Luka ne semble pas récupérer d'informations sur les
   GPU

   Trouver pourquoi les résultats sont si bas, peut-être un manque de
   configuration ?
   http://starpu.gforge.inria.fr/testing/morse/trunk/plafrim-trunk-plafrim-morse_trunk_chameleon_HEAD_seq.sl.o233738
   
   #+begin_example
   config.status: executing executable-scripts commands
   configure:
   
	CPUs   enabled: yes
	CUDA   enabled: yes
	OpenCL enabled: yes
	SCC    enabled: no
	MIC    enabled: no
   
	Compile-time limits
	(change these with --enable-maxcpus, --enable-maxcudadev,
	--enable-maxopencldev, --enable-maxmicdev, --enable-maxnodes,
        --enable-maxbuffers)
        (Note these numbers do not represent the number of detected
	devices, but the maximum number of devices StarPU can manage)
   
	Maximum number of CPUs:           64
	Maximum number of CUDA devices:   4
	Maximum number of OpenCL devices: 8
	Maximum number of SCC devices:    0
	Maximum number of MIC threads:    0
	Maximum number of memory nodes:   16
	Maximum number of task buffers:   8
   
	GPU-GPU transfers: yes
	Allocation cache:  yes
   
	Magma enabled:     no
	BLAS library:      mkl
	hwloc:             yes
	FxT trace enabled: no
	StarPU-Top:        no
   
        Documentation:     no
        Examples:          no
   
	StarPU Extensions:
	       MPI enabled:                                 yes
	       MPI test suite:                              yes
	       FFT Support:                                 yes
	       GCC plug-in:                                 no
	       GCC plug-in test suite (requires GNU Guile): no
	       OpenMP runtime support enabled:              no
	       SOCL enabled:                                no
               SOCL test suite:                             no
               Scheduler Hypervisor:                        yes
               simgrid enabled:                             no
               ayudame enabled:                             no
   #+end_example
* Mercredi 20/07
  Pour récupérer à partir d'une révision SVN :
  http://software.llnl.gov/spack/spack.html?highlight=git#spack.fetch_strategy.SvnFetchStrategy

  Doc : http://software.llnl.gov/spack/packaging_guide.html

  Il faut re-écrire le package StarPU pour accepter les différentes
  révisions SVN

  Un fichier CSV contient les révisions à tester (on pourra y mettre
  également un jeu d'options de compilation à tester). A partir de ce
  fichier CSV, on génère le package Spack correspondant (avec un
  script python), enfin on
  l'utilise dans Execo.

  Création des générateurs de packages Chameleon et StarPU, et du
  fichier CSV

  Import de ces fichiers dans la recette Execo

  -> ça marche ! (facile)

** Exploitation des données
   Exploiter les données avec :
   http://rmarkdown.rstudio.com/flexdashboard/ 
   (il faut juste récupérer les Gflop/s)

   -> Installation de RStudio
  
* Jeudi 21/07
  Peaufinnage : le fichier CSV contient un header, un module python
  (CSVHeader) permet de gérer cela facilement entre tous les scripts
  utilisant le header

  -> utilisation d'un .tar pour passer tous les scripts
  -> recipe plus propre

  PS: la commande tar est une horreur

  Création d'un script récupérant les données calculées en CSV
* Lundi 25/07
  Fin de l'écriture du script

  Ajout des fermetures de fichier avec =close()= dans les scripts python
  (plus propre)

  Installation manuelle de R 3.2.5 (les packages par défaut ne
  déppassent pas 3.0.2) -> long

  #+begin_example
  Télécharger l'archive .tar..gz
  Exécuter : ./configuration --enable-R-shrlib=yes
  Exécuter : make
  Remplacer le binaire à l'endroit donné par =which R=
  #+end_example

  Première utilisation de flexdashboard : long à charger
  http://rmarkdown.rstudio.com/authoring_shiny.html#deployment
  http://rmarkdown.rstudio.com/flexdashboard/shiny.html

  Le mieux est encore de regarder le code source des exemples :
  http://rmarkdown.rstudio.com/flexdashboard/examples.html

  Pour des courbes :
  https://beta.rstudioconnect.com/jjallaire/htmlwidgets-ggplotly-geoms/#geom_density
* Mardi 26/07
  Création du Markdown

  Dépendances (celles utilisées dans les exemples flashdashboard):
  - ggplot2
  - plotly (nécessite =apt-get install libssl-dev libcurl4-openssl-dev=)
  - plyr
  - flexdashboard

  X11 introuvable -> pour Debian : =apt-get install xorg-dev=

  Librairie readline introuvable : =apt-get install libreadline-dev=

  -> recompilation de R -> ça marche

  Première visualisation des résultats : ça marche bien !

  Pour rendre ça joli : http://docs.ggplot2.org/0.9.2.1/theme.html

  Utiliser Shiny pour rendre ça encore plus interactif

  A lire :
  - http://starpu-simgrid.gforge.inria.fr/misc/SIGOPS_paper.pdf
  - Git Scott Shacon -> youtube
  - Webinar 4
  - http://orgmode.org/worg/org-contrib/org-git-link.html
  
