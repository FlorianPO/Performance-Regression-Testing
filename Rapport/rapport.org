=Les titres marqués :Moodle: sont les parties qui me sont imposées=

* TODO Page de garde
  =A la fin=

* TODO Abstract
  =Intro pompeuse :)=

  De tout temps la communauté scientifique n'a cessé de croître grâce
  aux échanges, permettant aux scientifiques de baser leurs travaux
  sur ceux préalablement établis par d'autres. Ces échanges permettent
  également de crédibiliser les résultats trouvés en décrivant les protocoles
  expérimentaux, afin que quiconque puisse de son côté les
  vérifier. L'informatique ne dérogue pas à ce principe, néanmoins,
  le nombre de paramètres à prendre en compte et les différences entre
  machines rendent ce processus de partage épineux, autant pour celui
  qui souhaite décrire précisément son expérience que pour celui qui
  souhaite la reproduire.

  Dans ce document, nous abordons le problème de la reproductibilité
  des expériences, en particulier dans le domaine HPC (High
  Performance Computing), selon deux aspects qui sont : le contrôle de
  l'envrironnement et le pilotage de l'expérience. On y présentera
  notre solution basée sur des technologies développées à l'Inria
  permettant de déployer un envrionnement afin d'y conduire des
  expériences (runtime). L'objectif final est d'évaluer les
  performances (/benchmarker/) de StarPU tout au long de son évolution
  afin d'y déceler de potentielles régressions entre deux versions,
  tout en ayant un contrôle parfait de l'environnement et de
  l'expérience.

  =Ne pas évoquer StarPU tout de suite ?=
 
* TODO Sommaire
  =A la fin=

* TODO Introduction
  L'informatique moderne est devenue de plus en plus complexe au fur
  et à mesure des années, au niveau matériel tout comme au niveau
  logiciel : les architectures multi-coeurs (CPUs et GPUs) sont
  devenues communes, reliées par des réseaux à haute vitesse, dans
  lesquelles de nombreuses optimisations interviennent à tous les
  niveaux de façon dynamique. Tous ces éléments rendent
  l'informatique moderne imprédictible et non déterministe. Répéter
  une expérience ne produira pas forcément les mêmes résultats, en
  particulier lorsque la machine qui l'exécute n'est pas la même,
  pour des raisons matérielles. Mais le partage même de l'expérience
  à un tiers pose d'énormes problèmes : logiciels/paquets plus
  disponibles, problèmes de version, problèmes de compabilité,
  etc ... Il convient donc de s'intérresser à la reproductibilité des
  expériences, pour pouvoir les réitérer si besoin même 10 ans après.
  
  La reproductibilité est avant tout liée à de bonnes pratiques :
  comme dans d'autres domaines tels que les sciences physiques, une
  rigueur est de mise. Décrire un plan d'expérience, construire un
  environnement pour ensuite exécuter l'expérience, tenir un journal,
  organiser et stocker pertinemment les résultats, etc ... sont des
  éléments à prendre en considération dès le départ.
  
  Il existe de nombreux outils et autres solutions répondant à ce
  besoin, mais aucun ne résoud le problème dans sa globalité et la
  question reste encore ouverte. C'est pourquoi nous avons décidé de
  construire un outil /maison/ à l'aide d'outil préexistant (Spack,
  Kameleon, ...) permettant de définir entièrement une expérience :
  création de l'environnement, déploiement de l'environnement,
  pilotage de l'expérience et synthèse des résultats.
  
  =Description des différentes sections évoquées (trop tôt pour se
  prononcer ...)=
   
* TODO Contexte
  Le domainde du HPC s'intéresse aux architectures multicoeurs et à
  l'ordonnancement des tâches afin d'approcher les performances
  théoriques offertes par ce genre d'architecture, traitant des
  centaines de noeuds sur différentes machines connectées entre
  elles. En France, ces expériences sont principalement exécutées sur
  Grid5000, un projet lancé en 2003 dont le but était de mettre en
  place une grille informatique expérimentale répartie sur 10 sites en
  France. Ajourd'hui Grid5000 est constituée de milliers de CPU et de
  GPU, mis à disposition des chercheurs informatiques.

  Pour gérer cet ordonnancement des tâches, Inria a conçus StarPU : un
  support exécutif original qui fournit un modele d’execution unifié
  afin d’exploiter l’integralité de la puissance de calcul tout en
  s’affranchissant des difficultés liées a la gestion des
  données, et offre par ailleurs la possibilité de concevoir
  facilement des stratégies d’ordonnancement portables et efficaces.

  Piloter efficacement l'expérience ne représente qu'une partie de
  l'enjeu. La seconde partie que constitue la gestion de
  l'environnement nécessite de déterminer les éléments essentiels
  utilisés lors de l'expérience. Très souvent, lorsque l'on souhaite
  partager un logiciel qui a été crée sur sa machine, ce n'est jamais
  immédiat : les dépendances externes (librairies ou modules utilisés)
  ne représentent qu'une partie des dépendances et certains paquets
  échappent à l'oeil de l'expérimentateur, puisqu'il n'a pas eu besoin
  de les installer : ils l'étaient déjà.

  S'abstraire du contenu préexistant sur sa machine peut être réalisé
  en virtualisant une partie de son environnement (avec une VirtualBox
  par exemple). Néanmoins, un environnement virtualisé souffre d'un
  manque de performances inconvenant pour le HPC, en plus d'un manque
  de contrôle sur la virtualisation : c'est une boîte noire dont le
  comportement interne ne peut être précisément défini. Néanmoins, de
  nouvelles solutions (que nous présenterons plus tard) commencent à
  emmerger afin de pallier ces défauts.

  Cette gestion statique des dépendances, au moyen de temps et
  d'essais, pourra à priori être résolue bien que ce ne soit très
  plaisant. Malheureusement, cette gestion peut devenir dynamique : un
  plan d'expérience pourrait nécessiter l'installation successive d'un
  même logiciel mais avec plusieurs versions différentes, ou bien pour des
  dépendances différentes. C'est le cas avec StarPU par exemple : ce
  dernier utilise des BLAS (Basic Linear Algebra Subprograms) qui sont
  des librairies mathématiques, pour le calcul - à haute performances -
  de matrices par exemple.

  Tester StarPU pour différentes BLAS, avec différentes versions du
  logiciel, et ce de façon automatique (contenu dans un plan
  d'expérience) nécessite donc des outils afin de faciliter ce travail
  pour l'expérimentateur, aussi rigoureux soit-il.

* TODO Etat de l'art
  Tous les paramètres (nombre de coeurs, version des packages,
  version des compilateurs, etc... (la liste est longue)) doivent
  être captés au moment de l'expérience pour en interpréter les
  résultats. Il suffirait donc de construire un environnement
  possédant ces mêmes paramètres pour retrouver des résultats
  identiques. Cependant, est-ce possible ? Peut-on installer un
  programme/paquet à partir d'une version précise sans tomber
  dans un enfer de dépendances ?

  Une solution brutale, mais efficace, consisterait à enregistrer
  l'environnement dans sa globalité pour obtenir une image (un .tgz
  par exemple) que l'on pourrait redéployer : on obtiendrait un
  environnement identique et, auquel cas, des expériences identiques.

  Grid5000 est basé sur ce principe : à l'aide *tgz-g5k*, il est
  possible d'enregistrer son environnement pour ensuite le redéployer
  avec *Kadeploy*, un outil développé à l'Inria.

  Cette solution s'appuie sur le principe de bonnes pratiques, c'est à
  l'expérimentateur de s'assurer qu'une image de son expérience est
  disponible. Pour des raisons de stockage (une image peut peser
  plusieurs GB), cette solution peut ne pas être systématiquement
  appliquée, en particulier lorsqu'un logiciel à benchmarker possède
  des milliers de révisions.

  Plûtot que d'enregistrer chacun des environnements, des solutions
  telles que *Kameleon* permettent de les construire à volonté selon des
  /recettes/ : une image Debian8 pourra être construite pour ensuite y
  installer un certain nombre de paquets ou de logiciels, et
  constituer l'environnement d'une expérience. Kameleon n'est pas
  juste un outil qui exécutera successivement des commandes Shell. Son
  gros avantage (outre sa simplicité exemplaire) est la possibilité de
  créer des recettes basées sur d'autres recettes, à la manière
  d'héritage tel qu'il est proposé par les langages orientés
  objets. Une recette Kameleon pourra ainsi reprendre une recette
  construisant une image Debian basique sans se soucier de ce qu'elle
  contient.
 
  Pour ce qui concerne les dépendances dynamiques, l'outil *Spack*
  résoud ce problème en abstrayant toutes ces dépendances et leur
  installation à l'utilisateur. Ce dernier pourra ainsi installer
  StarPU avec tel ou tel BLAS, pour une version donnée, et/ou une
  version de compilateur, etc... sans se soucier du téléchargement des
  paquets nécessaires et de leur installation.

  Ces deux outils, à eux seuls, permettent de largement simplifier le
  travail de l'expérimentateur en ce qui concerne le gestion de son
  environnement et illustrent le besoin croissant des enjeux de la
  reproductibilité : des outils simples permettant de définir
  précisément et clairement les dépendances d'une machine d'un *point
  de vue extérieur*. Bien que ce ne soient pas des solutions miracles
  (installer StarPU avec Spack nécessite de fournir une fois pour
  toute les règles de compilation de ce premier), une recette Kameleon
  utilisant Spack en interne pourra être partagée sans problème et
  réutilisée à volonté.

  =Parler de du cache persistant de Kameleon pour capturer les paquets téléchargés=

  =Parler de Docker=

  =Parler d'autres trucs ?=
  
* TODO Ma contribution
  =A venir=

* TODO XP results
  =A venir=

* TODO Conclusion
  =A la fin, mais pas obligé (quand ce sera clair dans ma tête)=

* TODO Ouverture / Perspectives futures
  =RStudio -> affichage des résultats (flexdashboard)=
  =Stockage (Git branching, ...)=

* TODO Organisation et connaissances acquises			     :Moodle:
  =Shell, Org-mode (tenir un journal), ... (à méditer)=

* TODO Responsabilité sociétale des entreprises			     :Moodle:
  =A évacuer rapidement=

* TODO Bibliographie
  =A a fin=

* TODO Documents rédigés					     :Moodle:
  =A éclaircir=

* TODO Résumé / Tableau de révisions				     :Moodle:
  =A la fin=

* TODO Annexes
  =A venir=
