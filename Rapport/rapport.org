#+TITLE: Mise en place de tests de non régression de performance
#+AUTHOR: Florian Popek 
#+DATE: 13 août 2016
#+LANGUAGE: fr
#+TAGS: noexport(n) deprecated(d)
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport

#+LaTeX_CLASS: memoir
#+LaTeX_CLASS_OPTIONS: [12pt, a4paper]
#+OPTIONS: H:3 title:nil email:nil creator:nil timestamp:nil skip:nil toc:nil ^:nil
#+BABEL: :session *R* :cache yes :results output graphics :exports both :tangle yes 

#+LATEX_HEADER:\usepackage[french]{babel}
#+LATEX_HEADER:\usepackage [vscale=0.76,includehead]{geometry}                % See geometry.pdf to learn the layout options. There are lots.
# #+LATEX_HEADER:\geometry{a4paper}                   % ... or a4paper or a5paper or ... 
# #+LATEX_HEADER:\geometry{landscape}                % Activate for for rotated page geometry
# #+LATEX_HEADER:\OnehalfSpacing
# #+LATEX_HEADER: \setSingleSpace{1.05}
# #+LATEX_HEADER:\usepackage[parfill]{parskip}    % Activate to begin paragraphs with an empty line rather than an indent
#+LATEX_HEADER:\usepackage{amsmath}
#+LATEX_HEADER:\usepackage{fullpage}
#+LATEX_HEADER:\usepackage{mathptmx} % font = times
#+LATEX_HEADER:\usepackage{helvet} % font sf = helvetica
#+LATEX_HEADER:\usepackage[utf8]{inputenc}
#+LATEX_HEADER:\usepackage{relsize}
#+LATEX_HEADER:% \usepackage{listings}
#+LATEX_HEADER:\usepackage{color}
#+latex_header:\usepackage{xspace}
#+latex_header:\usepackage{subcaption}
#+LATEX_HEADER:% \usepackage{verbments}
#+LaTeX_HEADER:% \usepackage{minted}


#+BEGIN_LaTeX
% \lstset{ %
%   basicstyle=\footnotesize,        % the size of the fonts that are used for the code
%   breakatwhitespace=false,         % sets if automatic breaks should only happen at whitespace
%   breaklines=true,                 % sets automatic line breaking
%   captionpos=b,                    % sets the caption-position to bottom
%   %commentstyle=\color{mygreen},    % comment style
%   deletekeywords={...},            % if you want to delete keywords from the given language
%   escapeinside={\%*}{*)},          % if you want to add LaTeX within your code
%   extendedchars=true,              % lets you use non-ASCII characters; for 8-bits encodings only, does not work with UTF-8
%   frame=single,                    % adds a frame around the code
%   keepspaces=true,                 % keeps spaces in text, useful for keeping indentation of code (possibly needs columns=flexible)
%   keywordstyle=\color{blue},       % keyword style
%   language=Shell,                 % the language of the code
%   otherkeywords={*,...},           % if you want to add more keywords to the set
%   numbers=left,                    % where to put the line-numbers; possible values are (none, left, right)
%   numbersep=5pt,                   % how far the line-numbers are from the code
%   %numberstyle=\tiny\color{mygray}, % the style that is used for the line-numbers
%   rulecolor=\color{black},         % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. comments (green here))
%   showspaces=false,                % show spaces everywhere adding particular underscores; it overrides 'showstringspaces'
%   showstringspaces=false,          % underline spaces within strings only
%   showtabs=false,                  % show tabs within strings adding particular underscores
%   stepnumber=2,                    % the step between two line-numbers. If it's 1, each line will be numbered
%   stringstyle=\color{mymauve},     % string literal style
%   tabsize=2,                       % sets default tabsize to 2 spaces
%   title=\lstname                   % show the filename of files included with \lstinputlisting; also try caption instead of title
% }
% \renewcommand{\lstlistingname}{Code}
#+END_LaTeX

#+BEGIN_LaTeX
%Style des têtes de section, headings, chapitre
\headstyles{komalike}
\nouppercaseheads
\chapterstyle{dash}
\makeevenhead{headings}{\sffamily\thepage}{}{\sffamily\leftmark} 
\makeoddhead{headings}{\sffamily\rightmark}{}{\sffamily\thepage}
\makeoddfoot{plain}{}{}{} % Pages chapitre. 
\makeheadrule{headings}{\textwidth}{\normalrulethickness}
%\renewcommand{\leftmark}{\thechapter ---}
\renewcommand{\chaptername}{\relax}
\renewcommand{\chaptitlefont}{ \sffamily\bfseries \LARGE}
\renewcommand{\chapnumfont}{ \sffamily\bfseries \LARGE}
\setsecnumdepth{subsection}


% Title page formatting -- do not change!
\pretitle{\HUGE\sffamily \bfseries\begin{center}} 
\posttitle{\end{center}}
\preauthor{\LARGE  \sffamily \bfseries\begin{center}}
\postauthor{\par\end{center}}

\newcommand{\jury}[1]{% 
\gdef\juryB{#1}} 
\newcommand{\juryB}{} 
\newcommand{\session}[1]{% 
\gdef\sessionB{#1}} 
\newcommand{\sessionB}{} 
\newcommand{\option}[1]{% 
\gdef\optionB{#1}} 
\newcommand{\optionB}{} 

\renewcommand{\maketitlehookd}{% 
\vfill{}  \large\par\noindent  
\begin{center}\juryB \bigskip\sessionB\end{center}
\vspace{-1.5cm}}
\renewcommand{\maketitlehooka}{% 
% \vspace{-1.5cm}\noindent\includegraphics[height=14ex]{logoINP.png}\hfill\raisebox{2ex}{\includegraphics[height=7ex]{logoUJF.jpg}}\\
\bigskip
\begin{center} \large
RICM \\
option Réseau \end{center}\vfill}
% End of title page formatting

\option{$PDES$}
%\title{Mise en place de tests de non régression de performance}%\\\vspace{-1ex}\rule{10ex}{0.5pt} \\sub-title} 
%\author{Florian POPEK}
%\date{ June 22th 2016 } % Delete this line to display the current date
\jury{
Stage réalisé au Laboratoire d'Informatique de Grenoble \\\medskip
Sous la supervision d'Arnaud Legrand (équipe POLARIS)\\\medskip

Soutenu devant le jury composé de:\\
Dr Olivier Richard\\
...\\
}
\session{\textit{Septembre}\hfill 2016}
#+END_LaTeX

#+BEGIN_LaTeX
\selectlanguage{french} % french si rapport en français
\frontmatter
\begin{titlingpage}
\maketitle
\end{titlingpage}

%\small
\setlength{\parskip}{-1pt plus 1pt}

\renewcommand{\abstracttextfont}{\normalfont}
\abstractintoc
\renewcommand\abstractname{R\'esum\'e}
\begin{abstract} 
#+END_LaTeX
  De tout temps la communauté scientifique n'a cessé de croître grâce
  aux échanges, permettant aux scientifiques de baser leurs travaux
  sur ceux préalablement établis par d'autres. Ces échanges permettent
  également de crédibiliser les résultats trouvés en décrivant les
  protocoles expérimentaux, afin que quiconque puisse de son côté les
  vérifier. L'informatique ne déroge pas à ce principe, néanmoins, le
  nombre de paramètres à prendre en compte et les différences entre
  machines rendent ce processus de partage épineux, autant pour celui
  qui souhaite décrire précisément son expérience que pour celui qui
  souhaite la reproduire.

  Dans ce document, nous abordons le problème de la reproductibilité
  des expériences, en particulier dans le domaine HPC (High
  Performance Computing), selon deux aspects qui sont: le contrôle de
  l'environnement et le pilotage de l'expérience, en plus de quelques
  considérations autour de la reproductibilité en général. On y
  présentera notre solution basée sur des technologies développées à
  l'Inria permettant de déployer un environnement afin d'y conduire
  des expériences. L'objectif final est d'évaluer les performances
  (/benchmarker/) de StarPU tout au long de son évolution afin d'y
  déceler de potentielles régressions entre deux versions, tout en
  ayant un contrôle parfait de l'environnement et de l'expérience.
 \end{abstract}
#+BEGIN_LaTeX

\cleardoublepage

\tableofcontents* % the asterisk means that the table of contents itself isn't put into the ToC
\normalsize

\mainmatter
\SingleSpace
#+END_LaTeX
* Trucs à faire 						   :noexport:
** TODO Sommaire
   =A la fin=

* TODO Introduction
  L'informatique moderne est devenue de plus en plus complexe au fur
  et à mesure des années, au niveau matériel tout comme au niveau
  logiciel: les architectures multi-cœurs (CPUs et GPUs) sont
  devenues communes, reliées par des réseaux à haute vitesse, dans
  lesquelles de nombreuses optimisations interviennent à tous les
  niveaux de façon dynamique. Tous ces éléments rendent l'informatique
  moderne non déterministe et donc difficile à prédire. Répéter une expérience ne
  produira pas forcément les mêmes résultats, en particulier lorsque
  la machine qui l'exécute n'est pas la même, pour des raisons
  matérielles. Mais le partage même de l'expérience à un tiers pose
  d'énormes problèmes: logiciels/paquets plus disponibles, problèmes
  de version, problèmes de compatibilité, problèmes même de
  compréhension de l'expérience, etc ... Il convient donc de
  s'intéresser à la reproductibilité des expériences, pour pouvoir
  les réitérer si besoin même 10 ans après, sans avoir à y consacrer
  bien trop de temps précieux.
  
  La reproductibilité est avant tout liée à de bonnes pratiques:
  comme dans d'autres domaines tels que les sciences physiques, une
  rigueur est de mise. Décrire un plan d'expérience, construire un
  environnement pour ensuite exécuter l'expérience, tenir un journal,
  organiser et stocker pertinemment les résultats, etc ... sont des
  éléments à prendre en considération dès le départ.
  
  Il existe de nombreux outils et autres solutions répondant à ce
  besoin, mais aucun ne résoud le problème dans sa globalité et la
  question reste encore ouverte. C'est pourquoi nous avons décidé de
  construire un outil /maison/ à l'aide d'outil préexistant (Spack,
  Kameleon, ...) permettant de définir entièrement une expérience:
  création de l'environnement, déploiement de l'environnement,
  pilotage de l'expérience et synthèse des résultats, afin de répondre
  précisément à nos attentes concernant notre objectif.
  
  =Description des différentes sections évoquées (trop tôt pour se
  prononcer ...)=
   
* État de l'art
  La reproductibilité est une préoccupation récente motivée en
  particulier par les chercheurs en informatique traduisant une
  volonté de transparence et de clarté des expériences et des
  résultats (graphes clairs, titré, avec une bonne échelle, présence
  des unités, problèmes rencontrés, ...).

  Elle est issue d'un phénomène courant: lorsqu'un article paraît
  présentant des résultats, récupérer le code de l'expérience auprès
  de leurs auteurs est rarement possible pour des raisons variées:

  - L'auteur n'a pas l'intention de fournir le code
  - Le code n'est pas disponible pour des raisons commerciales
  - Le code est la propriété d'un organisme ou d'une université
  - La personne en charge de ce code ne fait plus parti de l'organisme
  - Problème de version: le code récupéré n'est pas exactement le
    même (il a évolué depuis)
  - Mauvaise pratique de back-up: le code est perdu / n'est plus
    accessible
  - Le code sera bientôt disponible (il est en phase de /nettoyage/, et
    très souvent ne sera pas délivré)
  - Le code n'est pas partageable: trop d'investissement serait
    nécessaire pour qu'il le soit

  D'autres phénomènes peuvent également biaiser les résultats d'une expérience la
  rendant non-reproductible:

  - Un article devra quasi-systématiquement afficher des résultats
    positifs (esprit de compétitivité)
  - Biais de l'expérimentateur: celui-ci se débrouillera pour
    concurrencer les résultats d'autres chercheurs puisqu'il fera tout
    pour (ces derniers pourraient en faire autant): problème de
    contexte d'exécution et de point de vue de l'expérimentateur
  - L'erreur humaine: problème de manipulation de données, ou erreurs
    de programmations qui au final affichent de bons résultats
  - Pas de volonté de rendre l'expérience partageable de toute façon:
    manque d'outils, le matériel et le logiciel changent constamment
    (ces excuses ne sont plus valables aujourd'hui)
  - Voire même problème de fraude

  Tous ces problèmes ont poussé les chercheurs à entreprendre des
  recherches reproductibles, dont la définition ne se limite pas à
  pouvoir ré-exécuter du code. Il s'agit de pouvoir répliquer à
  l'identique ce qu'un tiers a pu faire (réplicabilité) afin de
  recréer l'esprit des précédents travaux par soi-même pour en arriver
  à des conclusions identiques (reproductibilité).

  Plusieurs points clés définissent le processus de recherche
  reproductible:

  - Noter son activité
  - Noter et enregistrer ses résultats
  - Organiser ses résultats
  - Contrôler son environnement
  - Contrôler son expérience
  - Tout le monde refaire l'expérience

  Ainsi, l'objectif principal des recherches reproductibles est de noter
  absolument tout ce que l'expérimentateur entreprend et collecte,
  tant de bons que de mauvais résultats, mais aussi les motivations de
  ce qu'il fait. De nombreux outils permettent de faciliter ce travail
  de prise de note (Org-mode par exemple, que nous présenterons), et
  d'autres outils permettent de mieux définir une expérience en terme
  de workflow, mais aussi en terme d'avancement / de back-up avec les
  logiciels de gestion de versions tels que Git par exemple.

* TODO Contexte
  Le domaine du HPC s'intéresse aux architectures multi-cœurs et à
  l'ordonnancement des tâches afin d'approcher les performances
  théoriques offertes par ce genre d'architecture, traitant des
  centaines de noeuds sur différentes machines connectées entre
  elles. En France, ces expériences sont principalement exécutées sur
  Grid5000, un projet lancé en 2003 dont le but était de mettre en
  place une grille informatique expérimentale répartie sur 10 sites en
  France. Aujourd'hui Grid5000 est constituée de milliers de CPU et de
  GPU, mis à disposition des chercheurs informatiques.

  Pour gérer cet ordonnancement des tâches, Inria a conçus StarPU: un
  support exécutif original qui fournit un modelé d’exécution unifié
  afin d’exploiter l’intégralité de la puissance de calcul tout en
  s’affranchissant des difficultés liées a la gestion des
  données, et offre par ailleurs la possibilité de concevoir
  facilement des stratégies d’ordonnancement portables et efficaces.

  Piloter efficacement l'expérience ne représente qu'une partie de
  l'enjeu. La seconde partie que constitue la gestion de
  l'environnement nécessite de déterminer les éléments essentiels
  utilisés lors de l'expérience. Très souvent, lorsque l'on souhaite
  partager un logiciel qui a été crée sur sa machine, ce n'est jamais
  immédiat: les dépendances externes (librairies ou modules utilisés)
  ne représentent qu'une partie des dépendances et certains paquets
  échappent à l'oeil de l'expérimentateur, puisqu'il n'a pas eu besoin
  de les installer: ils l'étaient déjà.

  S'abstraire du contenu préexistant sur sa machine peut être réalisé
  en virtualisant une partie de son environnement (avec une VirtualBox
  par exemple). Néanmoins, un environnement virtualisé souffre d'un
  manque de performances inconvenant pour le HPC, en plus d'un manque
  de contrôle sur la virtualisation: c'est une boîte noire dont le
  comportement interne ne peut être précisément défini. Néanmoins, de
  nouvelles solutions (que nous présenterons plus tard) commencent à
  émerger afin de pallier ces défauts.

  Cette gestion statique des dépendances, au moyen de temps et
  d'essais, pourra à priori être résolue bien que ce ne soit très
  plaisant. Malheureusement, cette gestion peut devenir dynamique: un
  plan d'expérience pourrait nécessiter l'installation successive d'un
  même logiciel mais avec plusieurs versions différentes, ou bien pour des
  dépendances différentes. C'est le cas avec StarPU par exemple: ce
  dernier utilise des BLAS (Basic Linear Algebra Subprograms) qui sont
  des librairies mathématiques, pour le calcul - à haute performances -
  de matrices par exemple.

  Tester StarPU pour différentes BLAS, avec différentes versions du
  logiciel, et ce de façon automatique (contenu dans un plan
  d'expérience) nécessite donc des outils et de bonnes pratiques afin
  de faciliter ce travail pour l'expérimentateur, aussi rigoureux
  soit-il.

* Vrac
  Tous les paramètres (nombre de coeurs, version des packages,
  version des compilateurs, etc... (la liste est longue)) doivent
  être captés au moment de l'expérience pour en interpréter les
  résultats. Il suffirait donc de construire un environnement
  possédant ces mêmes paramètres pour retrouver des résultats
  identiques. Cependant, est-ce possible ? Peut-on installer un
  programme/paquet à partir d'une version précise sans tomber
  dans un enfer de dépendances ?

  Une solution brutale, mais efficace, consisterait à enregistrer
  l'environnement dans sa globalité pour obtenir une image (un .tgz
  par exemple) que l'on pourrait redéployer: on obtiendrait un
  environnement identique et, auquel cas, des expériences identiques.

  Grid5000 est basé sur ce principe: à l'aide *tgz-g5k*, il est
  possible d'enregistrer son environnement pour ensuite le redéployer
  avec *Kadeploy*, un outil développé à l'Inria.

  Cette solution s'appuie sur le principe de bonnes pratiques, c'est à
  l'expérimentateur de s'assurer qu'une image de son expérience est
  disponible. Pour des raisons de stockage (une image peut peser
  plusieurs GB), cette solution peut ne pas être systématiquement
  appliquée, en particulier lorsqu'un logiciel à benchmarker possède
  des milliers de révisions.

  Plutôt que d'enregistrer chacun des environnements, des solutions
  telles que *Kameleon* permettent de les construire à volonté selon des
  /recettes/: une image Debian8 pourra être construite pour ensuite y
  installer un certain nombre de paquets ou de logiciels, et
  constituer l'environnement d'une expérience. Kameleon n'est pas
  juste un outil qui exécutera successivement des commandes Shell. Son
  gros avantage (outre sa simplicité exemplaire) est la possibilité de
  créer des recettes basées sur d'autres recettes, à la manière
  d'héritage tel qu'il est proposé par les langages orientés
  objets. Une recette Kameleon pourra ainsi reprendre une recette
  construisant une image Debian basique sans se soucier de ce qu'elle
  contient.
 
  Pour ce qui concerne les dépendances dynamiques, l'outil *Spack*
  résoud ce problème en abstrayant toutes ces dépendances et leur
  installation à l'utilisateur. Ce dernier pourra ainsi installer
  StarPU avec tel ou tel BLAS, pour une version donnée, et/ou une
  version de compilateur, etc... sans se soucier du téléchargement des
  paquets nécessaires et de leur installation.

  Ces deux outils, à eux seuls, permettent de largement simplifier le
  travail de l'expérimentateur en ce qui concerne le gestion de son
  environnement et illustrent le besoin croissant des enjeux de la
  reproductibilité: des outils simples permettant de définir
  précisément et clairement les dépendances d'une machine d'un *point
  de vue extérieur*. Bien que ce ne soient pas des solutions miracles
  (installer StarPU avec Spack nécessite de fournir une fois pour
  toute les règles de compilation de ce premier), une recette Kameleon
  utilisant Spack en interne pourra être partagée sans problème et
  réutilisée à volonté.

  =Parler de du cache persistant de Kameleon pour capturer les paquets téléchargés=

  =Parler de Docker=

  =Parler d'autres trucs ?=
  
* TODO Ma contribution
  =A venir=

* TODO XP results
  =A venir=

* TODO Conclusion
  =A la fin, mais pas obligé (quand ce sera clair dans ma tête)=

* TODO Ouverture / Perspectives futures
  =RStudio -> affichage des résultats (flexdashboard)=
  =Stockage (Git branching, ...)=

* TODO Organisation et connaissances acquises			     :Moodle:
  =Shell, Org-mode (tenir un journal), ... (à méditer)=

* TODO Responsabilité sociétale des entreprises			     :Moodle:
  =A évacuer rapidement=

* TODO Bibliographie
  =A a fin=

* TODO Documents rédigés					     :Moodle:
  =A éclaircir=

* TODO Résumé / Tableau de révisions				     :Moodle:
  =A la fin=

* TODO Annexes
  =A venir=
* Emacs Setup 							   :noexport:
  This document has local variables in its postembule, which should
  allow Org-mode to work seamlessly without any setup. If you're
  uncomfortable using such variables, you can safely ignore them at
  startup. Exporting may require that you copy them in your .emacs.

# Local Variables:
# eval:    (require 'org-install)
# eval:    (org-babel-do-load-languages 'org-babel-load-languages '( (sh . t) (R . t) (perl . t) (ditaa . t) ))
# eval:    (setq org-confirm-babel-evaluate nil)
# eval:    (unless (boundp 'org-latex-classes) (setq org-latex-classes nil))
# eval:    (add-to-list 'org-latex-classes '("memoir" "\\documentclass[smallextended]{memoir} \n \[NO-DEFAULT-PACKAGES]\n \[EXTRA]\n  \\usepackage{graphicx}\n  \\usepackage{hyperref}" ("\\chapter{%s}" . "\\chapter*{%s}") ("\\section{%s}" . "\\section*{%s}") ("\\subsection{%s}" . "\\subsection*{%s}")                       ("\\subsubsection{%s}" . "\\subsubsection*{%s}")                       ("\\paragraph{%s}" . "\\paragraph*{%s}")                       ("\\subparagraph{%s}" . "\\subparagraph*{%s}")))
# eval:    (add-to-list 'org-latex-classes '("acm-proc-article-sp" "\\documentclass{acm_proc_article-sp}\n \[NO-DEFAULT-PACKAGES]\n \[EXTRA]\n"  ("\\section{%s}" . "\\section*{%s}") ("\\subsection{%s}" . "\\subsection*{%s}")                       ("\\subsubsection{%s}" . "\\subsubsection*{%s}")                       ("\\paragraph{%s}" . "\\paragraph*{%s}")                       ("\\subparagraph{%s}" . "\\subparagraph*{%s}")))
# eval:    (setq org-alphabetical-lists t)
# eval:    (setq org-src-fontify-natively t)
# eval:    (setq org-export-babel-evaluate nil)
# eval:    (setq ispell-local-dictionary "english")
# eval:    (eval (flyspell-mode t))
# eval:    (setq org-latex-listings 'minted)
# eval:    (setq org-latex-minted-options '(("bgcolor" "white") ("style" "tango") ("numbers" "left") ("numbersep" "5pt")))
# End:
